[
  {
    "objectID": "website_files/notebooks/wildfire.html",
    "href": "website_files/notebooks/wildfire.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "This dataset contains information on wildfires in Canada, compiled from official government sources.\n\n\n\nFire size (in hectares)\nCause of fire (e.g., lightning, human activity)\nDetection method\nResponse team size\nLatitude/longitude of the fire\nWeather conditions at the time of fire\n\n\n\n\nThe data was collected to monitor, assess, and respond to wildfire risks across regions. Wildfires have significant environmental, social, and economic impacts—especially for remote, Indigenous, and underserved communities that may lack the infrastructure to respond effectively.\nFrom an equity and inclusion perspective, studying wildfire data can help identify geographic and resource disparities in fire detection and containment efforts, as well as the disproportionate risks certain populations face due to climate change and infrastructure gaps."
  },
  {
    "objectID": "website_files/notebooks/wildfire.html#about-the-data",
    "href": "website_files/notebooks/wildfire.html#about-the-data",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "This dataset contains information on wildfires in Canada, compiled from official government sources.\n\n\n\nFire size (in hectares)\nCause of fire (e.g., lightning, human activity)\nDetection method\nResponse team size\nLatitude/longitude of the fire\nWeather conditions at the time of fire\n\n\n\n\nThe data was collected to monitor, assess, and respond to wildfire risks across regions. Wildfires have significant environmental, social, and economic impacts—especially for remote, Indigenous, and underserved communities that may lack the infrastructure to respond effectively.\nFrom an equity and inclusion perspective, studying wildfire data can help identify geographic and resource disparities in fire detection and containment efforts, as well as the disproportionate risks certain populations face due to climate change and infrastructure gaps."
  },
  {
    "objectID": "website_files/notebooks/wildfire.html#case-study",
    "href": "website_files/notebooks/wildfire.html#case-study",
    "title": "Diverse Data Hub",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nCan we identify the environmental and human factors most associated with large wildfires (&gt;10 hectares)?\nThe goal is to explore potential predictors of fire size, such as weather, fire cause, and detection method, and provide insights that could inform early interventions and resource planning.\n\n\nMethodology\n\n1. Data Cleaning & Processing\n\nConverted fire size to numeric\nCreated a binary variable large_fire (TRUE if &gt;10 ha)\nFiltered out incomplete records\n\n\n\n2. Exploratory Data Analysis (EDA)\nFire Size Distribution\n\nlibrary(ggplot2)\n\nggplot(wildfire_clean, aes(x = ASSESSMENT_HECTARES)) +\n  geom_histogram(bins = 40) +\n  scale_x_log10() +\n  labs(\n    title = \"Distribution of Fire Size (Assessment Hectares)\",\n    x = \"Fire Size (log scale)\",\n    y = \"Number of Fires\"\n  )\n\n\n\n\n\n\n\n\nProportion of Large Fires by Cause\n\nwildfire_clean %&gt;%\n  group_by(TRUE_CAUSE) %&gt;%\n  summarize(prop_large = mean(large_fire, na.rm = TRUE)) %&gt;%\n  ggplot(aes(x = reorder(TRUE_CAUSE, prop_large), y = prop_large)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Proportion of Large Fires by True Cause\",\n    x = \"True Cause\",\n    y = \"Proportion of Fires &gt; 10 ha\"\n  )\n\n\n\n\n\n\n\n\n\n\n3. Logistic Regression Model\nWe build a logistic regression model to predict the likelihood of a fire becoming large based on temperature, wind speed, and cause.\n\nlibrary(broom)\n\nmodel &lt;- glm(\n  large_fire ~ TEMPERATURE + WIND_SPEED + TRUE_CAUSE + DETECTION_AGENT_TYPE,\n  data = wildfire_clean,\n  family = \"binomial\"\n)\n\n\n# Tidy and clean model output\ntidy_model &lt;- broom::tidy(model) %&gt;%\n  dplyr::mutate(\n    estimate = round(estimate, 3),\n    std.error = round(std.error, 3),\n    statistic = round(statistic, 2),\n    p.value = round(p.value, 4)\n  )\n\n# Create a nice table\ngt_table &lt;- tidy_model %&gt;%\n  gt::gt() %&gt;%\n  gt::tab_header(\n    title = \"Logistic Regression Results\",\n    subtitle = \"Predicting Large Fires (&gt; 10 ha)\"\n  ) %&gt;%\n  gt::cols_label(\n    term = \"Variable\",\n    estimate = \"Estimate (Log-Odds)\",\n    std.error = \"Std. Error\",\n    statistic = \"z value\",\n    p.value = \"p-value\"\n  ) %&gt;%\n  gt::fmt_missing(everything(), missing_text = \"-\") %&gt;%\n  gt::tab_options(\n    table.font.size = \"small\",\n    data_row.padding = gt::px(4),\n    heading.title.font.size = 16,\n    heading.subtitle.font.size = 12\n  )\n\ngt_table\n\n\n\n\n\n\n\nLogistic Regression Results\n\n\nPredicting Large Fires (&gt; 10 ha)\n\n\nVariable\nEstimate (Log-Odds)\nStd. Error\nz value\np-value\n\n\n\n\n(Intercept)\n-4.262\n0.512\n-8.32\n0.0000\n\n\nTEMPERATURE\n-0.040\n0.012\n-3.22\n0.0013\n\n\nWIND_SPEED\n0.051\n0.007\n7.01\n0.0000\n\n\nTRUE_CAUSEAnimals\n-15.465\n2121.042\n-0.01\n0.9942\n\n\nTRUE_CAUSEArson Known\n-16.045\n2200.700\n-0.01\n0.9942\n\n\nTRUE_CAUSEArson Suspected\n-0.219\n0.671\n-0.33\n0.7443\n\n\nTRUE_CAUSEBurning Substance\n-0.016\n0.450\n-0.04\n0.9716\n\n\nTRUE_CAUSEFlammable Fluids\n-16.016\n4207.738\n0.00\n0.9970\n\n\nTRUE_CAUSEFriction Spark\n0.401\n0.678\n0.59\n0.5541\n\n\nTRUE_CAUSEHigh Hazard\n-16.284\n1926.733\n-0.01\n0.9933\n\n\nTRUE_CAUSEHot Exhaust\n0.346\n0.793\n0.44\n0.6628\n\n\nTRUE_CAUSEIncendiary Device\n0.489\n1.075\n0.45\n0.6492\n\n\nTRUE_CAUSEInsufficient Buffer\n0.231\n0.514\n0.45\n0.6531\n\n\nTRUE_CAUSEInsufficient Resources\n3.811\n1.241\n3.07\n0.0021\n\n\nTRUE_CAUSELine Impact\n-2.123\n1.069\n-1.99\n0.0470\n\n\nTRUE_CAUSEMechanical Failure\n-0.532\n0.790\n-0.67\n0.5011\n\n\nTRUE_CAUSEPermit Related\n0.326\n0.425\n0.77\n0.4439\n\n\nTRUE_CAUSEUnattended Fire\n0.041\n1.064\n0.04\n0.9696\n\n\nTRUE_CAUSEUnclassified\n0.375\n0.791\n0.47\n0.6355\n\n\nTRUE_CAUSEUnpredictable Event\n-0.738\n0.800\n-0.92\n0.3562\n\n\nTRUE_CAUSEUnsafe Fire\n-0.146\n0.401\n-0.36\n0.7161\n\n\nTRUE_CAUSEVehicle Fire\n-0.631\n1.060\n-0.60\n0.5516\n\n\nTRUE_CAUSEWinter Burning\n0.433\n0.454\n0.95\n0.3409\n\n\nDETECTION_AGENT_TYPEGRP\n-16.143\n438.705\n-0.04\n0.9706\n\n\nDETECTION_AGENT_TYPELKT\n0.023\n0.371\n0.06\n0.9502\n\n\nDETECTION_AGENT_TYPEUNP\n-0.613\n0.363\n-1.69\n0.0907\n\n\n\n\n\n\n\n\n\n4. Discussion\nThe logistic regression model revealed that higher wind speeds are strongly associated with an increased likelihood of a fire becoming large (over 10 hectares), consistent with our expectations about fire spread dynamics.\nSurprisingly, temperature showed a small negative association with fire size, though this may be influenced by interactions with other environmental factors like humidity or fuel type.\nAmong causes, “Insufficient Resources” and “Line Impact” were associated with significantly higher odds of large fires. This suggests that both human-related limitations and infrastructure vulnerability (like power lines) play a role in fire escalation.\nThe detection agent type showed weak evidence that fires detected by UNP agents may be less likely to become large, compared to FPD Staff, but the effect was not statistically strong (p = 0.09). Further exploration is needed here, especially considering the early intervention ability of different detection teams.\nThese findings provide insights into key environmental and operational factors influencing wildfire severity. Importantly, they point to the need for targeted mitigation strategies in areas with poor detection access or high infrastructure risks.\nIn the broader context of equity, this analysis reinforces that resource constraints and delayed detection—often more common in remote or underfunded regions—can amplify wildfire impacts. Data-informed strategies can help ensure more equitable protection against climate-driven disasters.\n\n\n5. Interpretation Boost using marginaleffects\nWind Speed\nAs wind speed increases, the model estimates a higher probability of a fire becoming large (&gt;10 hectares). However, the variability in the predicted probabilities also increases at higher wind speeds, as indicated by the wider confidence intervals. This suggests that while there is a general upward trend, the model’s certainty about the exact magnitude of the effect decreases in this range—likely due to fewer observations or greater variability in fire outcomes at high wind speeds.\n\nlibrary(marginaleffects)\n\nWarning: package 'marginaleffects' was built under R version 4.4.3\n\n## continuous variable\nplot_predictions(\n  model,\n  by = \"WIND_SPEED\"\n)\n\n\n\n\n\n\n\n\nTemperature\nAs temperature increases, the model predicts a relatively stable probability of a fire becoming large. The trend line flattens and the confidence intervals narrow, indicating that the model is more confident and consistent in its estimates across higher temperature ranges. This suggests that the relationship between temperature and fire size is more stable and predictable at higher temperatures, possibly due to a larger number of observations or less variability in outcomes.\n\n## continuous variable \"TEMPERATURE\"\n\nplot_predictions(\n  model,\n  by = \"TEMPERATURE\"\n)\n\n\n\n\n\n\n\n\nTrue Cause\nThe predicted probability of a large fire is near zero for most TRUE_CAUSE categories, indicating that these causes (e.g., natural ignition, campfires, equipment use) are generally not associated with large-scale fires. However, the category “Insufficient Resources” stands out with a significantly higher predicted probability and a wide confidence interval. This suggests that fires classified under this cause are much more likely to become large, though the wide interval reflects substantial uncertainty — likely due to a small number of observations in that category.\n\n## categorical variable \"TRUE_CAUSE\"\nplot_predictions(model, by = \"TRUE_CAUSE\") +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1)) +\n  ggplot2::labs(\n    title = \"Predicted Probability of Large Fire by True Cause\",\n    x = \"True Cause\",\n    y = \"Predicted Probability\"\n  )\n\n\n\n\n\n\n\n\nDetection Agent Type\nAlthough fires detected by AIR agents appear more likely to become large, the model is relatively uncertain about this pattern. The wide confidence interval indicates that this result should be interpreted cautiously, and may reflect data sparsity or high variability in fire outcomes for AIR-detected cases.\n\n## categorical variable \"DETECTION_AGENT_TYPE\"\nplot_predictions(\n  model,\n  by = \"DETECTION_AGENT_TYPE\"\n)"
  },
  {
    "objectID": "website_files/notebooks/notebook_r.html",
    "href": "website_files/notebooks/notebook_r.html",
    "title": "R Page With Code",
    "section": "",
    "text": "library(ggplot2)\n\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 37 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 37 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "website_files/notebooks/marchmadness.html",
    "href": "website_files/notebooks/marchmadness.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "This adapted data set contains historical records of every NCAA Division I Women’s Basketball Tournament appearance since the tournament began in 1982 up until 2018. Sourced from official NCAA, the adapted data set captures tournament results across more than four decades of collegiate women’s basketball.\nThe rise in popularity of the NCAA Women’s March Madness, fueled by athletes like Caitlin Clark and Paige Bueckers, reflects a broader cultural shift in the recognition of women’s sports. Beyond entertainment and athletic achievement, women’s participation in sport has social and professional benefits.\nAs Beth A. Brooke notes in her article Here’s Why Women Who Play Sports Are More Successful, research from EY shows that 94% of women in executive leadership roles played sports, and over half competed at the university level. Participation in sports hel develop skills such as resilience, teamwork, and competitiveness, traits that critical for career success.\nAnalyzing NCAA Women’s March Madness results and promoting visibility of women in sports, beyond exercising our data skills, supports advocation for equity, opportunity, and empowerment of women in leadership.\n\n\nEach row represents a single team’s appearance in a specific tournament year and includes information such as:\n\nTournament Seed – Seed assigned to the team\nTournament Results – Number of wins, losses, and how far the team advanced\nBid Type – Whether the team received an automatic bid or was selected at-large.\nSeason Records – Regular season, conference, and total win/loss stats and percentages\nConference Information – Team’s conference name, record, and rank within the conference\nDivision – Regional placement in the tournament bracket (e.g., East, West)\nHome Game Indication – Whether the team played its first game at home\n\n\n\n\nThis dataset is designed to support analysis of:\n\nTeam performance over time\nImpact of seeding and bid types on tournament results\nConference strength\nEmergence and decline of winning teams in women’s college basketball"
  },
  {
    "objectID": "website_files/notebooks/marchmadness.html#about-the-data",
    "href": "website_files/notebooks/marchmadness.html#about-the-data",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "This adapted data set contains historical records of every NCAA Division I Women’s Basketball Tournament appearance since the tournament began in 1982 up until 2018. Sourced from official NCAA, the adapted data set captures tournament results across more than four decades of collegiate women’s basketball.\nThe rise in popularity of the NCAA Women’s March Madness, fueled by athletes like Caitlin Clark and Paige Bueckers, reflects a broader cultural shift in the recognition of women’s sports. Beyond entertainment and athletic achievement, women’s participation in sport has social and professional benefits.\nAs Beth A. Brooke notes in her article Here’s Why Women Who Play Sports Are More Successful, research from EY shows that 94% of women in executive leadership roles played sports, and over half competed at the university level. Participation in sports hel develop skills such as resilience, teamwork, and competitiveness, traits that critical for career success.\nAnalyzing NCAA Women’s March Madness results and promoting visibility of women in sports, beyond exercising our data skills, supports advocation for equity, opportunity, and empowerment of women in leadership.\n\n\nEach row represents a single team’s appearance in a specific tournament year and includes information such as:\n\nTournament Seed – Seed assigned to the team\nTournament Results – Number of wins, losses, and how far the team advanced\nBid Type – Whether the team received an automatic bid or was selected at-large.\nSeason Records – Regular season, conference, and total win/loss stats and percentages\nConference Information – Team’s conference name, record, and rank within the conference\nDivision – Regional placement in the tournament bracket (e.g., East, West)\nHome Game Indication – Whether the team played its first game at home\n\n\n\n\nThis dataset is designed to support analysis of:\n\nTeam performance over time\nImpact of seeding and bid types on tournament results\nConference strength\nEmergence and decline of winning teams in women’s college basketball"
  },
  {
    "objectID": "website_files/notebooks/marchmadness.html#case-study",
    "href": "website_files/notebooks/marchmadness.html#case-study",
    "title": "Diverse Data Hub",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nHow much does a team’s tournament seed predict its success in the NCAA Division I Women’s Basketball Tournament?\nThis analysis explores the relationship between a team’s seed and its results on a tournament to evaluate whether teams with lower seeds consistently outperform ones with higher seeds.\nBy examining historical data, we aim to:\n\nIdentify trends in tournament advancement by seed level\n\nSeeding is intended to reflect a team’s regular-season performance. In theory, lower-numbered seeds (e.g., #1, #2) are given to the strongest teams, who should be more likely to advance. But upsets, bracket surprises, and standout performances from lower seeds raise questions like “How reliable is seeding as a predictor of success?”\nUnderstanding these dynamics can inform fan expectations and bracket predictions.\n\n\nMethodology\n\n1. Data Cleaning & Processing\nFirst, let’s load our data and remove all NA values for our variables of interest seed and tourney_wins.\n\nlibrary(tidyverse) \n\n# Reading Data\nmarchmadness &lt;- read_csv(\"../../data/clean/womensmarchmadness.csv\") \n\n# Review total rows\nnrow(marchmadness)\n\n[1] 2092\n\n# Removing NA but only in selected columns\nmarchmadness &lt;- marchmadness |&gt; drop_na(seed, tourney_wins)\n\n# Notice no rows were removed\nnrow(marchmadness)\n\n[1] 2092\n\n# Visualize the data set\nhead(marchmadness)\n\n# A tibble: 6 × 20\n   year school     seed conference conf_wins conf_losses conf_wins_pct conf_rank\n  &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n1  1982 Arizona …     4 Western C…        NA          NA          NA          NA\n2  1982 Auburn        7 Southeast…        NA          NA          NA          NA\n3  1982 Cheyney       2 Independe…        NA          NA          NA          NA\n4  1982 Clemson       5 Atlantic …         6           3          66.7         4\n5  1982 Drake         4 Missouri …        NA          NA          NA          NA\n6  1982 East Car…     6 Independe…        NA          NA          NA          NA\n# ℹ 12 more variables: division &lt;chr&gt;, reg_wins &lt;dbl&gt;, reg_losses &lt;dbl&gt;,\n#   reg_wins_pct &lt;dbl&gt;, bid &lt;chr&gt;, first_game_at_home &lt;chr&gt;,\n#   tourney_wins &lt;dbl&gt;, tourney_losses &lt;dbl&gt;, tourney_finish &lt;chr&gt;,\n#   total_wins &lt;dbl&gt;, total_losses &lt;dbl&gt;, total_wins_pct &lt;dbl&gt;\n\n\nNote that, the seed = 0 designation in 1983 notes the eight teams that played an opening-round game to become the No.8 seed in each region. For this exercise, we will not take them into consideration. Since seed is an ordinal categorical variable, we can set it as an ordered factor.\n\nmarchmadness &lt;- marchmadness |&gt; \n  filter(seed != 0)\n\n\n\n2. Exploratory Data Analysis\nWe can see which seeds appear more often.\n\nseed_count &lt;- marchmadness |&gt; \n  count(seed) |&gt; \n  arrange(desc(n)) |&gt;\n  mutate(seed = factor(seed, levels = seed))\n\nggplot(\n  seed_count, \n  aes(x = seed, y = n)\n  ) +\n  geom_col(fill = \"skyblue2\") +\n  labs(\n    title = \"Distribution of Tournament Seeds\",\n    x = \"Seed\",\n    y = \"Number of Teams\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can also take a look at the average tournament wins for each seed:\n\nmarchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  group_by(seed) |&gt; \n  summarise(\n    avg_tourney_wins = mean(tourney_wins, na.rm = TRUE)\n    ) |&gt;\n  arrange(desc(avg_tourney_wins)) |&gt;\n  mutate(seed = factor(seed, levels = seed)) |&gt;\n  ggplot(\n    aes(\n      x = as.factor(seed),\n      y = avg_tourney_wins)\n    ) +\n  geom_col(fill = \"skyblue2\") +\n  labs(\n    title = \"Average Tournament Wins by Seed\",\n    x = \"Seed\",\n    y = \"Avg. Tourney Wins\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can note that a teams with a higher seed tend to win more tournaments! We can also see the total amount of tourney wins for each seed.\n\nseed_order &lt;- marchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  group_by(seed) |&gt; \n  summarise(avg_wins = mean(tourney_wins, na.rm = TRUE)) |&gt; \n  arrange(desc(avg_wins)) |&gt; \n  pull(seed)\n\nmarchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  mutate(seed = factor(seed, levels = seed_order)) |&gt; \n  ggplot(\n    aes(x = seed, y = tourney_wins)\n  ) +\n  geom_violin(fill = \"skyblue2\") +\n  labs(\n    title = \"Distribution of Tournament Wins by Seed\",\n    x = \"Seed\",\n    y = \"Tournament Wins\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3. Hypothesis Testing: Are Seed and Wins Associated?\n\\(H_0\\)(Null): Seed and tournament wins are not associated\n\\(H_a\\)(Alternative): Seed and tournament wins are associated\n\ncor.test(marchmadness$seed, marchmadness$tourney_wins, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  marchmadness$seed and marchmadness$tourney_wins\nS = 2602468566, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.7252169 \n\n\nWe can note that from this correlation test, with a P-value below 0.05, we can reject the null hypothesis, denoting that seed and wins are likely associated. The strong negative Spearman’s rho suggests that lower seeds tend to win significantly more tournament games, as was confirmed from our exploratory analysis.\nThis can be visualized with the following plot:\n\nggplot(marchmadness, aes(x = seed, y = tourney_wins)) +\n  geom_jitter(width = 0.2, height = 0.2, alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"skyblue2\") +\n  labs(title = \"Seed vs Tournament Wins\",\n       x = \"Seed\",\n       y = \"Tournament Wins\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHowever, we can note that given that we’re setting tourney_wins as a response, our linear regression model may output negative values at high seed values. Therefore, a Poisson Regression model is better suited, considering that tourney wins is a count variable and is always non-negative.\n\npoisson_model &lt;- glm(tourney_wins ~ seed, family = \"poisson\", data = marchmadness)\nsummary(poisson_model)\n\n\nCall:\nglm(formula = tourney_wins ~ seed, family = \"poisson\", data = marchmadness)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.454260   0.035992   40.41   &lt;2e-16 ***\nseed        -0.260116   0.007231  -35.97   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3438.8  on 2083  degrees of freedom\nResidual deviance: 1610.3  on 2082  degrees of freedom\nAIC: 4238.8\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nmarchmadness$predicted_wins &lt;- predict(poisson_model, type = \"response\")\n\nmodel_plot &lt;- ggplot(marchmadness, aes(x = seed, y = tourney_wins)) +\n  geom_jitter(width = 0.3, alpha = 0.5) +\n  geom_line(aes(y = predicted_wins), color = \"skyblue2\", linewidth = 1.2) +\n  labs(title = \"Poisson Regression: Predicted Tournament Wins by Seed\",\n       x = \"Seed\",\n       y = \"Tournament Wins\") +\n  theme_minimal()\n\nmodel_plot\n\n\n\n\n\n\n\n\nThe seed coefficient \\(\\beta_1 = -0.2501\\) represents the log change in the expected number of tournament wins for every 1 unit increase in seed.\n\nexp(poisson_model$coefficients[\"seed\"])\n\n     seed \n0.7709619 \n\n\nThis means that for every increase in seed by 1, the expected tournament wins decreases by about 23% ( as 1-0.77 = 0.23)\n\n\n4. Overdispersion Testing\nIt is noteworthy that Poisson assumes that the mean is equal to the variance of the count variable. If the variance is much greater, we might need a Negative Binomial model. We can do an dispersion test to evaluate this matter.\nLetting \\(Y_i\\) be the \\(ith\\) Poisson response in the count regression model, in the presence of equidispersion, \\(Y_i\\) has the following parameters:\n\\(E(Y_i)=\\lambda_i, Var(Y_i)=\\lambda_i\\)\nThe test uses the following mathematical expression (using a \\(1+\\gamma\\) dispersion factor):\n\\(Var(Y_i)=(1+\\gamma)*\\lambda_i\\)\nwith the hypotheses:\n\\(H_0:1 + \\gamma = 1\\)\n\\(H_a: 1 + \\gamma &gt; 1\\)\nWhen there is evidence of overdispersion in our data, we will reject \\(H_o\\).\n\nlibrary(AER)\n\ndispersiontest(poisson_model)\n\n\n    Overdispersion test\n\ndata:  poisson_model\nz = -1.01, p-value = 0.8437\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n 0.9484459 \n\n\nSince the P-value (0.8437) is much greater than 0.05, we fail to reject the null hypothesis. This suggests that there is no significant evidence of overdispersion in the Poisson model.\n\n\n5. One Major Assumption…\nNote that throughout this analysis, we’ve made one big assumption: we have used seed as a numeric predictor. This assumes that the effect of seed is linear on the log scaled of the amount of tourney_wins.\n\nclass(marchmadness$seed)\n\n[1] \"numeric\"\n\n\nTo test if this assumption is appropraite, we can compare models that make different assumptions about seed.\nWe can create an equivalent Poisson model, but now, we can treat seed as a factor.\n\npoisson_model_factor &lt;- glm(tourney_wins ~ as.factor(as.character(seed)), family = \"poisson\", data = marchmadness)\nsummary(poisson_model_factor)\n\n\nCall:\nglm(formula = tourney_wins ~ as.factor(as.character(seed)), family = \"poisson\", \n    data = marchmadness)\n\nCoefficients:\n                                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                       1.24796    0.04390  28.430  &lt; 2e-16 ***\nas.factor(as.character(seed))10  -2.10541    0.14066 -14.969  &lt; 2e-16 ***\nas.factor(as.character(seed))11  -2.08421    0.14546 -14.329  &lt; 2e-16 ***\nas.factor(as.character(seed))12  -2.72794    0.19401 -14.061  &lt; 2e-16 ***\nas.factor(as.character(seed))13  -3.64585    0.33621 -10.844  &lt; 2e-16 ***\nas.factor(as.character(seed))14 -19.55054  574.63360  -0.034    0.973    \nas.factor(as.character(seed))15 -19.55054  571.75322  -0.034    0.973    \nas.factor(as.character(seed))16  -4.47678    0.50192  -8.919  &lt; 2e-16 ***\nas.factor(as.character(seed))2   -0.33849    0.06831  -4.955 7.23e-07 ***\nas.factor(as.character(seed))3   -0.66466    0.07531  -8.825  &lt; 2e-16 ***\nas.factor(as.character(seed))4   -0.79843    0.07898 -10.110  &lt; 2e-16 ***\nas.factor(as.character(seed))5   -1.25469    0.09319 -13.464  &lt; 2e-16 ***\nas.factor(as.character(seed))6   -1.41008    0.09963 -14.153  &lt; 2e-16 ***\nas.factor(as.character(seed))7   -1.56977    0.10576 -14.842  &lt; 2e-16 ***\nas.factor(as.character(seed))8   -1.90626    0.12500 -15.250  &lt; 2e-16 ***\nas.factor(as.character(seed))9   -1.87466    0.12733 -14.723  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3438.8  on 2083  degrees of freedom\nResidual deviance: 1534.5  on 2068  degrees of freedom\nAIC: 4191\n\nNumber of Fisher Scoring iterations: 16\n\n\nWe can visualize how the two models fit the data to evaluate if treating seed as numeric or factor would have a significant impact on our modelling process.\n\nmarchmadness &lt;- marchmadness |&gt; \n  mutate(\n    Numeric_Seed = predict(poisson_model, type = \"response\"),\n    Factor_Seed = predict(poisson_model_factor, type = \"response\")\n  )\n\nplot_data &lt;- marchmadness |&gt; \n  select(seed, tourney_wins, Numeric_Seed, Factor_Seed) |&gt; \n  pivot_longer(cols = c(\"Numeric_Seed\",\"Factor_Seed\"), names_to = \"model\", values_to = \"predicted\")\n\nggplot(plot_data, aes(x = seed, y = predicted, color = model)) +\n  geom_point(aes(y = tourney_wins), alpha = 0.3, color = \"black\") +\n  geom_line(stat = \"smooth\", method = \"loess\", se = FALSE, linewidth = 1.2) +\n  labs(title = \"Predicted Tournament Wins by Seed\",\n       x = \"Seed\",\n       y = \"Predicted Wins\",\n       color = \"Model\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHowever, is we wanted to formally evaluate which is the better approach we could use likelihood-based model selection tools.\n\nlibrary(broom)\n\nglance(poisson_model)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         3439.    2083 -2117. 4239. 4250.    1610.        2082  2084\n\nglance(poisson_model_factor)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         3439.    2083 -2080. 4191. 4281.    1535.        2068  2084\n\n\nBased on lower residual deviance, higher log-likelihood, and a lower AIC, the model that treats seed as a factor fits the data better. This would suggest that the relationship between tournament seed and number of wins is not linear, and would support using an approach that does not assume a constant effect per unit change in seed.\n\n\n6. Discussion\nThis analysis examined the relationship between a team’s tournament seed and its performance in the NCAA Division I Women’s Basketball Tournament. The results suggest that:\n\nSeed strongly predicts performance: Lower-numbered seeds (higher-ranked teams) tend to win more games on average. The correlation between seed and wins was statistically significant, with higher seeds associated with fewer wins.\nPoisson regression supports seeding as a predictor: The Poisson regression model confirmed that seed is a significant predictor of tournament wins, as expected for a count variable like wins.\nModel assumptions are key: Treating seed as a numeric variable assumes a linear effect across all seed values, which oversimplifies the relationship with the outcome. Ensuring that explanatory variables are approapriately coded is key. In this case, the influence of seeds could be described as slightly non-linear, which opens the door to discussion over model selection.\nThere is a lot of variation around the prediction: While seeding generally reflects team strength, upsets and unexpected performances do occur, showing that other factors also influence tournament outcomes.\n\nSeeding is an important predictor of success, but clearly other factors influence the results. It sets expectations, but unexpected performances still shape March Madness."
  },
  {
    "objectID": "website_files/grid_items/wildfire.html",
    "href": "website_files/grid_items/wildfire.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Wildfire\n\n\nDescription: This data set on Canadian wildfires includes data on fire size, cause, location, detection method, response, and weather. Collected from official sources, it supports wildfire risk assessment and response. It also highlights social and geographic disparities, emphasizing impacts on remote and underserved communities facing climate-related and infrastructure challenges.\n\nMore Details"
  },
  {
    "objectID": "website_files/grid_items/indigenousbusiness.html",
    "href": "website_files/grid_items/indigenousbusiness.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Indigenous Businesses\n\n\nDescription: XXX\n\nMore Details"
  },
  {
    "objectID": "website_files/grid_items/globalrights.html",
    "href": "website_files/grid_items/globalrights.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Global Rights\n\n\nDescription: XXX\n\nMore Details"
  },
  {
    "objectID": "website_files/description_pages/wildfire.html",
    "href": "website_files/description_pages/wildfire.html",
    "title": "Historical Canadian Wildfire Data",
    "section": "",
    "text": "Dataset including information on wildfires in the province of Alberta from 2006 to 2024, inclusive. Information tracked for each fire includes: cause, size, location (latitude and longitude, legal land description, and forest area), time and duration, weather conditions, staffing and physical resources used to suppress the fire, and area burned.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nwildfire.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nClimate Change\n\n\nAssociated Tasks\n\n\nClassification, Time Series, Geospatial Analysis\n\n\nFeature Type\n\n\nCategorical, Integer\n\n\nInstances\n\n\n26551 records\n\n\nFeatures\n\n\n50\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nASSESSMENT_HECTARES\nFeature\nFloat\nFire Size\nHectares\nNo\n\n\nTRUE_CAUSE\nFeature\nCategorical\nInsufficient Resources, Insufficient Buffer, Winter Burning, Incendiary Device, Permit Related, Friction Spark, Hot Exhaust, Unclassified, Burning Substance, Arson Suspected, Unattended Fire, Unpredictable Event, Mechanical Failure, Abandoned Fire, Vehicle Fire, Unsafe Fire, Line Impact, High Hazard, Flammable Fluids, Arson Known, Animals\n-\nNo"
  },
  {
    "objectID": "website_files/description_pages/wildfire.html#data-set-information",
    "href": "website_files/description_pages/wildfire.html#data-set-information",
    "title": "Historical Canadian Wildfire Data",
    "section": "",
    "text": "Dataset including information on wildfires in the province of Alberta from 2006 to 2024, inclusive. Information tracked for each fire includes: cause, size, location (latitude and longitude, legal land description, and forest area), time and duration, weather conditions, staffing and physical resources used to suppress the fire, and area burned.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nwildfire.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nClimate Change\n\n\nAssociated Tasks\n\n\nClassification, Time Series, Geospatial Analysis\n\n\nFeature Type\n\n\nCategorical, Integer\n\n\nInstances\n\n\n26551 records\n\n\nFeatures\n\n\n50\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nASSESSMENT_HECTARES\nFeature\nFloat\nFire Size\nHectares\nNo\n\n\nTRUE_CAUSE\nFeature\nCategorical\nInsufficient Resources, Insufficient Buffer, Winter Burning, Incendiary Device, Permit Related, Friction Spark, Hot Exhaust, Unclassified, Burning Substance, Arson Suspected, Unattended Fire, Unpredictable Event, Mechanical Failure, Abandoned Fire, Vehicle Fire, Unsafe Fire, Line Impact, High Hazard, Flammable Fluids, Arson Known, Animals\n-\nNo"
  },
  {
    "objectID": "website_files/description_pages/wildfire.html#about-the-data",
    "href": "website_files/description_pages/wildfire.html#about-the-data",
    "title": "Historical Canadian Wildfire Data",
    "section": "About the Data",
    "text": "About the Data\nThis dataset contains information on wildfires in Canada, compiled from official government sources.\n\nKey Features of the Dataset\n\nFire size (in hectares)\nCause of fire (e.g., lightning, human activity)\nDetection method\nResponse team size\nLatitude/longitude of the fire\nWeather conditions at the time of fire\n\n\n\nPurpose and Use Cases\nThe data was collected to monitor, assess, and respond to wildfire risks across regions. Wildfires have significant environmental, social, and economic impacts—especially for remote, Indigenous, and underserved communities that may lack the infrastructure to respond effectively.\nFrom an equity and inclusion perspective, studying wildfire data can help identify geographic and resource disparities in fire detection and containment efforts, as well as the disproportionate risks certain populations face due to climate change and infrastructure gaps."
  },
  {
    "objectID": "website_files/description_pages/wildfire.html#case-study",
    "href": "website_files/description_pages/wildfire.html#case-study",
    "title": "Historical Canadian Wildfire Data",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nCan we identify the environmental and human factors most associated with large wildfires (&gt;10 hectares)?\nThe goal is to explore potential predictors of fire size, such as weather, fire cause, and detection method, and provide insights that could inform early interventions and resource planning.\n\n\nMethodology\n\n1. Data Cleaning & Processing\n\nConverted fire size to numeric\nCreated a binary variable large_fire (TRUE if &gt;10 ha)\nFiltered out incomplete records\n\n\n\n2. Exploratory Data Analysis (EDA)\nFire Size Distribution\n\nlibrary(ggplot2)\n\nggplot(wildfire_clean, aes(x = ASSESSMENT_HECTARES)) +\n  geom_histogram(bins = 40) +\n  scale_x_log10() +\n  labs(\n    title = \"Distribution of Fire Size (Assessment Hectares)\",\n    x = \"Fire Size (log scale)\",\n    y = \"Number of Fires\"\n  )\n\n\n\n\n\n\n\n\nProportion of Large Fires by Cause\n\nwildfire_clean %&gt;%\n  group_by(TRUE_CAUSE) %&gt;%\n  summarize(prop_large = mean(large_fire, na.rm = TRUE)) %&gt;%\n  ggplot(aes(x = reorder(TRUE_CAUSE, prop_large), y = prop_large)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Proportion of Large Fires by True Cause\",\n    x = \"True Cause\",\n    y = \"Proportion of Fires &gt; 10 ha\"\n  )\n\n\n\n\n\n\n\n\n\n\n3. Logistic Regression Model\nWe build a logistic regression model to predict the likelihood of a fire becoming large based on temperature, wind speed, and cause.\n\nlibrary(broom)\n\nmodel &lt;- glm(\n  large_fire ~ TEMPERATURE + WIND_SPEED + TRUE_CAUSE + DETECTION_AGENT_TYPE,\n  data = wildfire_clean,\n  family = \"binomial\"\n)\n\n\n# Tidy and clean model output\ntidy_model &lt;- broom::tidy(model) %&gt;%\n  dplyr::mutate(\n    estimate = round(estimate, 3),\n    std.error = round(std.error, 3),\n    statistic = round(statistic, 2),\n    p.value = round(p.value, 4)\n  )\n\n# Create a nice table\ngt_table &lt;- tidy_model %&gt;%\n  gt::gt() %&gt;%\n  gt::tab_header(\n    title = \"Logistic Regression Results\",\n    subtitle = \"Predicting Large Fires (&gt; 10 ha)\"\n  ) %&gt;%\n  gt::cols_label(\n    term = \"Variable\",\n    estimate = \"Estimate (Log-Odds)\",\n    std.error = \"Std. Error\",\n    statistic = \"z value\",\n    p.value = \"p-value\"\n  ) %&gt;%\n  gt::fmt_missing(everything(), missing_text = \"-\") %&gt;%\n  gt::tab_options(\n    table.font.size = \"small\",\n    data_row.padding = gt::px(4),\n    heading.title.font.size = 16,\n    heading.subtitle.font.size = 12\n  )\n\ngt_table\n\n\n\n\n\n\n\nLogistic Regression Results\n\n\nPredicting Large Fires (&gt; 10 ha)\n\n\nVariable\nEstimate (Log-Odds)\nStd. Error\nz value\np-value\n\n\n\n\n(Intercept)\n-4.262\n0.512\n-8.32\n0.0000\n\n\nTEMPERATURE\n-0.040\n0.012\n-3.22\n0.0013\n\n\nWIND_SPEED\n0.051\n0.007\n7.01\n0.0000\n\n\nTRUE_CAUSEAnimals\n-15.465\n2121.042\n-0.01\n0.9942\n\n\nTRUE_CAUSEArson Known\n-16.045\n2200.700\n-0.01\n0.9942\n\n\nTRUE_CAUSEArson Suspected\n-0.219\n0.671\n-0.33\n0.7443\n\n\nTRUE_CAUSEBurning Substance\n-0.016\n0.450\n-0.04\n0.9716\n\n\nTRUE_CAUSEFlammable Fluids\n-16.016\n4207.738\n0.00\n0.9970\n\n\nTRUE_CAUSEFriction Spark\n0.401\n0.678\n0.59\n0.5541\n\n\nTRUE_CAUSEHigh Hazard\n-16.284\n1926.733\n-0.01\n0.9933\n\n\nTRUE_CAUSEHot Exhaust\n0.346\n0.793\n0.44\n0.6628\n\n\nTRUE_CAUSEIncendiary Device\n0.489\n1.075\n0.45\n0.6492\n\n\nTRUE_CAUSEInsufficient Buffer\n0.231\n0.514\n0.45\n0.6531\n\n\nTRUE_CAUSEInsufficient Resources\n3.811\n1.241\n3.07\n0.0021\n\n\nTRUE_CAUSELine Impact\n-2.123\n1.069\n-1.99\n0.0470\n\n\nTRUE_CAUSEMechanical Failure\n-0.532\n0.790\n-0.67\n0.5011\n\n\nTRUE_CAUSEPermit Related\n0.326\n0.425\n0.77\n0.4439\n\n\nTRUE_CAUSEUnattended Fire\n0.041\n1.064\n0.04\n0.9696\n\n\nTRUE_CAUSEUnclassified\n0.375\n0.791\n0.47\n0.6355\n\n\nTRUE_CAUSEUnpredictable Event\n-0.738\n0.800\n-0.92\n0.3562\n\n\nTRUE_CAUSEUnsafe Fire\n-0.146\n0.401\n-0.36\n0.7161\n\n\nTRUE_CAUSEVehicle Fire\n-0.631\n1.060\n-0.60\n0.5516\n\n\nTRUE_CAUSEWinter Burning\n0.433\n0.454\n0.95\n0.3409\n\n\nDETECTION_AGENT_TYPEGRP\n-16.143\n438.705\n-0.04\n0.9706\n\n\nDETECTION_AGENT_TYPELKT\n0.023\n0.371\n0.06\n0.9502\n\n\nDETECTION_AGENT_TYPEUNP\n-0.613\n0.363\n-1.69\n0.0907\n\n\n\n\n\n\n\n\n\n4. Discussion\nThe logistic regression model revealed that higher wind speeds are strongly associated with an increased likelihood of a fire becoming large (over 10 hectares), consistent with our expectations about fire spread dynamics.\nSurprisingly, temperature showed a small negative association with fire size, though this may be influenced by interactions with other environmental factors like humidity or fuel type.\nAmong causes, “Insufficient Resources” and “Line Impact” were associated with significantly higher odds of large fires. This suggests that both human-related limitations and infrastructure vulnerability (like power lines) play a role in fire escalation.\nThe detection agent type showed weak evidence that fires detected by UNP agents may be less likely to become large, compared to FPD Staff, but the effect was not statistically strong (p = 0.09). Further exploration is needed here, especially considering the early intervention ability of different detection teams.\nThese findings provide insights into key environmental and operational factors influencing wildfire severity. Importantly, they point to the need for targeted mitigation strategies in areas with poor detection access or high infrastructure risks.\nIn the broader context of equity, this analysis reinforces that resource constraints and delayed detection—often more common in remote or underfunded regions—can amplify wildfire impacts. Data-informed strategies can help ensure more equitable protection against climate-driven disasters.\n\n\n5. Interpretation Boost using marginaleffects\nWind Speed\nAs wind speed increases, the model estimates a higher probability of a fire becoming large (&gt;10 hectares). However, the variability in the predicted probabilities also increases at higher wind speeds, as indicated by the wider confidence intervals. This suggests that while there is a general upward trend, the model’s certainty about the exact magnitude of the effect decreases in this range—likely due to fewer observations or greater variability in fire outcomes at high wind speeds.\n\nlibrary(marginaleffects)\n\nWarning: package 'marginaleffects' was built under R version 4.4.3\n\n## continuous variable\nplot_predictions(\n  model,\n  by = \"WIND_SPEED\"\n)\n\n\n\n\n\n\n\n\nTemperature\nAs temperature increases, the model predicts a relatively stable probability of a fire becoming large. The trend line flattens and the confidence intervals narrow, indicating that the model is more confident and consistent in its estimates across higher temperature ranges. This suggests that the relationship between temperature and fire size is more stable and predictable at higher temperatures, possibly due to a larger number of observations or less variability in outcomes.\n\n## continuous variable \"TEMPERATURE\"\n\nplot_predictions(\n  model,\n  by = \"TEMPERATURE\"\n)\n\n\n\n\n\n\n\n\nTrue Cause\nThe predicted probability of a large fire is near zero for most TRUE_CAUSE categories, indicating that these causes (e.g., natural ignition, campfires, equipment use) are generally not associated with large-scale fires. However, the category “Insufficient Resources” stands out with a significantly higher predicted probability and a wide confidence interval. This suggests that fires classified under this cause are much more likely to become large, though the wide interval reflects substantial uncertainty — likely due to a small number of observations in that category.\n\n## categorical variable \"TRUE_CAUSE\"\nplot_predictions(model, by = \"TRUE_CAUSE\") +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1)) +\n  ggplot2::labs(\n    title = \"Predicted Probability of Large Fire by True Cause\",\n    x = \"True Cause\",\n    y = \"Predicted Probability\"\n  )\n\n\n\n\n\n\n\n\nDetection Agent Type\nAlthough fires detected by AIR agents appear more likely to become large, the model is relatively uncertain about this pattern. The wide confidence interval indicates that this result should be interpreted cautiously, and may reflect data sparsity or high variability in fire outcomes for AIR-detected cases.\n\n## categorical variable \"DETECTION_AGENT_TYPE\"\nplot_predictions(\n  model,\n  by = \"DETECTION_AGENT_TYPE\"\n)"
  },
  {
    "objectID": "website_files/description_pages/wildfire.html#attribution",
    "href": "website_files/description_pages/wildfire.html#attribution",
    "title": "Historical Canadian Wildfire Data",
    "section": "Attribution",
    "text": "Attribution\nData sourced from the Government of Alberta via the Government of Canada’s Open Government Portal, available under an Open Government Licence - Alberta. Original dataset: Historical wildfire data: 2006-2024."
  },
  {
    "objectID": "website_files/description_pages/hcmst.html",
    "href": "website_files/description_pages/hcmst.html",
    "title": "How Couples Meet and Stay Together",
    "section": "",
    "text": "The 2022 wave of the How Couples Meet and Stay Together (HCMST) study surveyed 1,722 U.S. adults to explore how relationships form and changed with time . Conducted by Ipsos, led by researchers from Stanford University, the survey focused on dating habits and the impact of the COVID-19 pandemic on relationships. Adapted from the original data set, this data offers a look at how social changes have changed how couples meet and stay together.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nhcmst.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nFamily and Relationships\n\n\nAssociated Tasks\n\n\nClassification\n\n\nFeature Type\n\n\nFactor, Integer, Numeric\n\n\nInstances\n\n\n1328\n\n\nFeatures\n\n\n21\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nsubject_age\nFeature\nNumeric\nSubject age\nyears\nNo\n\n\nsubject_education\nFeature\nOrdinal Categorical\nHighest degree obtained. Ordered categories: [‘no_education’ &lt; ‘1st_4th_grade’ &lt; ‘5th_6th_grade’ &lt; ‘7th_8th_grade’ &lt; ‘9th’ &lt; ‘10th’ &lt; ‘11th’ &lt; ‘12th_nodiploma’ &lt; ‘high_school_grad’ &lt; ‘some_college’ &lt; ‘associate_degree’ &lt; ‘bach_degree’ &lt; ‘masters_degree’ &lt; ‘prof_doct_degree’]\n-\nNo\n\n\nsubject_sex\nFeature\nNominal Categorical\nLevels: [‘male’, ‘female’, ‘other’]\n-\nNo\n\n\nsubject_ethnicity\nFeature\nNominal Categorical\nLevels: [‘white’, ‘black’, ‘other’, ‘hispanic’, ‘2_plus_eth’]\n-\nNo\n\n\nsubject_income_category\nFeature\nOrdinal Categorical\nOrdered categories: [‘under_5k’ &lt; ‘5k_7k’ &lt; ‘7k_10k’ &lt; ‘10k_12k’ &lt; ‘12k_15k’ &lt; ‘15k_20k’ &lt; ‘20k_25k’ &lt; ‘25k_30k’ &lt; ‘30k_35k’ &lt; ‘35k_40k’ &lt; ‘40k_50k’ &lt; ‘50k_60k’ &lt; ‘60k_75k’ &lt; ‘75k_85k’ &lt; ‘85k_100k’ &lt; ‘100k_125k’ &lt; ‘125k_150k’ &lt; ‘150k_175k’ &lt; ‘175k_200k’ &lt; ‘200k_250k’ &lt; ‘over_250k’]\ndollars\nNo\n\n\nsubject_employment_status\nFeature\nNominal Categorical\nLevels: [‘working_paid_employee’, ‘working_self_employed’, ‘not_working_temp_layoff’, ‘not_working_looking’, ‘not_working_retired’, ‘not_working_disabled’, ‘not_working_other’]\n-\nNo\n\n\nsame_sex_couple\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\nmarried\nFeature\nNominal Categorical\nLevels: [‘not_married’, ‘married’]\n-\nYes\n\n\nsex_frequency\nFeature\nOrdinal Categorical\nOrdered categories: [‘once_or_more_a_day’ &lt; ‘3_to_6_times_a_week’ &lt; ‘once_or_twice_a_week’ &lt; ‘2_to_3_times_a_month’ &lt; ‘once_a_month_or_less’]\n-\nYes\n\n\nflirts_with_partner\nFeature\nOrdinal Categorical\nOrdered categories: [‘every_day’ &lt; ‘a_few_times_a_week’ &lt; ‘once_a_week’ &lt; ‘1_to_3_times_a_month’ &lt; ‘less_than_once_a_month’ &lt; ‘never’]\n-\nYes\n\n\nfights_with_partner\nFeature\nOrdinal Categorical\nOrdered categories: [‘0_times’ &lt; ‘1_time’ &lt; ‘2_times’ &lt; ‘3_times’ &lt; ‘4_times’ &lt; ‘5_times’ &lt; ‘6_times’ &lt; ‘7_or_more_times’]\nAmount in the last 7 days\nYes\n\n\nrelationship_duration\nFeature\nNumeric\nDuration of relationship\nyears\nYes\n\n\nchildren\nFeature\nNumeric\nNumber of children in the household.\n-\nNo\n\n\nrel_change_during_pandemic\nFeature\nNominal Categorical\nLevels: [‘better_than_before’, ‘no_change’, ‘worse_than_before’]\n-\nNo\n\n\ninc_change_during_pandemic\nFeature\nOrdinal Categorical\nOrdered categories: [‘much_worse’ &lt; ‘worse’ &lt; ‘no_change’ &lt; ‘better’ &lt; ‘much_better’]\n-\nYes\n\n\nsubject_had_covid\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\npartner_had_covid\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\nsubject_vaccinated\nFeature\nNominal Categorical\nLevels: [‘fully_vaccinated_and_booster’, ‘fully_vaccinated_no_booster’, ‘partially_vaccinated’, ‘not_vaccinated’]\n-\nYes\n\n\npartner_vaccinated\nFeature\nNominal Categorical\nLevels: [‘fully_vaccinated_and_booster’, ‘fully_vaccinated_no_booster’, ‘partially_vaccinated’, ‘not_vaccinated’]\n-\nYes\n\n\nagree_covid_approach\nFeature\nNominal Categorical\nLevels: [‘completely_agree’, ‘mostly_agree’, ‘mostly_disagree’, ‘completely_disagree’]\n-\nYes\n\n\nrelationship_quality\nTarget\nOrdinal Categorical\nLevels: [‘excellent’ &lt; ‘good’ &lt; ‘fair’ &lt; ‘poor’ &lt; ‘very_poor’]\n-\nNo"
  },
  {
    "objectID": "website_files/description_pages/hcmst.html#data-set-information",
    "href": "website_files/description_pages/hcmst.html#data-set-information",
    "title": "How Couples Meet and Stay Together",
    "section": "",
    "text": "The 2022 wave of the How Couples Meet and Stay Together (HCMST) study surveyed 1,722 U.S. adults to explore how relationships form and changed with time . Conducted by Ipsos, led by researchers from Stanford University, the survey focused on dating habits and the impact of the COVID-19 pandemic on relationships. Adapted from the original data set, this data offers a look at how social changes have changed how couples meet and stay together.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nhcmst.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nFamily and Relationships\n\n\nAssociated Tasks\n\n\nClassification\n\n\nFeature Type\n\n\nFactor, Integer, Numeric\n\n\nInstances\n\n\n1328\n\n\nFeatures\n\n\n21\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nsubject_age\nFeature\nNumeric\nSubject age\nyears\nNo\n\n\nsubject_education\nFeature\nOrdinal Categorical\nHighest degree obtained. Ordered categories: [‘no_education’ &lt; ‘1st_4th_grade’ &lt; ‘5th_6th_grade’ &lt; ‘7th_8th_grade’ &lt; ‘9th’ &lt; ‘10th’ &lt; ‘11th’ &lt; ‘12th_nodiploma’ &lt; ‘high_school_grad’ &lt; ‘some_college’ &lt; ‘associate_degree’ &lt; ‘bach_degree’ &lt; ‘masters_degree’ &lt; ‘prof_doct_degree’]\n-\nNo\n\n\nsubject_sex\nFeature\nNominal Categorical\nLevels: [‘male’, ‘female’, ‘other’]\n-\nNo\n\n\nsubject_ethnicity\nFeature\nNominal Categorical\nLevels: [‘white’, ‘black’, ‘other’, ‘hispanic’, ‘2_plus_eth’]\n-\nNo\n\n\nsubject_income_category\nFeature\nOrdinal Categorical\nOrdered categories: [‘under_5k’ &lt; ‘5k_7k’ &lt; ‘7k_10k’ &lt; ‘10k_12k’ &lt; ‘12k_15k’ &lt; ‘15k_20k’ &lt; ‘20k_25k’ &lt; ‘25k_30k’ &lt; ‘30k_35k’ &lt; ‘35k_40k’ &lt; ‘40k_50k’ &lt; ‘50k_60k’ &lt; ‘60k_75k’ &lt; ‘75k_85k’ &lt; ‘85k_100k’ &lt; ‘100k_125k’ &lt; ‘125k_150k’ &lt; ‘150k_175k’ &lt; ‘175k_200k’ &lt; ‘200k_250k’ &lt; ‘over_250k’]\ndollars\nNo\n\n\nsubject_employment_status\nFeature\nNominal Categorical\nLevels: [‘working_paid_employee’, ‘working_self_employed’, ‘not_working_temp_layoff’, ‘not_working_looking’, ‘not_working_retired’, ‘not_working_disabled’, ‘not_working_other’]\n-\nNo\n\n\nsame_sex_couple\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\nmarried\nFeature\nNominal Categorical\nLevels: [‘not_married’, ‘married’]\n-\nYes\n\n\nsex_frequency\nFeature\nOrdinal Categorical\nOrdered categories: [‘once_or_more_a_day’ &lt; ‘3_to_6_times_a_week’ &lt; ‘once_or_twice_a_week’ &lt; ‘2_to_3_times_a_month’ &lt; ‘once_a_month_or_less’]\n-\nYes\n\n\nflirts_with_partner\nFeature\nOrdinal Categorical\nOrdered categories: [‘every_day’ &lt; ‘a_few_times_a_week’ &lt; ‘once_a_week’ &lt; ‘1_to_3_times_a_month’ &lt; ‘less_than_once_a_month’ &lt; ‘never’]\n-\nYes\n\n\nfights_with_partner\nFeature\nOrdinal Categorical\nOrdered categories: [‘0_times’ &lt; ‘1_time’ &lt; ‘2_times’ &lt; ‘3_times’ &lt; ‘4_times’ &lt; ‘5_times’ &lt; ‘6_times’ &lt; ‘7_or_more_times’]\nAmount in the last 7 days\nYes\n\n\nrelationship_duration\nFeature\nNumeric\nDuration of relationship\nyears\nYes\n\n\nchildren\nFeature\nNumeric\nNumber of children in the household.\n-\nNo\n\n\nrel_change_during_pandemic\nFeature\nNominal Categorical\nLevels: [‘better_than_before’, ‘no_change’, ‘worse_than_before’]\n-\nNo\n\n\ninc_change_during_pandemic\nFeature\nOrdinal Categorical\nOrdered categories: [‘much_worse’ &lt; ‘worse’ &lt; ‘no_change’ &lt; ‘better’ &lt; ‘much_better’]\n-\nYes\n\n\nsubject_had_covid\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\npartner_had_covid\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\nsubject_vaccinated\nFeature\nNominal Categorical\nLevels: [‘fully_vaccinated_and_booster’, ‘fully_vaccinated_no_booster’, ‘partially_vaccinated’, ‘not_vaccinated’]\n-\nYes\n\n\npartner_vaccinated\nFeature\nNominal Categorical\nLevels: [‘fully_vaccinated_and_booster’, ‘fully_vaccinated_no_booster’, ‘partially_vaccinated’, ‘not_vaccinated’]\n-\nYes\n\n\nagree_covid_approach\nFeature\nNominal Categorical\nLevels: [‘completely_agree’, ‘mostly_agree’, ‘mostly_disagree’, ‘completely_disagree’]\n-\nYes\n\n\nrelationship_quality\nTarget\nOrdinal Categorical\nLevels: [‘excellent’ &lt; ‘good’ &lt; ‘fair’ &lt; ‘poor’ &lt; ‘very_poor’]\n-\nNo"
  },
  {
    "objectID": "website_files/description_pages/hcmst.html#about-the-data",
    "href": "website_files/description_pages/hcmst.html#about-the-data",
    "title": "How Couples Meet and Stay Together",
    "section": "About the Data",
    "text": "About the Data\nX\n\nKey Features of the Dataset\nX\n\n\nPurpose and Use Cases\nX"
  },
  {
    "objectID": "website_files/description_pages/hcmst.html#case-study",
    "href": "website_files/description_pages/hcmst.html#case-study",
    "title": "How Couples Meet and Stay Together",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nX\n\n\nMethodology\n\n1. Data Cleaning & Processing\n\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Reading Data\nhcmst &lt;- read_csv(\"../../data/clean/hcmst.csv\") \n\nRows: 1328 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (18): subject_education, subject_sex, subject_ethnicity, subject_income_...\ndbl  (3): subject_age, relationship_duration, children\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Review total rows\nnrow(hcmst)\n\n[1] 1328\n\n# Removing NA since we plan on using all columns in our analysis\nhcmst &lt;- hcmst |&gt; \n  drop_na()\n\n# Notice no rows were removed\nnrow(hcmst)\n\n[1] 1192\n\n# Visualize the data set\nhead(hcmst)\n\n# A tibble: 6 × 21\n  subject_age subject_education subject_sex subject_ethnicity\n        &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;            \n1          53 high_school_grad  female      white            \n2          72 some_college      female      white            \n3          43 associate_degree  male        white            \n4          64 some_college      male        white            \n5          60 high_school_grad  female      black            \n6          78 high_school_grad  female      white            \n# ℹ 17 more variables: subject_income_category &lt;chr&gt;,\n#   subject_employment_status &lt;chr&gt;, same_sex_couple &lt;chr&gt;, married &lt;chr&gt;,\n#   sex_frequency &lt;chr&gt;, flirts_with_partner &lt;chr&gt;, fights_with_partner &lt;chr&gt;,\n#   relationship_duration &lt;dbl&gt;, children &lt;dbl&gt;,\n#   rel_change_during_pandemic &lt;chr&gt;, inc_change_during_pandemic &lt;chr&gt;,\n#   subject_had_covid &lt;chr&gt;, partner_had_covid &lt;chr&gt;, subject_vaccinated &lt;chr&gt;,\n#   partner_vaccinated &lt;chr&gt;, agree_covid_approach &lt;chr&gt;, …\n\n\n\n\n2. Exploratory Data Analysis\n\nnumeric_vars &lt;- c(\"subject_age\", \"relationship_duration\", \"children\")\n\nhcmst_long &lt;- hcmst |&gt;\n  select(all_of(numeric_vars)) |&gt;\n  pivot_longer(cols = everything(), names_to = \"variable\", values_to = \"value\")\n\nggplot(\n  hcmst_long, \n  aes(x = value)\n  ) +\n  geom_density(fill = \"skyblue2\") +\n  labs(title = \"Density Plots for Numeric Variables\", x = NULL, y = \"Density\") +\n  facet_wrap(~ variable, scales = \"free\", ncol = 2) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncols_to_plot &lt;- c(\"subject_education\", \"subject_sex\", \"subject_ethnicity\", \"subject_income_category\", \"subject_employment_status\", \"same_sex_couple\", \"married\", \"sex_frequency\", \"flirts_with_partner\", \"fights_with_partner\")\n\nhcmst_long &lt;- hcmst |&gt;\n  select(all_of(cols_to_plot)) |&gt;\n  pivot_longer(cols = everything(), names_to = \"variable\", values_to = \"value\") |&gt;\n  count(variable, value)\n\n\nggplot(\n  hcmst_long, \n  aes(y = reorder(value, n))\n  ) +\n  geom_bar(aes(x = n), stat = \"identity\", fill = \"skyblue2\") +\n  labs(\n    title = \"Counts by Category\",\n    x = \"Count\",\n    y = NULL\n  ) +\n  facet_wrap(~ variable, scales = \"free\", ncol = 1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncols_to_plot &lt;- c(\"rel_change_during_pandemic\", \"inc_change_during_pandemic\", \"subject_had_covid\", \"partner_had_covid\", \"subject_vaccinated\", \"partner_vaccinated\", \"agree_covid_approach\", \"sex_frequency\", \"flirts_with_partner\", \"fights_with_partner\")\n\nhcmst_long &lt;- hcmst |&gt;\n  select(all_of(cols_to_plot)) |&gt;\n  pivot_longer(cols = everything(), names_to = \"variable\", values_to = \"value\") |&gt;\n  count(variable, value)\n\n\nggplot(\n  hcmst_long, \n  aes(y = reorder(value, n))\n  ) +\n  geom_bar(aes(x = n), stat = \"identity\", fill = \"skyblue2\") +\n  labs(\n    title = \"Counts by Category\",\n    x = \"Count\",\n    y = NULL\n  ) +\n  facet_wrap(~ variable, scales = \"free\", ncol = 1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nrelationship_quality &lt;- hcmst |&gt; \n  add_count(relationship_quality) |&gt; \n  ggplot(aes(y = reorder(relationship_quality, n))) +\n  geom_bar(fill = \"skyblue2\") +\n  labs(\n    title = \"Quality of Relationships\",\n    x = \"Count\",\n    y = NULL\n  ) +\n  theme_minimal()\n\nrelationship_quality\n\n\n\n\n\n\n\n\n\nggsave(\"../img/hcmst.png\", plot = relationship_quality, width = 6, height = 4, dpi = 300)\n\n\n\n3. More…\n\nhcmst$subject_sex &lt;- as.factor(hcmst$subject_sex)\nlevels(hcmst$subject_sex)\n\n[1] \"female\" \"male\"  \n\nhcmst$subject_ethnicity &lt;- as.factor(hcmst$subject_ethnicity)\nlevels(hcmst$subject_ethnicity)\n\n[1] \"2_plus_eth\" \"black\"      \"hispanic\"   \"other\"      \"white\"     \n\nhcmst$subject_employment_status &lt;- as.factor(hcmst$subject_employment_status)\nlevels(hcmst$subject_employment_status)\n\n[1] \"not_working_disabled\"    \"not_working_looking\"    \n[3] \"not_working_other\"       \"not_working_retired\"    \n[5] \"not_working_temp_layoff\" \"working_paid_employee\"  \n[7] \"working_self_employed\"  \n\nhcmst$same_sex_couple &lt;- as.factor(hcmst$same_sex_couple)\nlevels(hcmst$same_sex_couple)\n\n[1] \"no\"  \"yes\"\n\nhcmst$married &lt;- as.factor(hcmst$married)\nlevels(hcmst$married)\n\n[1] \"married\"     \"not_married\"\n\nhcmst$subject_had_covid &lt;- as.factor(hcmst$subject_had_covid)\nlevels(hcmst$subject_had_covid)\n\n[1] \"no\"  \"yes\"\n\nhcmst$partner_had_covid &lt;- as.factor(hcmst$partner_had_covid)\nlevels(hcmst$partner_had_covid)\n\n[1] \"no\"  \"yes\"\n\nhcmst$subject_education &lt;- as.ordered(hcmst$subject_education)\nhcmst$subject_education &lt;- fct_relevel(\n  hcmst$subject_education,\n  c(\"prof_doct_degree\", \"masters_degree\", \"bach_degree\", \"associate_degree\", \"some_college\", \"high_school_grad\", \"12th_nodiploma\", \"11th\", \"10th\", \"9th\", \"7th_8th_grade\", \"5th_6th_grade\", \"1st_4th_grade\", \"no_education\")\n)\nlevels(hcmst$subject_education)\n\n [1] \"prof_doct_degree\" \"masters_degree\"   \"bach_degree\"      \"associate_degree\"\n [5] \"some_college\"     \"high_school_grad\" \"12th_nodiploma\"   \"11th\"            \n [9] \"10th\"             \"9th\"              \"7th_8th_grade\"    \"5th_6th_grade\"   \n[13] \"1st_4th_grade\"    \"no_education\"    \n\nhcmst$subject_income_category &lt;- as.ordered(hcmst$subject_income_category)\nhcmst$subject_income_category &lt;- fct_relevel(\n  hcmst$subject_income_category,\n  c(\"under_5k\", \"5k_7k\", \"7k_10k\", \"10k_12k\", \"12k_15k\", \"15k_20k\", \"20k_25k\", \"25k_30k\", \"30k_35k\", \"35k_40k\", \"40k_50k\", \"50k_60k\", \"60k_75k\", \"75k_85k\", \"85k_100k\", \"100k_125k\", \"125k_150k\", \"150k_175k\", \"175k_200k\", \"200k_250k\", \"over_250k\")\n)\nlevels(hcmst$subject_income_category)\n\n [1] \"under_5k\"  \"5k_7k\"     \"7k_10k\"    \"10k_12k\"   \"12k_15k\"   \"15k_20k\"  \n [7] \"20k_25k\"   \"25k_30k\"   \"30k_35k\"   \"35k_40k\"   \"40k_50k\"   \"50k_60k\"  \n[13] \"60k_75k\"   \"75k_85k\"   \"85k_100k\"  \"100k_125k\" \"125k_150k\" \"150k_175k\"\n[19] \"175k_200k\" \"200k_250k\" \"over_250k\"\n\nhcmst$sex_frequency &lt;- as.ordered(hcmst$sex_frequency)\nhcmst$sex_frequency &lt;- fct_relevel(\n  hcmst$sex_frequency,\n  c(\"once_or_more_a_day\", \"once_or_twice_a_week\", \"3_to_6_times_a_week\", \"2_to_3_times_a_month\", \"once_a_month_or_less\")\n)\nlevels(hcmst$sex_frequency)\n\n[1] \"once_or_more_a_day\"   \"once_or_twice_a_week\" \"3_to_6_times_a_week\" \n[4] \"2_to_3_times_a_month\" \"once_a_month_or_less\"\n\nhcmst$flirts_with_partner &lt;- as.ordered(hcmst$flirts_with_partner)\nhcmst$flirts_with_partner &lt;- fct_relevel(\n  hcmst$flirts_with_partner,\n  c(\"never\", \"less_than_once_a_month\", \"1_to_3_times_a_month\", \"once_a_week\", \"a_few_times_a_week\", \"every_day\")\n)\nlevels(hcmst$flirts_with_partner)\n\n[1] \"never\"                  \"less_than_once_a_month\" \"1_to_3_times_a_month\"  \n[4] \"once_a_week\"            \"a_few_times_a_week\"     \"every_day\"             \n\nhcmst$fights_with_partner &lt;- as.ordered(hcmst$fights_with_partner)\nhcmst$fights_with_partner &lt;- fct_relevel(\n  hcmst$fights_with_partner,\n  c(\"0_times\", \"1_time\", \"2_times\", \"3_times\", \"4_times\", \"5_times\", \"6_times\", \"7_or_more_times\")\n)\nlevels(hcmst$fights_with_partner)\n\n[1] \"0_times\"         \"1_time\"          \"2_times\"         \"3_times\"        \n[5] \"4_times\"         \"5_times\"         \"6_times\"         \"7_or_more_times\"\n\nhcmst$rel_change_during_pandemic &lt;- as.ordered(hcmst$rel_change_during_pandemic)\nhcmst$rel_change_during_pandemic &lt;- fct_relevel(\n  hcmst$rel_change_during_pandemic,\n  c(\"better_than_before\", \"no_change\", \"worse_than_before\")\n)\nlevels(hcmst$rel_change_during_pandemic)\n\n[1] \"better_than_before\" \"no_change\"          \"worse_than_before\" \n\nhcmst$inc_change_during_pandemic &lt;- as.ordered(hcmst$inc_change_during_pandemic)\nhcmst$inc_change_during_pandemic &lt;- fct_relevel(\n  hcmst$inc_change_during_pandemic,\n  c(\"much_worse\", \"worse\", \"no_change\", \"better\", \"much_better\")\n)\nlevels(hcmst$inc_change_during_pandemic)\n\n[1] \"much_worse\"  \"worse\"       \"no_change\"   \"better\"      \"much_better\"\n\nhcmst$subject_vaccinated &lt;- as.ordered(hcmst$subject_vaccinated)\nhcmst$subject_vaccinated &lt;- fct_relevel(\n  hcmst$subject_vaccinated,\n  c(\"not_vaccinated\", \"partially_vaccinated\", \"fully_vaccinated_no_booster\", \"fully_vaccinated_and_booster\")\n)\nlevels(hcmst$subject_vaccinated)\n\n[1] \"not_vaccinated\"               \"partially_vaccinated\"        \n[3] \"fully_vaccinated_no_booster\"  \"fully_vaccinated_and_booster\"\n\nhcmst$partner_vaccinated &lt;- as.ordered(hcmst$partner_vaccinated)\nhcmst$partner_vaccinated &lt;- fct_relevel(\n  hcmst$partner_vaccinated,\n  c(\"not_vaccinated\", \"partially_vaccinated\", \"fully_vaccinated_no_booster\", \"fully_vaccinated_and_booster\")\n)\nlevels(hcmst$partner_vaccinated)\n\n[1] \"not_vaccinated\"               \"partially_vaccinated\"        \n[3] \"fully_vaccinated_no_booster\"  \"fully_vaccinated_and_booster\"\n\nhcmst$agree_covid_approach &lt;- as.ordered(hcmst$agree_covid_approach)\nhcmst$agree_covid_approach &lt;- fct_relevel(\n  hcmst$agree_covid_approach,\n  c(\"completely_agree\", \"mostly_agree\", \"mostly_disagree\", \"completely_disagree\")\n)\nlevels(hcmst$agree_covid_approach)\n\n[1] \"completely_agree\"    \"mostly_agree\"        \"mostly_disagree\"    \n[4] \"completely_disagree\"\n\nhcmst$relationship_quality &lt;- as.ordered(hcmst$relationship_quality)\nhcmst$relationship_quality &lt;- fct_relevel(\n  hcmst$relationship_quality,\n  c(\"excellent\", \"good\", \"fair\", \"poor\", \"very_poor\")\n)\nlevels(hcmst$relationship_quality)\n\n[1] \"excellent\" \"good\"      \"fair\"      \"poor\"      \"very_poor\"\n\nhead(hcmst)\n\n# A tibble: 6 × 21\n  subject_age subject_education subject_sex subject_ethnicity\n        &lt;dbl&gt; &lt;ord&gt;             &lt;fct&gt;       &lt;fct&gt;            \n1          53 high_school_grad  female      white            \n2          72 some_college      female      white            \n3          43 associate_degree  male        white            \n4          64 some_college      male        white            \n5          60 high_school_grad  female      black            \n6          78 high_school_grad  female      white            \n# ℹ 17 more variables: subject_income_category &lt;ord&gt;,\n#   subject_employment_status &lt;fct&gt;, same_sex_couple &lt;fct&gt;, married &lt;fct&gt;,\n#   sex_frequency &lt;ord&gt;, flirts_with_partner &lt;ord&gt;, fights_with_partner &lt;ord&gt;,\n#   relationship_duration &lt;dbl&gt;, children &lt;dbl&gt;,\n#   rel_change_during_pandemic &lt;ord&gt;, inc_change_during_pandemic &lt;ord&gt;,\n#   subject_had_covid &lt;fct&gt;, partner_had_covid &lt;fct&gt;, subject_vaccinated &lt;ord&gt;,\n#   partner_vaccinated &lt;ord&gt;, agree_covid_approach &lt;ord&gt;, …\n\n\n\ncolnames(hcmst)\n\n [1] \"subject_age\"                \"subject_education\"         \n [3] \"subject_sex\"                \"subject_ethnicity\"         \n [5] \"subject_income_category\"    \"subject_employment_status\" \n [7] \"same_sex_couple\"            \"married\"                   \n [9] \"sex_frequency\"              \"flirts_with_partner\"       \n[11] \"fights_with_partner\"        \"relationship_duration\"     \n[13] \"children\"                   \"rel_change_during_pandemic\"\n[15] \"inc_change_during_pandemic\" \"subject_had_covid\"         \n[17] \"partner_had_covid\"          \"subject_vaccinated\"        \n[19] \"partner_vaccinated\"         \"agree_covid_approach\"      \n[21] \"relationship_quality\"      \n\n\n\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nlibrary(broom)\n\noptions(contrasts = c(\"contr.treatment\", \"contr.sdif\"))\n\nfull_ordinal_model &lt;- polr(relationship_quality ~ subject_age + subject_education + subject_sex + subject_ethnicity + subject_income_category + subject_employment_status + same_sex_couple + married + sex_frequency + flirts_with_partner + fights_with_partner + relationship_duration + children + rel_change_during_pandemic + inc_change_during_pandemic + subject_had_covid + partner_had_covid + subject_vaccinated + partner_vaccinated + agree_covid_approach,\n  data = hcmst, Hess = TRUE\n)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nsummary_full_ordinal_model &lt;- cbind(tidy(full_ordinal_model),\n  p.value = pnorm(abs(tidy(full_ordinal_model)$statistic), lower.tail = FALSE) * 2) |&gt;\n  mutate_if(is.numeric, round, 2)\n\nsummary_full_ordinal_model |&gt; \n  filter(p.value &lt; 0.05, \n         coef.type == \"coefficient\")\n\n                                                     term estimate std.error\n1                    subject_education11th-12th_nodiploma     1.98      0.89\n2             subject_educationno_education-1st_4th_grade   -18.17      0.06\n3                                      marriednot_married     0.78      0.21\n4   sex_frequency2_to_3_times_a_month-3_to_6_times_a_week     0.74      0.29\n5  sex_frequencyonce_a_month_or_less-2_to_3_times_a_month     0.94      0.17\n6         flirts_with_partnerevery_day-a_few_times_a_week    -0.69      0.30\n7                       fights_with_partner1_time-0_times     0.78      0.16\n8  rel_change_during_pandemicno_change-better_than_before     1.00      0.19\n9   rel_change_during_pandemicworse_than_before-no_change     1.94      0.28\n10              inc_change_during_pandemicno_change-worse    -0.58      0.18\n11      agree_covid_approachmostly_agree-completely_agree     0.47      0.15\n12       agree_covid_approachmostly_disagree-mostly_agree     1.38      0.43\n   statistic   coef.type p.value\n1       2.22 coefficient    0.03\n2    -308.64 coefficient    0.00\n3       3.76 coefficient    0.00\n4       2.54 coefficient    0.01\n5       5.44 coefficient    0.00\n6      -2.28 coefficient    0.02\n7       5.02 coefficient    0.00\n8       5.31 coefficient    0.00\n9       6.82 coefficient    0.00\n10     -3.19 coefficient    0.00\n11      3.23 coefficient    0.00\n12      3.19 coefficient    0.00\n\n\n\npredict(full_ordinal_model, tibble(\n  subject_age = 40, \n  subject_education = \"bach_degree\",\n  subject_sex = \"male\",\n  subject_ethnicity = \"hispanic\",\n  subject_income_category = \"60k_75k\",\n  subject_employment_status = \"working_paid_employee\",\n  same_sex_couple = \"yes\",\n  married = \"not_married\",\n  sex_frequency = \"2_to_3_times_a_month\",\n  flirts_with_partner = \"a_few_times_a_week\",\n  fights_with_partner = \"3_times\",\n  relationship_duration = 10,\n  children = 2,\n  rel_change_during_pandemic = \"no_change\",\n  inc_change_during_pandemic = \"much_worse\",\n  subject_had_covid = \"yes\",\n  partner_had_covid = \"yes\",\n  subject_vaccinated = \"fully_vaccinated_no_booster\",\n  partner_vaccinated = \"not_vaccinated\",\n  agree_covid_approach = \"completely_disagree\"), \n  type = \"probs\")\n\n excellent       good       fair       poor  very_poor \n0.03780206 0.43096376 0.42696611 0.09113980 0.01312827 \n\n\n\npartial_ordinal_model &lt;- polr(relationship_quality ~ subject_age + subject_education + subject_sex + subject_ethnicity + subject_income_category + subject_employment_status + same_sex_couple + married + sex_frequency + flirts_with_partner + fights_with_partner + relationship_duration + children + rel_change_during_pandemic + inc_change_during_pandemic + subject_had_covid + partner_had_covid + subject_vaccinated + partner_vaccinated + agree_covid_approach,\n  data = hcmst, Hess = TRUE\n)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nsummary_partial_ordinal_model &lt;- cbind(tidy(partial_ordinal_model),\n  p.value = pnorm(abs(tidy(partial_ordinal_model)$statistic), lower.tail = FALSE) * 2) |&gt;\n  mutate_if(is.numeric, round, 2)\n\nsummary_partial_ordinal_model |&gt; \n  filter(p.value &lt; 0.05, \n         coef.type == \"coefficient\")\n\n                                                     term estimate std.error\n1                    subject_education11th-12th_nodiploma     1.98      0.89\n2             subject_educationno_education-1st_4th_grade   -18.17      0.06\n3                                      marriednot_married     0.78      0.21\n4   sex_frequency2_to_3_times_a_month-3_to_6_times_a_week     0.74      0.29\n5  sex_frequencyonce_a_month_or_less-2_to_3_times_a_month     0.94      0.17\n6         flirts_with_partnerevery_day-a_few_times_a_week    -0.69      0.30\n7                       fights_with_partner1_time-0_times     0.78      0.16\n8  rel_change_during_pandemicno_change-better_than_before     1.00      0.19\n9   rel_change_during_pandemicworse_than_before-no_change     1.94      0.28\n10              inc_change_during_pandemicno_change-worse    -0.58      0.18\n11      agree_covid_approachmostly_agree-completely_agree     0.47      0.15\n12       agree_covid_approachmostly_disagree-mostly_agree     1.38      0.43\n   statistic   coef.type p.value\n1       2.22 coefficient    0.03\n2    -308.64 coefficient    0.00\n3       3.76 coefficient    0.00\n4       2.54 coefficient    0.01\n5       5.44 coefficient    0.00\n6      -2.28 coefficient    0.02\n7       5.02 coefficient    0.00\n8       5.31 coefficient    0.00\n9       6.82 coefficient    0.00\n10     -3.19 coefficient    0.00\n11      3.23 coefficient    0.00\n12      3.19 coefficient    0.00\n\n\n\n\n4. Discussion\nX"
  },
  {
    "objectID": "website_files/description_pages/hcmst.html#attribution",
    "href": "website_files/description_pages/hcmst.html#attribution",
    "title": "How Couples Meet and Stay Together",
    "section": "Attribution",
    "text": "Attribution\nData adapted from Rosenfeld, Michael J., Reuben J. Thomas, and Sonia Hausen. 2023. How Couples Meet and Stay Together 2017-2020-2022 Combined Dataset. [Computer files]. Stanford, CA: Stanford University Libraries. Data."
  },
  {
    "objectID": "website_files/citation.html",
    "href": "website_files/citation.html",
    "title": "Citation",
    "section": "",
    "text": "Burak K (2025). diversedata: Diverse Dataset Hub. R package version TBD, https://github.com/diverse-data-hub/diversedata"
  },
  {
    "objectID": "website_files/citation.html#tbd-another-reference",
    "href": "website_files/citation.html#tbd-another-reference",
    "title": "Citation",
    "section": "TBD Another Reference",
    "text": "TBD Another Reference\n\nOwners\nKatie Burak PhD\nCopyright Holder\n\nCollaborators\nFrancisco Ramirez\nAzin Piran\nSiddarth Subrahmanian"
  },
  {
    "objectID": "scripts/wildfire_clean.html",
    "href": "scripts/wildfire_clean.html",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "",
    "text": "import pandas as pd\n\nwildfire = pd.read_csv(\"../data/raw/wildfire/wildfire.csv\")\nwildfire.head()\n\n\n\n\n\n\n\n\nYEAR\nFIRE_NUMBER\nFIRE_NAME\nCURRENT_SIZE\nSIZE_CLASS\nLATITUDE\nLONGITUDE\nFIRE_ORIGIN\nGENERAL_CAUSE\nINDUSTRY_IDENTIFIER\n...\nDISTANCE_FROM_WATER_SOURCE\nFIRST_BUCKET_DROP_DATE\nFIRST_BH_DATE\nFIRST_BH_SIZE\nFIRST_UC_DATE\nFIRST_UC_SIZE\nFIRST_TO_DATE\nFIRST_TO_SIZE\nFIRST_EX_DATE\nFIRST_EX_SIZE_PERIMETER\n\n\n\n\n0\n2006\nPWF001\nNaN\n0.10\nA\n56.249956\n-117.181960\nPrivate Land\nResident\nNaN\n...\nNaN\nNaN\n2006-04-02 22:00:00\n0.01\n2006-04-02 22:00:00\n0.01\nNaN\nNaN\n2006-04-03 10:20:00\n0.10\n\n\n1\n2006\nEWF002\nNaN\n0.20\nB\n53.606367\n-115.915733\nProvincial Land\nIncendiary\nNaN\n...\nNaN\nNaN\n2006-04-03 13:20:00\n0.20\n2006-04-03 13:20:00\n0.20\nNaN\nNaN\n2006-04-03 14:00:00\n0.20\n\n\n2\n2006\nEWF001\nNaN\n0.50\nB\n53.610933\n-115.594267\nProvincial Land\nIncendiary\nNaN\n...\nNaN\nNaN\n2006-04-03 13:23:00\n0.50\n2006-04-03 13:23:00\n0.50\nNaN\nNaN\n2006-04-03 15:00:00\n0.50\n\n\n3\n2006\nEWF003\nNaN\n0.01\nA\n53.608867\n-115.609467\nProvincial Land\nIncendiary\nNaN\n...\nNaN\nNaN\n2006-04-03 14:08:00\n0.01\n2006-04-03 14:08:00\n0.01\nNaN\nNaN\n2006-04-03 15:05:00\n0.01\n\n\n4\n2006\nPWF002\nNaN\n0.10\nA\n56.249956\n-117.050249\nProvincial Land\nOther Industry\nWaste Disposal\n...\nNaN\nNaN\n2006-04-03 19:57:00\n0.10\n2006-04-03 20:19:00\n0.10\n2006-04-03 20:20:00\n0.1\n2006-04-05 10:18:00\n0.10\n\n\n\n\n5 rows × 50 columns"
  },
  {
    "objectID": "scripts/wildfire_clean.html#drop-uninformative-or-very-sparse-columns",
    "href": "scripts/wildfire_clean.html#drop-uninformative-or-very-sparse-columns",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Drop uninformative or very sparse columns",
    "text": "Drop uninformative or very sparse columns\nThese columns have more than 50% missing values and we can remove them.\n\n## These columns are very sparse\n# FIRE_NAME                       25756\n# INDUSTRY_IDENTIFIER             26071\n# DISCOVERED_SIZE                 26402\n# DISTANCE_FROM_WATER_SOURCE      18958\n# FIRST_BUCKET_DROP_DATE          18957\n# FIRST_TO_DATE                   23809\n# FIRST_TO_SIZE                   23809\n\n\n\nwildfire = wildfire.drop(columns=[\n    \"FIRE_NAME\", \"INDUSTRY_IDENTIFIER\", \"DISCOVERED_SIZE\", \n    \"DISTANCE_FROM_WATER_SOURCE\", \"FIRST_BUCKET_DROP_DATE\", \"FIRST_TO_DATE\", \"FIRST_TO_SIZE\"\n], errors=\"ignore\")"
  },
  {
    "objectID": "scripts/wildfire_clean.html#handle-moderate-missing-values",
    "href": "scripts/wildfire_clean.html#handle-moderate-missing-values",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Handle moderate missing values",
    "text": "Handle moderate missing values\nThese are useful variables but have some missing data. We can fill with “unknown”, 0, or mean.\n\n# few missing\nwildfire[\"DISPATCHED_RESOURCE\"] = wildfire[\"DISPATCHED_RESOURCE\"].fillna(\"Unknown\")\nwildfire[\"DISPATCH_DATE\"] = pd.to_datetime(wildfire[\"DISPATCH_DATE\"], errors=\"coerce\") # I converted this column to date, and If a value can't be converted to a date (e.g., it's missing or malformed), it will be replaced with NaT\nwildfire[\"START_FOR_FIRE_DATE\"] = pd.to_datetime(wildfire[\"START_FOR_FIRE_DATE\"], errors=\"coerce\")\nwildfire[\"INITIAL_ACTION_BY\"] = wildfire[\"INITIAL_ACTION_BY\"].fillna(\"Unknown\")\nwildfire[\"FIRE_ORIGIN\"] = wildfire[\"INITIAL_ACTION_BY\"].fillna(\"Unknown\")\nwildfire[\"FIRST_EX_DATE\"] = pd.to_datetime(wildfire[\"FIRST_EX_DATE\"], errors=\"coerce\")\nwildfire[\"FIRST_EX_SIZE_PERIMETER\"] = wildfire[\"FIRST_EX_SIZE_PERIMETER\"].fillna(-1) # missing or unknown numeric data\n\n# Moderate missing\nwildfire[\"FIRE_START_DATE\"] = pd.to_datetime(wildfire[\"FIRE_START_DATE\"], errors=\"coerce\")\nwildfire[\"DISCOVERED_DATE\"] = pd.to_datetime(wildfire[\"DISCOVERED_DATE\"], errors=\"coerce\")\nwildfire[\"FIRE_SPREAD_RATE\"] = wildfire[\"FIRE_SPREAD_RATE\"].fillna(wildfire[\"FIRE_SPREAD_RATE\"].mean())  ## mean value\nwildfire[\"FIRE_POSITION_ON_SLOPE\"] = wildfire[\"FIRE_POSITION_ON_SLOPE\"].fillna(\"Unknown\")\nwildfire[\"WEATHER_CONDITIONS_OVER_FIRE\"] = wildfire[\"WEATHER_CONDITIONS_OVER_FIRE\"].fillna(\"Unknown\")\nwildfire[\"WIND_DIRECTION\"] = wildfire[\"WIND_DIRECTION\"].fillna(\"Unknown\")\nwildfire[\"FUEL_TYPE\"] = wildfire[\"FUEL_TYPE\"].fillna(\"Unknown\")\nwildfire[\"TRUE_CAUSE\"] = wildfire[\"TRUE_CAUSE\"].fillna(\"Unknown\") \nwildfire[\"FIRE_TYPE\"] = wildfire[\"FIRE_TYPE\"].fillna(\"Unknown\") \n\n# Higher missing \nwildfire[\"RESPONSIBLE_GROUP\"] = wildfire[\"RESPONSIBLE_GROUP\"].fillna(\"Unknown\")\nwildfire[\"ACTIVITY_CLASS\"] = wildfire[\"ACTIVITY_CLASS\"].fillna(\"Unknown\")\nwildfire[\"IA_ARRIVAL_AT_FIRE_DATE\"] = pd.to_datetime(wildfire[\"IA_ARRIVAL_AT_FIRE_DATE\"], errors=\"coerce\")\nwildfire[\"IA_ACCESS\"] = wildfire[\"IA_ACCESS\"].fillna(\"Unknown\")\nwildfire[\"FIRE_FIGHTING_START_DATE\"] = pd.to_datetime(wildfire[\"FIRE_FIGHTING_START_DATE\"], errors=\"coerce\")\nwildfire[\"FIRE_FIGHTING_START_SIZE\"] = wildfire[\"FIRE_FIGHTING_START_SIZE\"].fillna(wildfire[\"FIRE_FIGHTING_START_SIZE\"].median()) ## median value\nwildfire[\"BUCKETING_ON_FIRE\"] = wildfire[\"BUCKETING_ON_FIRE\"].fillna(\"Unknown\")\n\n\n\n\n## Double check everything one more time  --&gt; alll of the date columns now have NaT \nwildfire.isna().sum()\n## Please let me know about the other columns, like humidity or temperature and wind_s, what should we do \n\nYEAR                               0\nFIRE_NUMBER                        0\nCURRENT_SIZE                       0\nSIZE_CLASS                         0\nLATITUDE                           0\nLONGITUDE                          0\nFIRE_ORIGIN                        0\nGENERAL_CAUSE                      0\nRESPONSIBLE_GROUP                  0\nACTIVITY_CLASS                     0\nTRUE_CAUSE                         0\nFIRE_START_DATE                  693\nDETECTION_AGENT_TYPE               0\nDETECTION_AGENT                    0\nDISCOVERED_DATE                 5409\nREPORTED_DATE                      0\nDISPATCHED_RESOURCE                0\nDISPATCH_DATE                     12\nSTART_FOR_FIRE_DATE               17\nASSESSMENT_RESOURCE                0\nASSESSMENT_DATETIME                0\nASSESSMENT_HECTARES                0\nFIRE_SPREAD_RATE                   0\nFIRE_TYPE                          0\nFIRE_POSITION_ON_SLOPE             0\nWEATHER_CONDITIONS_OVER_FIRE       0\nTEMPERATURE                     2872\nRELATIVE_HUMIDITY               2878\nWIND_DIRECTION                     0\nWIND_SPEED                      2880\nFUEL_TYPE                          0\nINITIAL_ACTION_BY                  0\nIA_ARRIVAL_AT_FIRE_DATE         7703\nIA_ACCESS                          0\nFIRE_FIGHTING_START_DATE        7572\nFIRE_FIGHTING_START_SIZE           0\nBUCKETING_ON_FIRE                  0\nFIRST_BH_DATE                      0\nFIRST_BH_SIZE                      0\nFIRST_UC_DATE                      0\nFIRST_UC_SIZE                      0\nFIRST_EX_DATE                      6\nFIRST_EX_SIZE_PERIMETER            0\ndtype: int64"
  },
  {
    "objectID": "scripts/wildfire_clean.html#datetime",
    "href": "scripts/wildfire_clean.html#datetime",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Date/Time",
    "text": "Date/Time\n\ndate_cols = [\n    \"FIRE_START_DATE\", \"DISCOVERED_DATE\", \"REPORTED_DATE\", \"DISPATCH_DATE\",\n    \"START_FOR_FIRE_DATE\", \"IA_ARRIVAL_AT_FIRE_DATE\", \"FIRE_FIGHTING_START_DATE\", \"FIRST_BH_DATE\", \"FIRST_UC_DATE\",\n    \"FIRST_EX_DATE\", \"ASSESSMENT_DATETIME\"\n]\n\nfor col in date_cols:\n    wildfire[col] = pd.to_datetime(wildfire[col], errors=\"coerce\")\n\n## Format all float columns to 2 decimal places\n\nfloat_cols = wildfire.select_dtypes(include=[\"float64\"]).columns\nwildfire[float_cols] = wildfire[float_cols].round(2)"
  },
  {
    "objectID": "scripts/wildfire_clean.html#based-on-alberta-historical-wildfire-data-dictionary-20062024",
    "href": "scripts/wildfire_clean.html#based-on-alberta-historical-wildfire-data-dictionary-20062024",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Based on Alberta Historical Wildfire Data Dictionary (2006–2024)",
    "text": "Based on Alberta Historical Wildfire Data Dictionary (2006–2024)\n\n\n\n\n\n\n\nColumn Name\nOfficial Definition (From Data Dictionary)\n\n\n\n\nfire_start_date\nThe estimated or known time and date the wildfire began. May come from storm tracking, witness statements, or lightning map data.\n\n\ndiscovered_date\nThe time the detection agent first discovered the wildfire. May be blank for unplanned detections.\n\n\nreported_date\nThe time and date the wildfire was reported to Alberta Wildfire (usually when the detection agent contacts dispatch).\n\n\ndispatch_date\nThe date and time the first resource was dispatched to respond to the wildfire.\n\n\nstart_for_fire_date\nThe time and date the dispatched resource left for the wildfire, e.g., wheels roll, skids up, or vehicle departure.\n\n\nassessment_datetime\nThe date and time of the initial wildfire assessment, which determines the fire year.\n\n\nia_arrival_at_fire_date\nThe date and time the initial action resource arrived at the wildfire site.\n\n\nfire_fighting_start_date\nThe date and time suppression efforts began (e.g., digging firelines, water drops).\n\n\nfirst_bh_date\nThe date/time the wildfire status changed to Being Held (BH) — unlikely to spread further under current conditions.\n\n\nfirst_uc_date\nThe date/time the fire was declared Under Control (UC) — fire perimeter secured, no further spread expected.\n\n\nfirst_ex_date\nThe date/time the fire was declared Extinguished (EX) — fully out, no hot spots remaining."
  },
  {
    "objectID": "scripts/wildfire_clean.html#i-just-keep-these-date-columns-and-i-think-these-columns-are-most-informative",
    "href": "scripts/wildfire_clean.html#i-just-keep-these-date-columns-and-i-think-these-columns-are-most-informative",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "I just keep these date columns and I think these columns are most informative",
    "text": "I just keep these date columns and I think these columns are most informative\n\n## I keep these columns\n##   'fire_start_date',\n##   'discovered_date',\n##   'ia_arrival_at_fire_date',\n##   'fire_fighting_start_date',\n##   'first_bh_date',\n##   'first_uc_date',\n##   'first_ex_date'\n\n# I deleted these columns\ncols_to_delete = [\n  'reported_date',\n    'dispatch_date',\n    'start_for_fire_date',\n    'first_ex_date',\n    'discovered_date', \n    'assessment_datetime',\n    'dispatched_resource', ## This is not a date column, but it is not useful so I deleted it here\n    'assessment_resource' ## This is not date column but it is not usefull so I deleted here\n]\n\nwildfire = wildfire.drop(columns=cols_to_delete, errors='ignore')\nwildfire.head()\n\n\n\n\n\n\n\n\nyear\nfire_number\ncurrent_size\nsize_class\nlatitude\nlongitude\nfire_origin\ngeneral_cause\nresponsible_group\nactivity_class\n...\nia_arrival_at_fire_date\nia_access\nfire_fighting_start_date\nfire_fighting_start_size\nbucketing_on_fire\nfirst_bh_date\nfirst_bh_size\nfirst_uc_date\nfirst_uc_size\nfirst_ex_size_perimeter\n\n\n\n\n0\n2006\nPWF001\n0.10\nA\n56.25\n-117.18\nLand Owner\nResident\nResident\nGrass\n...\nNaT\nUnknown\nNaT\n0.02\nUnknown\n2006-04-02 22:00:00\n0.01\n2006-04-02 22:00:00\n0.01\n0.10\n\n\n1\n2006\nEWF002\n0.20\nB\n53.61\n-115.92\nFire Department\nIncendiary\nOthers (explain in remarks)\nLighting Fires\n...\nNaT\nUnknown\nNaT\n0.02\nUnknown\n2006-04-03 13:20:00\n0.20\n2006-04-03 13:20:00\n0.20\n0.20\n\n\n2\n2006\nEWF001\n0.50\nB\n53.61\n-115.59\nFire Department\nIncendiary\nOthers (explain in remarks)\nLighting Fires\n...\nNaT\nUnknown\nNaT\n0.02\nUnknown\n2006-04-03 13:23:00\n0.50\n2006-04-03 13:23:00\n0.50\n0.50\n\n\n3\n2006\nEWF003\n0.01\nA\n53.61\n-115.61\nIndustry\nIncendiary\nOthers (explain in remarks)\nLighting Fires\n...\nNaT\nUnknown\nNaT\n0.02\nUnknown\n2006-04-03 14:08:00\n0.01\n2006-04-03 14:08:00\n0.01\n0.01\n\n\n4\n2006\nPWF002\n0.10\nA\n56.25\n-117.05\nFire Department\nOther Industry\nEmployees\nRefuse\n...\nNaT\nUnknown\nNaT\n0.02\nUnknown\n2006-04-03 19:57:00\n0.10\n2006-04-03 20:19:00\n0.10\n0.10\n\n\n\n\n5 rows × 35 columns\n\n\n\n\nwildfire.columns.tolist()\n\n['year',\n 'fire_number',\n 'current_size',\n 'size_class',\n 'latitude',\n 'longitude',\n 'fire_origin',\n 'general_cause',\n 'responsible_group',\n 'activity_class',\n 'true_cause',\n 'fire_start_date',\n 'detection_agent_type',\n 'detection_agent',\n 'assessment_hectares',\n 'fire_spread_rate',\n 'fire_type',\n 'fire_position_on_slope',\n 'weather_conditions_over_fire',\n 'temperature',\n 'relative_humidity',\n 'wind_direction',\n 'wind_speed',\n 'fuel_type',\n 'initial_action_by',\n 'ia_arrival_at_fire_date',\n 'ia_access',\n 'fire_fighting_start_date',\n 'fire_fighting_start_size',\n 'bucketing_on_fire',\n 'first_bh_date',\n 'first_bh_size',\n 'first_uc_date',\n 'first_uc_size',\n 'first_ex_size_perimeter']"
  },
  {
    "objectID": "scripts/wildfire_clean.html#please-let-me-know-which-columns-you-think-are-better-to-keep",
    "href": "scripts/wildfire_clean.html#please-let-me-know-which-columns-you-think-are-better-to-keep",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Please let me know which columns you think are better to keep",
    "text": "Please let me know which columns you think are better to keep\n\n\n\n\n\n\n\nCategory\nColumns\n\n\n\n\nIdentifiers\n'year', 'fire_number'\n\n\nFire Size & Status\n'current_size', 'size_class', 'fire_fighting_start_size', 'first_bh_size', 'first_uc_size', 'first_ex_size_perimeter'\n\n\nLocation\n'latitude', 'longitude', 'fire_origin'\n\n\nCause & Activity\n'general_cause', 'true_cause', 'activity_class', 'responsible_group'\n\n\nKey Dates\n'fire_start_date', 'discovered_date', 'ia_arrival_at_fire_date', 'fire_fighting_start_date', 'first_bh_date', 'first_uc_date'\n\n\nDetection & Resources\n'detection_agent_type', 'detection_agent', 'initial_action_by', 'ia_access'\n\n\nAssessment & Behavior\n'assessment_hectares', 'fire_spread_rate', 'fire_type', 'fire_position_on_slope', 'fuel_type'\n\n\nWeather\n'weather_conditions_over_fire', 'temperature', 'relative_humidity', 'wind_direction', 'wind_speed'\n\n\nSuppression\n'bucketing_on_fire'"
  },
  {
    "objectID": "scripts/wildfire_clean.html#validate-cleaned-file",
    "href": "scripts/wildfire_clean.html#validate-cleaned-file",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Validate cleaned file",
    "text": "Validate cleaned file\n\nclean = pd.read_csv(\"../data/clean/wildfire.csv\")\nclean.shape\nclean.head()\n\n\n\n\n\n\n\n\nyear\nfire_number\ncurrent_size\nsize_class\nlatitude\nlongitude\nfire_origin\ngeneral_cause\nresponsible_group\nactivity_class\n...\nia_arrival_at_fire_date\nia_access\nfire_fighting_start_date\nfire_fighting_start_size\nbucketing_on_fire\nfirst_bh_date\nfirst_bh_size\nfirst_uc_date\nfirst_uc_size\nfirst_ex_size_perimeter\n\n\n\n\n0\n2006\nPWF001\n0.10\nA\n56.25\n-117.18\nLand Owner\nResident\nResident\nGrass\n...\nNaN\nUnknown\nNaN\n0.02\nUnknown\n2006-04-02 22:00:00\n0.01\n2006-04-02 22:00:00\n0.01\n0.10\n\n\n1\n2006\nEWF002\n0.20\nB\n53.61\n-115.92\nFire Department\nIncendiary\nOthers\nLighting Fires\n...\nNaN\nUnknown\nNaN\n0.02\nUnknown\n2006-04-03 13:20:00\n0.20\n2006-04-03 13:20:00\n0.20\n0.20\n\n\n2\n2006\nEWF001\n0.50\nB\n53.61\n-115.59\nFire Department\nIncendiary\nOthers\nLighting Fires\n...\nNaN\nUnknown\nNaN\n0.02\nUnknown\n2006-04-03 13:23:00\n0.50\n2006-04-03 13:23:00\n0.50\n0.50\n\n\n3\n2006\nEWF003\n0.01\nA\n53.61\n-115.61\nIndustry\nIncendiary\nOthers\nLighting Fires\n...\nNaN\nUnknown\nNaN\n0.02\nUnknown\n2006-04-03 14:08:00\n0.01\n2006-04-03 14:08:00\n0.01\n0.01\n\n\n4\n2006\nPWF002\n0.10\nA\n56.25\n-117.05\nFire Department\nOther Industry\nEmployees\nRefuse\n...\nNaN\nUnknown\nNaN\n0.02\nUnknown\n2006-04-03 19:57:00\n0.10\n2006-04-03 20:19:00\n0.10\n0.10\n\n\n\n\n5 rows × 35 columns"
  },
  {
    "objectID": "scripts/LGBTIQ-rights_clean.html",
    "href": "scripts/LGBTIQ-rights_clean.html",
    "title": "LGBTIQ-rights Dataset Cleaning Steps",
    "section": "",
    "text": "First, we will examine how many unique years and countries are included across the different datasets."
  },
  {
    "objectID": "scripts/LGBTIQ-rights_clean.html#lgbtiq-specific-datasets",
    "href": "scripts/LGBTIQ-rights_clean.html#lgbtiq-specific-datasets",
    "title": "LGBTIQ-rights Dataset Cleaning Steps",
    "section": "",
    "text": "First, we will examine how many unique years and countries are included across the different datasets."
  },
  {
    "objectID": "scripts/LGBTIQ-rights_clean.html#python-code-to-analyze-each-dataset",
    "href": "scripts/LGBTIQ-rights_clean.html#python-code-to-analyze-each-dataset",
    "title": "LGBTIQ-rights Dataset Cleaning Steps",
    "section": "Python Code to Analyze Each Dataset",
    "text": "Python Code to Analyze Each Dataset\n\nimport pandas as pd\n\n# Function to summarize unique years and countries\ndef summarize_years_and_countries(df, dataset_name):\n    return pd.DataFrame({\n        \"Dataset\": [dataset_name],\n        \"Unique Years\": [df[\"Year\"].nunique()],\n        \"Unique Countries\": [df[\"Entity\"].nunique()]\n    })\n\n\n\n# Censorship of LGBTIQ Issues\ndf_censorship = pd.read_csv(\"../data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/censorship-of-lgbtiq-issues.csv\")\ncensorship_summary = summarize_years_and_countries(df_censorship, \"Censorship of LGBTIQ Issues\")\n\n# Employment Discrimination\ndf_employment_discrimination = pd.read_csv(\"../data/raw/LGBTIQ-rights/employment-discrimination/employment-discrimination-lgbt-equaldex.csv\")\nemployment_discrimination_summary = summarize_years_and_countries(df_employment_discrimination, \"Employment Discrimination\")\n\n# Economic Inequality (Gini Index)\ndf_gini = pd.read_csv(\"../data/raw/LGBTIQ-rights/economic-inequality-gini-index/economic-inequality-gini-index.csv\")\n\ngini_summary = summarize_years_and_countries(df_gini, \"Economic Inequality (Gini Index)\")\n\n# GDP per Capita\ndf_gdp = pd.read_csv(\"../data/raw/LGBTIQ-rights/gdp-per-capita/gdp-per-capita-worldbank.csv\")\ngdp_summary = summarize_years_and_countries(df_gdp, \"GDP per Capita\")\n\n# Government Expenditure on Education\ndf_education = pd.read_csv(\"../data/raw/LGBTIQ-rights/government-expenditure-on-education/total-government-expenditure-on-education-gdp.csv\")\neducation_summary = summarize_years_and_countries(df_education, \"Government Education Expenditure\")\n\n# Gender-Affirming Care\ndf_gender_care = pd.read_csv(\"../data/raw/LGBTIQ-rights/gender-affirming-care/gender-affirming-care.csv\")\ngender_care_summary = summarize_years_and_countries(df_gender_care, \"Gender-Affirming Care\")\n\n# Same-Sex Marriage Rights\ndf_marriage = pd.read_csv(\"../data/raw/LGBTIQ-rights/marriage-same-sex-partners/marriage-same-sex-partners-equaldex.csv\")\nmarriage_summary = summarize_years_and_countries(df_marriage, \"Same-Sex Marriage\")\n\n# Legal Gender Change Rights\ndf_legal_gender = pd.read_csv(\"../data/raw/LGBTIQ-rights/right-to-change-legal-gender/right-to-change-legal-gender-equaldex.csv\")\nlegal_gender_summary = summarize_years_and_countries(df_legal_gender, \"Legal Gender Change\")\n\ndef summarize_countries_per_year(df, dataset_name):\n    return (\n        df.groupby(\"Year\")[\"Entity\"]\n        .nunique()\n        .reset_index(name=\"num_countries\")\n        .assign(Dataset=dataset_name)\n    )\n\n\n\ncensorship_summary = summarize_countries_per_year(df_censorship, \"Censorship of LGBTIQ Issues\")\nemployment_summary = summarize_countries_per_year(df_employment_discrimination, \"Employment Discrimination\")\ngini_summary = summarize_countries_per_year(df_gini, \"Economic Inequality (Gini Index)\")\ngdp_summary = summarize_countries_per_year(df_gdp, \"GDP per Capita\")\neducation_summary = summarize_countries_per_year(df_education, \"Government Education Expenditure\")\ngender_care_summary = summarize_countries_per_year(df_gender_care, \"Gender-Affirming Care\")\nmarriage_summary = summarize_countries_per_year(df_marriage, \"Same-Sex Marriage\")\nlegal_gender_summary = summarize_countries_per_year(df_legal_gender, \"Legal Gender Change\")\n\n# Combine\nsummary_all = pd.concat([\n    censorship_summary,\n    employment_summary,\n    gini_summary,\n    gdp_summary,\n    education_summary,\n    gender_care_summary,\n    marriage_summary,\n    legal_gender_summary\n], ignore_index=True)\n\n# Pivot\nsummary_pivot = summary_all.pivot_table(\n    index=\"Dataset\",\n    columns=\"Year\",\n    values=\"num_countries\",\n    fill_value=0\n).reset_index()\n\nsummary_pivot\n\n\n\n\n\n\n\nYear\nDataset\n1870\n1913\n1937\n1950\n1951\n1952\n1953\n1954\n1955\n...\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n2024\n2025\n\n\n\n\n0\nCensorship of LGBTIQ Issues\n0.0\n0.0\n0.0\n4.0\n4.0\n4.0\n4.0\n4.0\n4.0\n...\n34.0\n37.0\n37.0\n40.0\n41.0\n43.0\n46.0\n48.0\n50.0\n194.0\n\n\n1\nEconomic Inequality (Gini Index)\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n87.0\n83.0\n96.0\n82.0\n70.0\n75.0\n28.0\n4.0\n0.0\n0.0\n\n\n2\nEmployment Discrimination\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n63.0\n66.0\n73.0\n78.0\n81.0\n84.0\n86.0\n87.0\n88.0\n183.0\n\n\n3\nGDP per Capita\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n213.0\n213.0\n213.0\n213.0\n213.0\n213.0\n212.0\n206.0\n0.0\n0.0\n\n\n4\nGender-Affirming Care\n0.0\n0.0\n0.0\n9.0\n9.0\n9.0\n9.0\n9.0\n9.0\n...\n66.0\n67.0\n70.0\n71.0\n75.0\n76.0\n79.0\n81.0\n83.0\n164.0\n\n\n5\nGovernment Education Expenditure\n5.0\n8.0\n11.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n184.0\n187.0\n182.0\n184.0\n181.0\n180.0\n149.0\n66.0\n0.0\n0.0\n\n\n6\nLegal Gender Change\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n...\n87.0\n91.0\n95.0\n98.0\n98.0\n98.0\n102.0\n103.0\n103.0\n194.0\n\n\n7\nSame-Sex Marriage\n0.0\n0.0\n0.0\n12.0\n13.0\n13.0\n14.0\n14.0\n14.0\n...\n126.0\n128.0\n131.0\n134.0\n135.0\n135.0\n135.0\n138.0\n138.0\n194.0\n\n\n\n\n8 rows × 80 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = summary_all.copy()\nprint(df)\n\n     Year  num_countries                      Dataset\n0    1950              4  Censorship of LGBTIQ Issues\n1    1951              4  Censorship of LGBTIQ Issues\n2    1952              4  Censorship of LGBTIQ Issues\n3    1953              4  Censorship of LGBTIQ Issues\n4    1954              4  Censorship of LGBTIQ Issues\n..    ...            ...                          ...\n497  2021             98          Legal Gender Change\n498  2022            102          Legal Gender Change\n499  2023            103          Legal Gender Change\n500  2024            103          Legal Gender Change\n501  2025            194          Legal Gender Change\n\n[502 rows x 3 columns]\n\n\n\nimport matplotlib.pyplot as plt\n\nfor dataset in df[\"Dataset\"].unique():\n    subset = df[df[\"Dataset\"] == dataset]\n\n    if subset[\"num_countries\"].notna().sum() == 0:\n        print(f\"Skipping {dataset} – all values are null\")\n        continue\n\n    plt.figure(figsize=(8, 4))\n    plt.plot(subset[\"Year\"], subset[\"num_countries\"], marker='o', linestyle='-')\n    plt.title(f\"Non-Null Value Count per Year – {dataset}\")\n    plt.xlabel(\"Year\")\n    plt.ylabel(\"Count of countries that has data\")\n    plt.xticks(rotation=45)\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## So based on the result, I think after 2000, we have an acceptable number of countries that have data ( all of them at least have 50 coountires after this year with the valid data)\n## So I filter the dataset for after 2000, please let me know if you want to change this\n## This frame would be our base table for our left join \n## summary_all\n\n\n## I've noticed that for some csv files. we do not have code, so I just want to left join on YEsr and Country\n\ncolumns_to_check = [\"Year\", \"Entity\", \"Code\"]\n\ndataframes = {\n    \"df_censorship\": df_censorship,\n    \"df_employment_discrimination\": df_employment_discrimination,\n    \"df_gini\": df_gini,\n    \"df_gdp\": df_gdp,\n    \"df_education\": df_education,\n    \"df_gender_care\": df_gender_care,\n    \"df_marriage\": df_marriage,\n    \"df_legal_gender\": df_legal_gender,\n}\n\nfor name, df in dataframes.items():\n    print(f\"\\n{name} - Nulls in Key Columns:\")\n    for col in columns_to_check:\n        if col in df.columns:\n            null_count = df[col].isnull().sum()\n            print(f\"  {col}: {null_count} null(s)\")\n        else:\n            print(f\"  {col}: Column not found\")\n\n\ndf_censorship - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 0 null(s)\n\ndf_employment_discrimination - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 0 null(s)\n\ndf_gini - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 133 null(s)\n\ndf_gdp - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 458 null(s)\n\ndf_education - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 428 null(s)\n\ndf_gender_care - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 0 null(s)\n\ndf_marriage - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 0 null(s)\n\ndf_legal_gender - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 0 null(s)\n\n\n\n# First, I combined all datasets into one long DataFrame \nall_data = pd.concat([\n    df_censorship[[\"Entity\", \"Code\", \"Year\"]],\n    df_employment_discrimination[[\"Entity\",\"Code\", \"Year\"]],\n    df_gini[[\"Entity\",\"Code\", \"Year\"]],\n    df_gdp[[\"Entity\",\"Code\", \"Year\"]],\n    df_education[[\"Entity\",\"Code\", \"Year\"]],\n    df_gender_care[[\"Entity\",\"Code\", \"Year\"]],\n    df_marriage[[\"Entity\",\"Code\", \"Year\"]],\n    df_legal_gender[[\"Entity\",\"Code\", \"Year\"]],\n], ignore_index=True)\n\n##\n## Show rows where 'Code' is null\nnull_code_rows = all_data[all_data[\"Code\"].isna()]\nprint(null_code_rows)\n\n                                Entity Code  Year\n3108                 Argentina (urban)  NaN  1980\n3109                 Argentina (urban)  NaN  1986\n3110                 Argentina (urban)  NaN  1987\n3111                 Argentina (urban)  NaN  1991\n3112                 Argentina (urban)  NaN  1992\n...                                ...  ...   ...\n18012  Western and Central Africa (WB)  NaN  2018\n18013  Western and Central Africa (WB)  NaN  2019\n18014  Western and Central Africa (WB)  NaN  2020\n18015  Western and Central Africa (WB)  NaN  2021\n18016  Western and Central Africa (WB)  NaN  2022\n\n[1019 rows x 3 columns]\n\n\n\nimport pandas as pd\n\n## Create a mapping from Entity → Code using non-null values\nentity_to_code_map = (\n    all_data[all_data[\"Code\"].notna()]\n    .drop_duplicates(subset=\"Entity\")\n    .set_index(\"Entity\")[\"Code\"]\n    .to_dict()\n)\n\n## Create lists to store matched and unmatched entity names\nmatched_entities = []\nunmatched_entities = []\n\n## Fill missing codes and track matches\ndef fill_code_and_track(row):\n    if pd.isna(row[\"Code\"]):\n        matched_code = entity_to_code_map.get(row[\"Entity\"])\n        if matched_code is not None:\n            matched_entities.append(row[\"Entity\"])\n            return matched_code\n        else:\n            unmatched_entities.append(row[\"Entity\"])\n            return None\n    return row[\"Code\"]\n\nall_data[\"Code\"] = all_data.apply(fill_code_and_track, axis=1)\n\n## Remove duplicates from tracking lists\nmatched_entities = sorted(set(matched_entities))\nunmatched_entities = sorted(set(unmatched_entities))\n\nprint(\"✅ Finished filling missing Code values.\")\nprint(f\"✅ {len(matched_entities)} entities were successfully matched:\")\nfor entity in matched_entities:\n    print(\"  ✓\", entity)\n\nprint(\"\\n❗ Entities with no Code found:\")\nfor entity in unmatched_entities:\n    print(\"  ✗\", entity)\n\nprint(f\"\\n🧮 Remaining rows with missing Code: {all_data['Code'].isna().sum()}\")\n## As we can see for these countries, we do not have code, please let mw know, what should we do for them \n\n✅ Finished filling missing Code values.\n✅ 0 entities were successfully matched:\n\n❗ Entities with no Code found:\n  ✗ Arab World (WB)\n  ✗ Argentina (urban)\n  ✗ Bolivia (urban)\n  ✗ Central Europe and the Baltics (WB)\n  ✗ China (rural)\n  ✗ China (urban)\n  ✗ Colombia (urban)\n  ✗ EU (27)\n  ✗ East Asia and Pacific (WB)\n  ✗ East Asia and the Pacific (WB)\n  ✗ Ecuador (urban)\n  ✗ Ethiopia (rural)\n  ✗ Europe and Central Asia (WB)\n  ✗ European Union (27)\n  ✗ Faeroe Islands\n  ✗ High-income countries\n  ✗ Honduras (urban)\n  ✗ India (rural)\n  ✗ India (urban)\n  ✗ Latin America and Caribbean (WB)\n  ✗ Low-income countries\n  ✗ Lower-middle-income countries\n  ✗ Micronesia (country) (urban)\n  ✗ Middle East and North Africa (WB)\n  ✗ Middle-income countries\n  ✗ North America (WB)\n  ✗ Rwanda (rural)\n  ✗ South Asia (WB)\n  ✗ Southern and Eastern Africa (WB)\n  ✗ Sub-Saharan Africa (WB)\n  ✗ Suriname (urban)\n  ✗ Upper-middle-income countries\n  ✗ Uruguay (urban)\n  ✗ Western and Central Africa (WB)\n\n🧮 Remaining rows with missing Code: 1019\n\n\n\n## So I just created my base table based on Year and Country and filtered it out for Year &gt; 2000\nfiltered_data = all_data[all_data[\"Year\"] &gt; 2000]\nbase_table = filtered_data[[\"Year\", \"Entity\", \"Code\"]].drop_duplicates()\nbase_table = base_table.sort_values(by=[\"Year\", \"Entity\"]).reset_index(drop=True)\nbase_table\n\n\n\n\n\n\n\n\nYear\nEntity\nCode\n\n\n\n\n0\n2001\nAfghanistan\nAFG\n\n\n1\n2001\nAlbania\nALB\n\n\n2\n2001\nAlgeria\nDZA\n\n\n3\n2001\nAndorra\nAND\n\n\n4\n2001\nAngola\nAGO\n\n\n...\n...\n...\n...\n\n\n5637\n2025\nVenezuela\nVEN\n\n\n5638\n2025\nVietnam\nVNM\n\n\n5639\n2025\nYemen\nYEM\n\n\n5640\n2025\nZambia\nZMB\n\n\n5641\n2025\nZimbabwe\nZWE\n\n\n\n\n5642 rows × 3 columns\n\n\n\n\nmerged_wide_df = base_table.copy()\ndatasets = {\n    \"censorship\": df_censorship,\n    \"employment\": df_employment_discrimination,\n    \"gini\": df_gini,\n    \"gdp\": df_gdp,\n    \"education\": df_education,\n    \"gendercare\": df_gender_care,\n    \"marriage\": df_marriage,\n    \"legalgender\": df_legal_gender,\n}\n\n\nfor name, df in datasets.items():\n\n    value_cols = [col for col in df.columns if col not in [\"Entity\", \"Year\"]]\n    df_renamed = df.rename(columns={col: f\"{col}_{name}\" for col in value_cols})\n    merged_wide_df = merged_wide_df.merge(\n        df_renamed,\n        on=[\"Entity\", \"Year\"],\n        how=\"left\"\n    )\n\nprint(\"Final shape:\", merged_wide_df.shape)\n\nFinal shape: (5642, 20)\n\n\n\nmerged_wide_df.head()\n\n\n\n\n\n\n\n\nYear\nEntity\nCode\nCode_censorship\nCensorship of LGBT+ issues (historical)_censorship\nCode_employment\nLGBT+ employment discrimination (historical)_employment\nCode_gini\nGini coefficient_gini\n990179-annotations_gini\nCode_gdp\nGDP per capita, PPP (constant 2021 international $)_gdp\nCode_education\nPublic spending on education as a share of GDP_education\nCode_gendercare\nGender-affirming care (historical)_gendercare\nCode_marriage\nSame-sex marriage (historical)_marriage\nCode_legalgender\nRight to change legal gender (historical)_legalgender\n\n\n\n\n0\n2001\nAfghanistan\nAFG\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAFG\n1454.1108\nNaN\nNaN\nNaN\nNaN\nAFG\nBanned\nNaN\nNaN\n\n\n1\n2001\nAlbania\nALB\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nALB\n7215.8200\nALB\n3.4587\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n2001\nAlgeria\nDZA\nDZA\nImprisonment as punishment\nNaN\nNaN\nNaN\nNaN\nNaN\nDZA\n11742.5950\nNaN\nNaN\nNaN\nNaN\nDZA\nBanned\nNaN\nNaN\n\n\n3\n2001\nAndorra\nAND\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAND\n59109.0160\nNaN\nNaN\nAND\nRestricted\nNaN\nNaN\nNaN\nNaN\n\n\n4\n2001\nAngola\nAGO\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAGO\n6049.1630\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nprint(\"Long format shape:\", merged_wide_df.shape)\n\nLong format shape: (5642, 20)\n\n\n\nlist(merged_wide_df.columns)\n\n['Year',\n 'Entity',\n 'Code',\n 'Code_censorship',\n 'Censorship of LGBT+ issues (historical)_censorship',\n 'Code_employment',\n 'LGBT+ employment discrimination (historical)_employment',\n 'Code_gini',\n 'Gini coefficient_gini',\n '990179-annotations_gini',\n 'Code_gdp',\n 'GDP per capita, PPP (constant 2021 international $)_gdp',\n 'Code_education',\n 'Public spending on education as a share of GDP_education',\n 'Code_gendercare',\n 'Gender-affirming care (historical)_gendercare',\n 'Code_marriage',\n 'Same-sex marriage (historical)_marriage',\n 'Code_legalgender',\n 'Right to change legal gender (historical)_legalgender']\n\n\n\n# Drop all columns that start with 'Code_'\nmerged_wide_df = merged_wide_df.loc[:, ~merged_wide_df.columns.str.contains(\"Code_\")]\nlist(merged_wide_df.columns)\n\n['Year',\n 'Entity',\n 'Code',\n 'Censorship of LGBT+ issues (historical)_censorship',\n 'LGBT+ employment discrimination (historical)_employment',\n 'Gini coefficient_gini',\n '990179-annotations_gini',\n 'GDP per capita, PPP (constant 2021 international $)_gdp',\n 'Public spending on education as a share of GDP_education',\n 'Gender-affirming care (historical)_gendercare',\n 'Same-sex marriage (historical)_marriage',\n 'Right to change legal gender (historical)_legalgender']\n\n\n\nexclude_cols = [\"Entity\", \"Year\"]\nvalue_cols = merged_wide_df.columns.difference(exclude_cols)\ncleaned_long_df = merged_wide_df.dropna(subset=value_cols, how='all').reset_index(drop=True)\nprint(\"Shape after cleaning:\", cleaned_long_df.shape)\ncleaned_long_df\n\nShape after cleaning: (5642, 12)\n\n\n\n\n\n\n\n\n\nYear\nEntity\nCode\nCensorship of LGBT+ issues (historical)_censorship\nLGBT+ employment discrimination (historical)_employment\nGini coefficient_gini\n990179-annotations_gini\nGDP per capita, PPP (constant 2021 international $)_gdp\nPublic spending on education as a share of GDP_education\nGender-affirming care (historical)_gendercare\nSame-sex marriage (historical)_marriage\nRight to change legal gender (historical)_legalgender\n\n\n\n\n0\n2001\nAfghanistan\nAFG\nNaN\nNaN\nNaN\nNaN\n1454.1108\nNaN\nNaN\nBanned\nNaN\n\n\n1\n2001\nAlbania\nALB\nNaN\nNaN\nNaN\nNaN\n7215.8200\n3.4587\nNaN\nNaN\nNaN\n\n\n2\n2001\nAlgeria\nDZA\nImprisonment as punishment\nNaN\nNaN\nNaN\n11742.5950\nNaN\nNaN\nBanned\nNaN\n\n\n3\n2001\nAndorra\nAND\nNaN\nNaN\nNaN\nNaN\n59109.0160\nNaN\nRestricted\nNaN\nNaN\n\n\n4\n2001\nAngola\nAGO\nNaN\nNaN\nNaN\nNaN\n6049.1630\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5637\n2025\nVenezuela\nVEN\nNo censorship\nSexual orientation only\nNaN\nNaN\nNaN\nNaN\nRestricted\nBanned\nIllegal\n\n\n5638\n2025\nVietnam\nVNM\nNo censorship\nNo protections\nNaN\nNaN\nNaN\nNaN\nLegal\nBanned\nLegal, surgery required\n\n\n5639\n2025\nYemen\nYEM\nState-enforced\nNaN\nNaN\nNaN\nNaN\nNaN\nBanned\nBanned\nIllegal\n\n\n5640\n2025\nZambia\nZMB\nImprisonment as punishment\nNo protections\nNaN\nNaN\nNaN\nNaN\nBanned\nBanned\nIllegal\n\n\n5641\n2025\nZimbabwe\nZWE\nImprisonment as punishment\nNo protections\nNaN\nNaN\nNaN\nNaN\nRestricted\nBanned\nIllegal\n\n\n\n\n5642 rows × 12 columns\n\n\n\n\ncleaned_long_df.tail()\n\n\n\n\n\n\n\n\nYear\nEntity\nCode\nCensorship of LGBT+ issues (historical)_censorship\nLGBT+ employment discrimination (historical)_employment\nGini coefficient_gini\n990179-annotations_gini\nGDP per capita, PPP (constant 2021 international $)_gdp\nPublic spending on education as a share of GDP_education\nGender-affirming care (historical)_gendercare\nSame-sex marriage (historical)_marriage\nRight to change legal gender (historical)_legalgender\n\n\n\n\n5637\n2025\nVenezuela\nVEN\nNo censorship\nSexual orientation only\nNaN\nNaN\nNaN\nNaN\nRestricted\nBanned\nIllegal\n\n\n5638\n2025\nVietnam\nVNM\nNo censorship\nNo protections\nNaN\nNaN\nNaN\nNaN\nLegal\nBanned\nLegal, surgery required\n\n\n5639\n2025\nYemen\nYEM\nState-enforced\nNaN\nNaN\nNaN\nNaN\nNaN\nBanned\nBanned\nIllegal\n\n\n5640\n2025\nZambia\nZMB\nImprisonment as punishment\nNo protections\nNaN\nNaN\nNaN\nNaN\nBanned\nBanned\nIllegal\n\n\n5641\n2025\nZimbabwe\nZWE\nImprisonment as punishment\nNo protections\nNaN\nNaN\nNaN\nNaN\nRestricted\nBanned\nIllegal\n\n\n\n\n\n\n\n\nprint(cleaned_long_df.columns.tolist())\n\n['Year', 'Entity', 'Code', 'Censorship of LGBT+ issues (historical)_censorship', 'LGBT+ employment discrimination (historical)_employment', 'Gini coefficient_gini', '990179-annotations_gini', 'GDP per capita, PPP (constant 2021 international $)_gdp', 'Public spending on education as a share of GDP_education', 'Gender-affirming care (historical)_gendercare', 'Same-sex marriage (historical)_marriage', 'Right to change legal gender (historical)_legalgender']\n\n\n\ncleaned_long_df.columns = (\n    cleaned_long_df.columns\n    .str.replace(\"Entity\", \"country\", regex=False)\n    .str.replace(\"Year\", \"year\", regex=False)\n    .str.replace(\"Code\", \"country-code\", regex=False)\n    .str.replace(\"Censorship of LGBT+ issues (historical)_censorship\", \"lgbtq-censorship\", regex=False)\n    .str.replace(\"LGBT+ employment discrimination (historical)_employment\", \"employment-discrimination\", regex=False)\n    .str.replace(\"Gini coefficient_gini\", \"gini-index\", regex=False)\n    .str.replace(\"990179-annotations_gini\", \"inequality-annotations\", regex=False)\n    .str.replace(\"GDP per capita, PPP (constant 2021 international $)_gdp\", \"gdp-per-capita\", regex=False)\n    .str.replace(\"Public spending on education as a share of GDP_education\", \"education-spending-gdp\", regex=False)\n    .str.replace(\"Gender-affirming care (historical)_gendercare\", \"gender-affirming-care\", regex=False)\n    .str.replace(\"Same-sex marriage (historical)_marriage\", \"same-sex-marriage\", regex=False)\n    .str.replace(\"Right to change legal gender (historical)_legalgender\", \"legal-gender\", regex=False)\n)\n\n\ncleaned_long_df\n\n\n\n\n\n\n\n\nyear\ncountry\ncountry-code\nlgbtq-censorship\nemployment-discrimination\ngini-index\ninequality-annotations\ngdp-per-capita\neducation-spending-gdp\ngender-affirming-care\nsame-sex-marriage\nlegal-gender\n\n\n\n\n0\n2001\nAfghanistan\nAFG\nNaN\nNaN\nNaN\nNaN\n1454.1108\nNaN\nNaN\nBanned\nNaN\n\n\n1\n2001\nAlbania\nALB\nNaN\nNaN\nNaN\nNaN\n7215.8200\n3.4587\nNaN\nNaN\nNaN\n\n\n2\n2001\nAlgeria\nDZA\nImprisonment as punishment\nNaN\nNaN\nNaN\n11742.5950\nNaN\nNaN\nBanned\nNaN\n\n\n3\n2001\nAndorra\nAND\nNaN\nNaN\nNaN\nNaN\n59109.0160\nNaN\nRestricted\nNaN\nNaN\n\n\n4\n2001\nAngola\nAGO\nNaN\nNaN\nNaN\nNaN\n6049.1630\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5637\n2025\nVenezuela\nVEN\nNo censorship\nSexual orientation only\nNaN\nNaN\nNaN\nNaN\nRestricted\nBanned\nIllegal\n\n\n5638\n2025\nVietnam\nVNM\nNo censorship\nNo protections\nNaN\nNaN\nNaN\nNaN\nLegal\nBanned\nLegal, surgery required\n\n\n5639\n2025\nYemen\nYEM\nState-enforced\nNaN\nNaN\nNaN\nNaN\nNaN\nBanned\nBanned\nIllegal\n\n\n5640\n2025\nZambia\nZMB\nImprisonment as punishment\nNo protections\nNaN\nNaN\nNaN\nNaN\nBanned\nBanned\nIllegal\n\n\n5641\n2025\nZimbabwe\nZWE\nImprisonment as punishment\nNo protections\nNaN\nNaN\nNaN\nNaN\nRestricted\nBanned\nIllegal\n\n\n\n\n5642 rows × 12 columns\n\n\n\n\nprint(cleaned_long_df.dtypes)\n\nyear                           int64\ncountry                       object\ncountry-code                  object\nlgbtq-censorship              object\nemployment-discrimination     object\ngini-index                   float64\ninequality-annotations       float64\ngdp-per-capita               float64\neducation-spending-gdp       float64\ngender-affirming-care         object\nsame-sex-marriage             object\nlegal-gender                  object\ndtype: object\n\n\n\nfloat_cols = cleaned_long_df.select_dtypes(include=[\"float64\"]).columns\ncleaned_long_df[float_cols] = cleaned_long_df[float_cols].round(2)\n\n\neda_summary = pd.DataFrame({\n    \"Non-Null Count\": cleaned_long_df.notnull().sum(),\n    \"Total Rows\": len(cleaned_long_df),\n    \"Non-Null %\": cleaned_long_df.notnull().mean() * 100,\n    \"Data Type\": cleaned_long_df.dtypes\n})\n\n\neda_summary = eda_summary.sort_values(by=\"Non-Null Count\", ascending=False)\neda_summary[\"Non-Null %\"] = eda_summary[\"Non-Null %\"].round(1)\neda_summary.reset_index(inplace=True)\neda_summary.rename(columns={\"index\": \"Column\"}, inplace=True)\n\n\neda_summary\n\n\n\n\n\n\n\n\nColumn\nNon-Null Count\nTotal Rows\nNon-Null %\nData Type\n\n\n\n\n0\nyear\n5642\n5642\n100.0\nint64\n\n\n1\ncountry\n5642\n5642\n100.0\nobject\n\n\n2\ncountry-code\n5144\n5642\n91.2\nobject\n\n\n3\ngdp-per-capita\n4841\n5642\n85.8\nfloat64\n\n\n4\neducation-spending-gdp\n3601\n5642\n63.8\nfloat64\n\n\n5\nsame-sex-marriage\n2892\n5642\n51.3\nobject\n\n\n6\nlegal-gender\n2000\n5642\n35.4\nobject\n\n\n7\ngini-index\n1664\n5642\n29.5\nfloat64\n\n\n8\ngender-affirming-care\n1661\n5642\n29.4\nobject\n\n\n9\nemployment-discrimination\n1496\n5642\n26.5\nobject\n\n\n10\nlgbtq-censorship\n964\n5642\n17.1\nobject\n\n\n11\ninequality-annotations\n0\n5642\n0.0\nfloat64\n\n\n\n\n\n\n\n\ncleaned_long_df.to_csv(\"../data/clean/LGBTIQ-rights_clean.csv\", index=False)"
  },
  {
    "objectID": "scripts/bcindegeniouslistings_clean.html",
    "href": "scripts/bcindegeniouslistings_clean.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport re\n\nLoad the raw data\n\n# Load the data\ndf = pd.read_csv(\"../bcindigenousbusinesslistings3.csv\")\n\nInspecting the data\n\n# Inspect the data\nprint(df.info())\nprint(df.head())\nprint(f\"Initial number of rows: {len(df)}\") \n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1259 entries, 0 to 1258\nData columns (total 12 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Business Name        1259 non-null   object \n 1   Description          1135 non-null   object \n 2   Web Site             699 non-null    object \n 3   City                 1258 non-null   object \n 4   Latitude             1258 non-null   float64\n 5   Longitude            1258 non-null   float64\n 6   Keywords             1257 non-null   object \n 7   Region               1259 non-null   object \n 8   Type                 1123 non-null   object \n 9   Industry Sector      1222 non-null   object \n 10  Year Formed          648 non-null    float64\n 11  Number of Employees  572 non-null    object \ndtypes: float64(3), object(9)\nmemory usage: 118.2+ KB\nNone\n                                       Business Name  \\\n0                                Ellipsis Energy Inc   \n1  Indigenous Community Development & Prosperity ...   \n2                         Formline Construction Ltd.   \n3                          Quilakwa Investments Ltd.   \n4                                      Quilakwa Esso   \n\n                                         Description  \\\n0  Ellipsis Energy Inc is an Aboriginal owned com...   \n1  ICDPRO works together with Indigenous communit...   \n2  With over combined 30 years of experience in t...   \n3  Quilakwa Investments Ltd. oversees several Ind...   \n4  Quilakwa Esso is owned by the Splatsin Indian ...   \n\n                                      Web Site           City   Latitude  \\\n0                 http://www.ellipsisenergy.ca  Moberly Lake   55.819370   \n1  https://indigenouscommunitydevelopment.com/        Enderby  50.551498   \n2                        https://www.flcon.ca/        Burnaby  49.266050   \n3                    http://www.splatsindc.com        Enderby  50.537507   \n4                                          NaN        Enderby  50.537507   \n\n    Longitude                                           Keywords  \\\n0 -121.834602  Ellipsis Energy Inc 21 – Mining, quarrying, an...   \n1 -119.133546  Indigenous Community Development & Prosperity ...   \n2  123.005840       Formline Construction Ltd. 23 – Construction   \n3 -119.141955                          Quilakwa Investments Ltd.   \n4 -119.141955                 Quilakwa Esso 44-45 - Retail trade   \n\n                       Region                     Type  \\\n0                   Northeast          Private Company   \n1         Thompson / Okanagan          Private Company   \n2  Lower Mainland / Southwest          Private Company   \n3         Thompson / Okanagan  Community Owned Company   \n4         Thompson / Okanagan  Community Owned Company   \n\n                                     Industry Sector  Year Formed  \\\n0  21 – Mining, quarrying, and oil and gas extrac...       2012.0   \n1  81 – Other services (except public administrat...       2020.0   \n2                                  23 – Construction       2021.0   \n3               72 – Accommodation and food services       1984.0   \n4                               44-45 - Retail trade       1984.0   \n\n  Number of Employees  \n0              5 to 9  \n1              1 to 4  \n2              1 to 4  \n3            20 to 49  \n4            10 to 19  \nInitial number of rows: 1259\n\n\nColumn Name Standardization\n\n#  Clean column names (convert to lowercase and replace spaces with underscores)\ndf.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n\nRemove Unnecessary Columns\n\n# Remove unnecessary columns\ncolumns_to_drop = ['description', 'web_site', 'keywords']\ndf = df.drop(columns=columns_to_drop, errors='ignore')\n\nRemoval of Duplicates\n\n# Remove duplicate rows\ndf = df.drop_duplicates()\n\n\n# check no of rows after removing duplicates\nprint(f\"No of rows after removing duplicates: {len(df)}\") \n\nNo of rows after removing duplicates: 1259\n\n\nCritical Data Validation\n\n# Remove rows missing critical information\n#business_name is a mandatory field here\nif 'business_name' in df.columns:\n    df = df[df['business_name'].notna() & (df['business_name'] != '')]\n\n\n# check no of rows after removing rows missing critical information\nprint(f\"No of rows: {len(df)}\") \n\nNo of rows: 1259\n\n\nEnsure Year is an integer\n\n# Ensure year_formed is a nullable integer\ndf['year_formed'] = pd.to_numeric(df['year_formed'], errors='coerce').astype('Int64')\n\nCleanup industry_sector\n\n# custom function to standardize industry_sector data\ndef clean_industry_sector(sector):\n    if pd.isna(sector):\n        return np.nan\n    \n    # Convert to string\n    sector = str(sector).strip()\n    \n    # Handle cases starting with colon\n    if sector.startswith(':'):\n        sector = sector[1:].strip()\n    \n    # Remove ALL number patterns including:\n    # \"23 - \", \"44-45 - \", \"1.5 - \", \"54 – \" (with en dash)\n    sector = re.sub(r'^[\\d\\.]+\\s*[-–—]?\\s*[\\d\\.]*\\s*[-–—]\\s*', '', sector).strip()\n    \n    # Return np.nan if empty, otherwise capitalize first letter\n    return np.nan if not sector else sector[0].upper() + sector[1:]\n\n\nprint(\"test cleaning:\")\ntest_case = \":54 – Professional, scientific and technical services\"\nprint(f\"'{test_case}' → '{clean_industry_sector(test_case)}'\")\n\n\ndf['industry_sector'] = df['industry_sector'].apply(clean_industry_sector)\n\ntest cleaning:\n':54 – Professional, scientific and technical services' → 'Professional, scientific and technical services'\n\n\nData Formatting\n\n# Trim whitespace in string fields\ntext_cols = ['business_name', 'city', 'industry_sector','region','type']\ndf[text_cols] = df[text_cols].apply(lambda x: x.str.strip())\n\nSave the Cleaned data\n\n# Save cleaned data\ndf.to_csv(\"cleaned_indigenous_businesses.csv\", index=False)\n\nValidation of Cleaned Data\n\n# Validate cleaned data\nclean_data= pd.read_csv(\"cleaned_indigenous_businesses.csv\")\nprint(f\"Final cleaned dataset rows: {len(clean_data)}\")  # Final row count\nclean_data.head()\n\nFinal cleaned dataset rows: 1259\n\n\n\n\n\n\n\n\n\nbusiness_name\ncity\nlatitude\nlongitude\nregion\ntype\nindustry_sector\nyear_formed\nnumber_of_employees\n\n\n\n\n0\nEllipsis Energy Inc\nMoberly Lake\n55.819370\n-121.834602\nNortheast\nPrivate Company\nMining, quarrying, and oil and gas extraction\n2012.0\n5 to 9\n\n\n1\nIndigenous Community Development & Prosperity ...\nEnderby\n50.551498\n-119.133546\nThompson / Okanagan\nPrivate Company\nOther services (except public administration)\n2020.0\n1 to 4\n\n\n2\nFormline Construction Ltd.\nBurnaby\n49.266050\n123.005840\nLower Mainland / Southwest\nPrivate Company\nConstruction\n2021.0\n1 to 4\n\n\n3\nQuilakwa Investments Ltd.\nEnderby\n50.537507\n-119.141955\nThompson / Okanagan\nCommunity Owned Company\nAccommodation and food services\n1984.0\n20 to 49\n\n\n4\nQuilakwa Esso\nEnderby\n50.537507\n-119.141955\nThompson / Okanagan\nCommunity Owned Company\nRetail trade\n1984.0\n10 to 19"
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html",
    "href": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html",
    "title": "Gender marker change - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Gender marker change” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nDescribes the legislation status of the right to change legal gender. This is the legal recognition of sex reassignment by permitting a change of legal gender on an individual’s birth certificate. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Gender marker change” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#csv-structure",
    "title": "Gender marker change - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#metadata.json-structure",
    "title": "Gender marker change - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#about-the-data",
    "title": "Gender marker change - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#gender-marker-change",
    "href": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#gender-marker-change",
    "title": "Gender marker change - Data package",
    "section": "",
    "text": "Describes the legislation status of the right to change legal gender. This is the legal recognition of sex reassignment by permitting a change of legal gender on an individual’s birth certificate. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Gender marker change” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html",
    "href": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html",
    "title": "Public spending on education as a share of GDP - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Public spending on education as a share of GDP” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nTotal general government expenditure on education (all levels of government and all levels of education), given as a share of GDP. Last updated: November 4, 2024\nNext update: November 2025\nDate range: 1870–2023\nUnit: %\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nWorld Bank (2024); Tanzi & Schuknecht (2000) – processed by Our World in Data\n\n\n\nWorld Bank (2024); Tanzi & Schuknecht (2000) – processed by Our World in Data. “Public spending on education as a share of GDP” [dataset]. World Bank, “World Bank Education Statistics (EdStats)”; Tanzi & Schuknecht, “Public Expenditure on Education OECD” [original data]. Source: World Bank (2024), Tanzi & Schuknecht (2000) – processed by Our World In Data\n\n\n\n\n\n\n\n\n\nRetrieved on: 2024-11-04\nRetrieved from: https://datacatalog.worldbank.org/search/dataset/0038480/education-statistics\n\n\n\nRetrieved on: 2017-09-30\nRetrieved from: https://link.springer.com/article/10.1023%2FA%3A1017578302202?LI=true\n\n\n\nHistorical expenditure data:\nHistorical data in this dataset is based on a wide array of sources, reflecting a comprehensive approach to data collection across different time periods and regions. However, the diverse nature of these sources leads to inconsistencies, as methodologies and data quality vary between sources. For instance, older sources like the League of Nations Statistical Yearbook or Mitchell’s 1962 data may use different metrics or collection methods compared to more modern sources like the OECD Education reports or UN surveys. This variance in source material and methodology means that direct comparisons across different years or countries might be challenging, necessitating careful interpretation and cross-reference for accuracy. The dataset serves as a rich historical repository but also underscores the complexities and challenges inherent in compiling and harmonizing historical data from multiple, diverse sources.\nRecent estimates:\nGeneral government expenditure on education (current, capital, and transfers) is expressed as a percentage of GDP. It includes expenditure funded by transfers from international sources to government. General government usually refers to local, regional and central governments.\nWorld Bank variable id: SE.XPD.TOTL.GD.ZS\nOriginal source: UNESCO Institute for Statistics (UIS). UIS.Stat Bulk Data Download Service. Accessed October 24, 2022."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#csv-structure",
    "title": "Public spending on education as a share of GDP - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#metadata.json-structure",
    "title": "Public spending on education as a share of GDP - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#about-the-data",
    "title": "Public spending on education as a share of GDP - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#public-spending-on-education-as-a-share-of-gdp",
    "href": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#public-spending-on-education-as-a-share-of-gdp",
    "title": "Public spending on education as a share of GDP - Data package",
    "section": "",
    "text": "Total general government expenditure on education (all levels of government and all levels of education), given as a share of GDP. Last updated: November 4, 2024\nNext update: November 2025\nDate range: 1870–2023\nUnit: %\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nWorld Bank (2024); Tanzi & Schuknecht (2000) – processed by Our World in Data\n\n\n\nWorld Bank (2024); Tanzi & Schuknecht (2000) – processed by Our World in Data. “Public spending on education as a share of GDP” [dataset]. World Bank, “World Bank Education Statistics (EdStats)”; Tanzi & Schuknecht, “Public Expenditure on Education OECD” [original data]. Source: World Bank (2024), Tanzi & Schuknecht (2000) – processed by Our World In Data\n\n\n\n\n\n\n\n\n\nRetrieved on: 2024-11-04\nRetrieved from: https://datacatalog.worldbank.org/search/dataset/0038480/education-statistics\n\n\n\nRetrieved on: 2017-09-30\nRetrieved from: https://link.springer.com/article/10.1023%2FA%3A1017578302202?LI=true\n\n\n\nHistorical expenditure data:\nHistorical data in this dataset is based on a wide array of sources, reflecting a comprehensive approach to data collection across different time periods and regions. However, the diverse nature of these sources leads to inconsistencies, as methodologies and data quality vary between sources. For instance, older sources like the League of Nations Statistical Yearbook or Mitchell’s 1962 data may use different metrics or collection methods compared to more modern sources like the OECD Education reports or UN surveys. This variance in source material and methodology means that direct comparisons across different years or countries might be challenging, necessitating careful interpretation and cross-reference for accuracy. The dataset serves as a rich historical repository but also underscores the complexities and challenges inherent in compiling and harmonizing historical data from multiple, diverse sources.\nRecent estimates:\nGeneral government expenditure on education (current, capital, and transfers) is expressed as a percentage of GDP. It includes expenditure funded by transfers from international sources to government. General government usually refers to local, regional and central governments.\nWorld Bank variable id: SE.XPD.TOTL.GD.ZS\nOriginal source: UNESCO Institute for Statistics (UIS). UIS.Stat Bulk Data Download Service. Accessed October 24, 2022."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html",
    "href": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html",
    "title": "GDP per capita - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “GDP per capita” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nAverage economic output per person in a country or region per year. This data is adjusted for inflation and for differences in living costs between countries. Last updated: January 24, 2025\nNext update: January 2026\nDate range: 1990–2023\nUnit: international-$ in 2021 prices\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nData compiled from multiple sources by World Bank (2025) – with minor processing by Our World in Data\n\n\n\nData compiled from multiple sources by World Bank (2025) – with minor processing by Our World in Data. “GDP per capita – World Bank – In constant international-$” [dataset]. Data compiled from multiple sources by World Bank, “World Development Indicators” [original data]. Source: Data compiled from multiple sources by World Bank (2025) – with minor processing by Our World In Data\n\n\n\n\n\nGross domestic product (GDP) is a measure of the total value added from the production of goods and services in a country or region each year. GDP per capita is GDP divided by population.\nThis GDP per capita indicator provides information on economic growth and income levels from 1990.\nThis data is adjusted for inflation and for differences in living costs between countries.\nThis data is expressed in international-$ at 2021 prices.\nFor GDP per capita estimates in the long run, explore the Maddison Project Database’s indicator.\n\n\n\n\nGDP per capita based on purchasing power parity (PPP). PPP GDP is gross domestic product converted to international dollars using purchasing power parity rates. An international dollar has the same purchasing power over GDP as the U.S. dollar has in the United States. GDP at purchaser’s prices is the sum of gross value added by all resident producers in the country plus any product taxes and minus any subsidies not included in the value of the products. It is calculated without making deductions for depreciation of fabricated assets or for depletion and degradation of natural resources. Data are in constant 2021 international dollars.\nStatistical concept and methodology: For the concept and methodology of PPP, please refer to the International Comparison Program (ICP)’s website (https://www.worldbank.org/en/programs/icp).\n\n\n\n\n\nRetrieved on: 2025-01-24\nRetrieved from: https://datacatalog.worldbank.org/search/dataset/0037712/World-Development-Indicators"
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#csv-structure",
    "title": "GDP per capita - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#metadata.json-structure",
    "title": "GDP per capita - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#about-the-data",
    "title": "GDP per capita - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#gdp-per-capita-in-constant-international--world-bank",
    "href": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#gdp-per-capita-in-constant-international--world-bank",
    "title": "GDP per capita - Data package",
    "section": "",
    "text": "Average economic output per person in a country or region per year. This data is adjusted for inflation and for differences in living costs between countries. Last updated: January 24, 2025\nNext update: January 2026\nDate range: 1990–2023\nUnit: international-$ in 2021 prices\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nData compiled from multiple sources by World Bank (2025) – with minor processing by Our World in Data\n\n\n\nData compiled from multiple sources by World Bank (2025) – with minor processing by Our World in Data. “GDP per capita – World Bank – In constant international-$” [dataset]. Data compiled from multiple sources by World Bank, “World Development Indicators” [original data]. Source: Data compiled from multiple sources by World Bank (2025) – with minor processing by Our World In Data\n\n\n\n\n\nGross domestic product (GDP) is a measure of the total value added from the production of goods and services in a country or region each year. GDP per capita is GDP divided by population.\nThis GDP per capita indicator provides information on economic growth and income levels from 1990.\nThis data is adjusted for inflation and for differences in living costs between countries.\nThis data is expressed in international-$ at 2021 prices.\nFor GDP per capita estimates in the long run, explore the Maddison Project Database’s indicator.\n\n\n\n\nGDP per capita based on purchasing power parity (PPP). PPP GDP is gross domestic product converted to international dollars using purchasing power parity rates. An international dollar has the same purchasing power over GDP as the U.S. dollar has in the United States. GDP at purchaser’s prices is the sum of gross value added by all resident producers in the country plus any product taxes and minus any subsidies not included in the value of the products. It is calculated without making deductions for depreciation of fabricated assets or for depletion and degradation of natural resources. Data are in constant 2021 international dollars.\nStatistical concept and methodology: For the concept and methodology of PPP, please refer to the International Comparison Program (ICP)’s website (https://www.worldbank.org/en/programs/icp).\n\n\n\n\n\nRetrieved on: 2025-01-24\nRetrieved from: https://datacatalog.worldbank.org/search/dataset/0037712/World-Development-Indicators"
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html",
    "href": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html",
    "title": "Income inequality: Gini coefficient - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Income inequality: Gini coefficient” on the Our World in Data website.\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe remaining columns are the data columns, each of which is a time series. If the CSV data is downloaded using the “full data” option, then each column corresponds to one time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data columns are transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\nAll data and visualizations on Our World in Data rely on data sourced from one or several original data providers. Preparing this original data involves several processing steps. Depending on the data, this can include standardizing country names and world region definitions, converting units, calculating derived indicators such as per capita measures, as well as adding or adapting metadata such as the name or the description given to an indicator. Read about our data pipeline\n\n\n\n\n\n\n\nThe Gini coefficient measures inequality on a scale from 0 to 1. Higher values indicate higher inequality. Last updated: October 7, 2024\nNext update: May 2025\nDate range: 1963–2023\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nWorld Bank Poverty and Inequality Platform (2024) – with major processing by Our World in Data\n\n\n\nWorld Bank Poverty and Inequality Platform (2024) – with major processing by Our World in Data. “Gini Coefficient – World Bank” [dataset]. World Bank Poverty and Inequality Platform, “World Bank Poverty and Inequality Platform (PIP) 20240627_2017, 20240627_2011” [original data]. Source: World Bank Poverty and Inequality Platform (2024) – with major processing by Our World In Data\n\n\n\n\n\nDepending on the country and year, the data relates to income measured after taxes and benefits, or to consumption, per capita. ‘Per capita’ means that the income of each household is attributed equally to each member of the household (including children).\nNon-market sources of income, including food grown by subsistence farmers for their own consumption, are taken into account.\n\n\n\n\n\n\nRetrieved on: 2024-10-07\nRetrieved from: https://pip.worldbank.org\n\n\n\nFor most countries in the PIP dataset, estimates relate to either disposable income or consumption, for all available years. A number of countries, however, have a mix of income and consumption data points, with both data types sometimes available for particular years.\nIn most of our charts, we present the data with some data points dropped in order to present single series for each country. This allows us to make readable visualizations that combine multiple countries and metrics. In choosing which data points to drop, we try to strike a balance between maintaining comparability over time and showing as long a time series as possible. As such, the exact approach varies somewhat across countries.\nIf you would like to see the original data with all available income and consumption data points shown separately, you can do so in our Poverty Data Explorer. You can also download this data in our complete dataset of the World Bank PIP data."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#csv-structure",
    "title": "Income inequality: Gini coefficient - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe remaining columns are the data columns, each of which is a time series. If the CSV data is downloaded using the “full data” option, then each column corresponds to one time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data columns are transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#metadata.json-structure",
    "title": "Income inequality: Gini coefficient - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#about-the-data",
    "title": "Income inequality: Gini coefficient - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\nAll data and visualizations on Our World in Data rely on data sourced from one or several original data providers. Preparing this original data involves several processing steps. Depending on the data, this can include standardizing country names and world region definitions, converting units, calculating derived indicators such as per capita measures, as well as adding or adapting metadata such as the name or the description given to an indicator. Read about our data pipeline"
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#gini-coefficient-world-bank",
    "href": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#gini-coefficient-world-bank",
    "title": "Income inequality: Gini coefficient - Data package",
    "section": "",
    "text": "The Gini coefficient measures inequality on a scale from 0 to 1. Higher values indicate higher inequality. Last updated: October 7, 2024\nNext update: May 2025\nDate range: 1963–2023\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nWorld Bank Poverty and Inequality Platform (2024) – with major processing by Our World in Data\n\n\n\nWorld Bank Poverty and Inequality Platform (2024) – with major processing by Our World in Data. “Gini Coefficient – World Bank” [dataset]. World Bank Poverty and Inequality Platform, “World Bank Poverty and Inequality Platform (PIP) 20240627_2017, 20240627_2011” [original data]. Source: World Bank Poverty and Inequality Platform (2024) – with major processing by Our World In Data\n\n\n\n\n\nDepending on the country and year, the data relates to income measured after taxes and benefits, or to consumption, per capita. ‘Per capita’ means that the income of each household is attributed equally to each member of the household (including children).\nNon-market sources of income, including food grown by subsistence farmers for their own consumption, are taken into account.\n\n\n\n\n\n\nRetrieved on: 2024-10-07\nRetrieved from: https://pip.worldbank.org\n\n\n\nFor most countries in the PIP dataset, estimates relate to either disposable income or consumption, for all available years. A number of countries, however, have a mix of income and consumption data points, with both data types sometimes available for particular years.\nIn most of our charts, we present the data with some data points dropped in order to present single series for each country. This allows us to make readable visualizations that combine multiple countries and metrics. In choosing which data points to drop, we try to strike a balance between maintaining comparability over time and showing as long a time series as possible. As such, the exact approach varies somewhat across countries.\nIf you would like to see the original data with all available income and consumption data points shown separately, you can do so in our Poverty Data Explorer. You can also download this data in our complete dataset of the World Bank PIP data."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html",
    "href": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html",
    "title": "Censorship of LGBT issues - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Censorship of LGBT issues” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nDescribes censorship or prohibition of discussing, promoting, or teaching LGBT+ topics in media, schools, and in the general public. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Censorship of LGBT+ issues” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#csv-structure",
    "title": "Censorship of LGBT issues - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#metadata.json-structure",
    "title": "Censorship of LGBT issues - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#about-the-data",
    "title": "Censorship of LGBT issues - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#censorship-of-lgbt-issues",
    "href": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#censorship-of-lgbt-issues",
    "title": "Censorship of LGBT issues - Data package",
    "section": "",
    "text": "Describes censorship or prohibition of discussing, promoting, or teaching LGBT+ topics in media, schools, and in the general public. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Censorship of LGBT+ issues” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html",
    "href": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html",
    "title": "Employment discrimination based on sexual orientation or gender identity - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Employment discrimination based on sexual orientation or gender identity” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nDescribes the prohibition of discrimination based on sexual orientation and/or gender identity in employment, including hiring, promotion, termination, harassment, etc. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1981–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Employment discrimination based on sexual orientation or gender identity prohibited” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#csv-structure",
    "title": "Employment discrimination based on sexual orientation or gender identity - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#metadata.json-structure",
    "title": "Employment discrimination based on sexual orientation or gender identity - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#about-the-data",
    "title": "Employment discrimination based on sexual orientation or gender identity - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#employment-discrimination-based-on-sexual-orientation-or-gender-identity-prohibited",
    "href": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#employment-discrimination-based-on-sexual-orientation-or-gender-identity-prohibited",
    "title": "Employment discrimination based on sexual orientation or gender identity - Data package",
    "section": "",
    "text": "Describes the prohibition of discrimination based on sexual orientation and/or gender identity in employment, including hiring, promotion, termination, harassment, etc. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1981–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Employment discrimination based on sexual orientation or gender identity prohibited” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html",
    "href": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html",
    "title": "Gender-affirming care - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Gender-affirming care” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nInterventions to help transgender and non-binary people align their bodies with their gender identity. This can include hormone replacement therapy, surgeries, or psychological support. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Gender-affirming care” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#csv-structure",
    "title": "Gender-affirming care - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#metadata.json-structure",
    "title": "Gender-affirming care - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#about-the-data",
    "title": "Gender-affirming care - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#gender-affirming-care",
    "href": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#gender-affirming-care",
    "title": "Gender-affirming care - Data package",
    "section": "",
    "text": "Interventions to help transgender and non-binary people align their bodies with their gender identity. This can include hormone replacement therapy, surgeries, or psychological support. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Gender-affirming care” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html",
    "href": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html",
    "title": "Marriage for same-sex partners - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Marriage for same-sex partners” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nDescribes the legislation status of same-sex marriage. This is marriage and marriage recognition between two people of the same biological sex and/or gender identity. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Marriage for same-sex partners” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#csv-structure",
    "title": "Marriage for same-sex partners - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#metadata.json-structure",
    "title": "Marriage for same-sex partners - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#about-the-data",
    "title": "Marriage for same-sex partners - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#marriage-for-same-sex-partners",
    "href": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#marriage-for-same-sex-partners",
    "title": "Marriage for same-sex partners - Data package",
    "section": "",
    "text": "Describes the legislation status of same-sex marriage. This is marriage and marriage recognition between two people of the same biological sex and/or gender identity. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Marriage for same-sex partners” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Diverse Data Hub is an open educational resource offering curated datasets focused on equity, diversity, inclusion, and other socially relevant topics. It is designed to support students, educators, and researchers in accessing and working with meaningful data in their teaching, learning, and analysis.\nDatasets are available through the diversedata R package, allowing for straightforward integration into data science workflows. Each dataset includes detailed documentation and contextual background to support informed exploration and connection to real-world topics. Example case studies are also included to illustrate practical applications.\nGet Started →"
  },
  {
    "objectID": "index.html#featured-datasets",
    "href": "index.html#featured-datasets",
    "title": "Diverse Data Hub",
    "section": "Featured Datasets",
    "text": "Featured Datasets\n\n\n\n\n\n\nWomen’s March Madness\n\n\nDescription: This data set tracks every NCAA Division I Women’s Basketball Tournament appearance since 1982 up until 2018. It includes team seeds, results, bid types, season and conference records, and regional placements. Useful for analyzing team success, seeding impact, conference strength, and historical trends in women’s college basketball over four decades.\n\nMore Details\n\n\n\n\nWildfire\n\n\nDescription: This data set on Canadian wildfires includes data on fire size, cause, location, detection method, response, and weather. Collected from official sources, it supports wildfire risk assessment and response. It also highlights social and geographic disparities, emphasizing impacts on remote and underserved communities facing climate-related and infrastructure challenges.\n\nMore Details\n\n\n\n\n\nHow Couples Meet and Stay Together\n\n\nDescription: This data set contains information from a 2022 survey of people across the U.S. to understand how couples meet and stay together. It focuses on how relationships were influenced by the COVID-19 pandemic and offers insight at modern relationships, including changes in dating habits and how couples adapted during a challenging time.\n\nMore Details\n\n\n\n\nIndigenous Businesses\n\n\nDescription: XXX\n\nMore Details\n\n\n\n\nGender Assessment\n\n\nDescription: XXX\n\nMore Details\n\n\n\n\nGlobal Rights\n\n\nDescription: XXX\n\nMore Details"
  },
  {
    "objectID": "scripts/HCMST_clean.html",
    "href": "scripts/HCMST_clean.html",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "",
    "text": "Load the necessary libraries for the clean-up, as well as the provided dataset\n\nimport pandas as pd\n\n\ndf = pd.read_csv(\"../data/raw/how-couples-meet-and-stay-together/HCMST_2017-2022.csv\")\ndf.head()\n\n\n\n\n\n\n\n\ncaseid_new\nw3_Weight\nw3_Weight_LGB\nw3_combo_weight\nw3_attrition_adj_weight\nw2_weight_genpop\nw2_weight_LGB\nw2_combo_weight\nw2_attrition_adj_weights\nw1_weight_combo\n...\np20_pppa1634\np20_pppa1902\np20_pppa1903\np20_pppa1904\np20_ppp22001\np20_pppa1905\np20_pppa1648\np20_ppp20072\np20_ppp20071\np20_ppp2date2020\n\n\n\n\n0\n53001\n0.4422\nNaN\n0.495308\n0.400185\n0.3856\nNaN\n0.437670\n0.380351\n0.426861\n...\n2.0\n0.0\n1.0\n0.0\n0.0\n0.0\n13.0\n6.0\nNaN\n20210506.0\n\n\n1\n71609\n0.8284\nNaN\n0.927891\n0.879258\n0.9196\nNaN\n1.043778\n0.953948\n1.295508\n...\n2.0\n0.0\n1.0\n0.0\n0.0\n0.0\n2.0\n5.0\n1.0\n20201118.0\n\n\n2\n106983\n0.8255\nNaN\n0.924643\n0.706467\n0.7748\nNaN\n0.879425\n0.724682\n1.126573\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n4.0\n2.0\n20210429.0\n\n\n3\n121759\nNaN\nNaN\nNaN\nNaN\n0.9177\nNaN\n1.041622\n0.793093\n0.933440\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n11.0\n2.0\n1.0\n20210507.0\n\n\n4\n158083\n0.8810\nNaN\n0.986809\n0.655467\n0.8697\nNaN\n0.987140\n0.735473\n0.931291\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n13.0\n6.0\nNaN\n20210602.0\n\n\n\n\n5 rows × 725 columns\n\n\n\n\ndf.shape\n\n(3510, 725)"
  },
  {
    "objectID": "scripts/HCMST_clean.html#loading-csv",
    "href": "scripts/HCMST_clean.html#loading-csv",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "",
    "text": "Load the necessary libraries for the clean-up, as well as the provided dataset\n\nimport pandas as pd\n\n\ndf = pd.read_csv(\"../data/raw/how-couples-meet-and-stay-together/HCMST_2017-2022.csv\")\ndf.head()\n\n\n\n\n\n\n\n\ncaseid_new\nw3_Weight\nw3_Weight_LGB\nw3_combo_weight\nw3_attrition_adj_weight\nw2_weight_genpop\nw2_weight_LGB\nw2_combo_weight\nw2_attrition_adj_weights\nw1_weight_combo\n...\np20_pppa1634\np20_pppa1902\np20_pppa1903\np20_pppa1904\np20_ppp22001\np20_pppa1905\np20_pppa1648\np20_ppp20072\np20_ppp20071\np20_ppp2date2020\n\n\n\n\n0\n53001\n0.4422\nNaN\n0.495308\n0.400185\n0.3856\nNaN\n0.437670\n0.380351\n0.426861\n...\n2.0\n0.0\n1.0\n0.0\n0.0\n0.0\n13.0\n6.0\nNaN\n20210506.0\n\n\n1\n71609\n0.8284\nNaN\n0.927891\n0.879258\n0.9196\nNaN\n1.043778\n0.953948\n1.295508\n...\n2.0\n0.0\n1.0\n0.0\n0.0\n0.0\n2.0\n5.0\n1.0\n20201118.0\n\n\n2\n106983\n0.8255\nNaN\n0.924643\n0.706467\n0.7748\nNaN\n0.879425\n0.724682\n1.126573\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n4.0\n2.0\n20210429.0\n\n\n3\n121759\nNaN\nNaN\nNaN\nNaN\n0.9177\nNaN\n1.041622\n0.793093\n0.933440\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n11.0\n2.0\n1.0\n20210507.0\n\n\n4\n158083\n0.8810\nNaN\n0.986809\n0.655467\n0.8697\nNaN\n0.987140\n0.735473\n0.931291\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n13.0\n6.0\nNaN\n20210602.0\n\n\n\n\n5 rows × 725 columns\n\n\n\n\ndf.shape\n\n(3510, 725)"
  },
  {
    "objectID": "scripts/HCMST_clean.html#full-list-of-variables",
    "href": "scripts/HCMST_clean.html#full-list-of-variables",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Full List of Variables",
    "text": "Full List of Variables\nThe next cell displays the full list of variables in the original data set. We are not going to use everything…\nWe’ll focus on variables of interest for specific inquiries.\nIn the following links, we can find the encoding of each variable.\nData source: https://data.stanford.edu/hcmst2017\nVariable List per year (Note w1 = 2017, w2 = 2020, w3 = 2022): https://stacks.stanford.edu/file/druid:tq903pj6286/HCMST%202017-%202022%20user%27s%20guide%20v2.3.pdf\nDetailed Info on variables: https://stacks.stanford.edu/file/druid:hg921sg6829/HCMST%202017%20to%202022%20v2.2%20codebook.pdf\n\n#df.columns.tolist()"
  },
  {
    "objectID": "scripts/HCMST_clean.html#variables-of-interest",
    "href": "scripts/HCMST_clean.html#variables-of-interest",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Variables of Interest",
    "text": "Variables of Interest\nThe following lists are not actually used in the rest of the notebook for data cleaning purposes.\nStill, they display the selected variables of interest (and how their names vary from year to year), so, we are leaving them in the notebook for documentation.\n\n# ppage = Age\n# ppeduc = Education (Highest Degree Received)\n# ppgender = Gender\n# ppethm =  Race / Ethnicity \n# ppincimp = Household Income\n# ppwork = Current Employment Status \n\nsubject_demographics_2017 = [\n    'w1_ppage', 'w1_ppeduc', 'w1_ppgender', 'w1_ppethm', 'w1_ppincimp', 'w1_ppwork'\n]\nsubject_demographics_2020 = [\n    'w2_ppage', 'w2_ppeduc', 'w2_ppgender', 'w2_ppethm', 'w2_ppincimp', 'w2_ppwork'\n]\nsubject_demographics_2022 = [\n    'w3_ppage', 'w3_ppeduc', 'w3_ppgender', 'w3_ppethm', 'w3_ppincimp', 'w3_ppwork'\n]\n\n\n# q4 = Partner Gender\n# q9 = Partner Age\n# q6b = Partner's Race\n# q10 = Partner's Education (Highest Degree Received)\n\npartner_demographics_2017 = [\n    'w1_q4', 'w1_q9', 'w1_q6b', 'w1_q10'\n]\npartner_demographics_2020 = [\n    'w2_Q4', 'w2_Q9', 'w2_Q6B', 'w2_Q10'\n]\npartner_demographics_2022 = [\n    'w3_Q4', 'w3_Q9', 'w3_Q6B', 'w3_Q10'\n]\n\n\n# same_sex_couple = same-sex couple\n# married = Married\n# q34/rel_qual_combo/rel_qual = Relationship quality 1 (Excellent) to 5 (Very Poor) - Potential Target\n\nrelationship_status_2017 = [\n    'w1_same_sex_couple', 'w1_married', 'w1_q34'\n]\nrelationship_status_2020 = [\n    'w2_same_sex_couple', 'w2_married', 'w2_rel_qual_combo'\n]\nrelationship_status_2022 = [\n    'w3_same_sex_couple', 'w3_married', 'w3_rel_qual'\n]\n\n\n# q21b - Year current relationship started\n# q21d - Year of marriage\n# q21e - Year relationship ended\n# relate/relationship duration = Duration of relationship in years\n\nrelationship_time_2017 = [\n    'w1_q21b_year', 'w1_q21d_year', 'w1_q21e_year', 'w1_relate_duration_in2017_years'\n]\nrelationship_time_2020 = [\n    'w2_q21b_year', 'w2_q21d_year', 'w2_q21e_year', 'w2_relationship_duration'\n]\nrelationship_time_2022 = [\n    'w3_Q21B_year', 'w3_Q21D_year', 'w3_Q21E_year', 'w3_relationship_duration_yrs'\n]\n\n\n# PPT01 = # of children in the household ages 0-1\n# PPT25 = # of children in the household ages 2-5\n# PPT612 = # of children in the household ages 6-12\n# PPT1317 = # of children in the household ages 13-17\n# PPT18OV = # of children in the household ages 18-Over\n\nchildren_info_2017 = [\n    'w1_PPT01', 'w1_PPT25', 'w1_PPT612', 'w1_PPT1317', 'w1_PPT18OV'\n]\nchildren_info_2020 = [\n    'w2_PPT01', 'w2_PPT25', 'w2_PPT612', 'w2_PPT1317', 'w2_PPT18OV'\n]\nchildren_info_2022 = [\n    'w3_PPT01', 'w3_PPT25', 'w3_PPT612', 'w3_PPT1317', 'w3_PPT18OV'\n]\n\n\n# Only available in 2022 in full (Post-COVID)\n\n# coronavirus_effect_combo = Is relationship better or worse during pandemic\n# pandemic_income = has income gone up or down during pandemic\n# subject/partner_had_COVID = has been sick with COVID\n# corona/partner_vaccine = has been vaccinated\n# COVID_agreement = subject and partner agree on approach to pandemic\n\ncovid_vars_2022 = [\n    'w3_coronavirus_effect_combo', 'w3_pandemic_income', 'w3_subject_had_COVID', 'w3_partner_had_COVID', 'w3_corona_vaccine',\n    'w3_partner_corona_vaccine', 'w3_COVID_agreement'\n]\n\n\n# Only some variables available per year\n\n# sex_frequency = Frequency of sex\n# flirt = how often flirt\n# fight = how often fight\n# monogamy = subject's commitment to monogamy\n# p_monogamy = expected commitment to monogamy from partner\n\nrelationship_quality_2017 = [\n    'w1_sex_frequency'\n]\nrelationship_quality_2020 = [\n    'w2_sex_frequency', 'w2_flirt', 'w2_fight'\n]\nrelationship_quality_2022 = [\n    'w3_sex_frequency', 'w3_flirt', 'w3_fight'\n]"
  },
  {
    "objectID": "scripts/HCMST_clean.html#rename-columns",
    "href": "scripts/HCMST_clean.html#rename-columns",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Rename Columns",
    "text": "Rename Columns\nSome variables contain the same information but vary in name year to year. So, we’ll need 3 renaming dictionaries (1 per year)\nFirst, the 3 renaming maps (one per year):\n\ncolumn_renames_2017 = {\n    #subject_demographics\n    'w1_ppage': 'subject_age',\n    'w1_ppeduc': 'subject_education',\n    'w1_ppgender': 'subject_sex',\n    'w1_ppethm': 'subject_ethnicity',\n    'w1_ppincimp': 'subject_income_category',\n    'w1_ppwork': 'subject_employment_status',\n    #partner_demographics\n    'w1_q4': 'partner_sex',\n    'w1_q9': 'partner_age',\n    'w1_q6b': 'partner_ethnicity',\n    'w1_q10': 'partner_education',\n    #relationship_status\n    'w1_same_sex_couple': 'same_sex_couple',\n    'w1_married': 'married',\n    'w1_q34': 'relationship_quality',\n    #relationship_time\n    'w1_q21b_year': 'relationship_start_year',\n    'w1_q21d_year': 'marriage_year',\n    'w1_q21e_year': 'break_up_year',\n    'w1_relate_duration_in2017_years': 'relationship_duration',\n    #children_info\n    'w1_PPT01': 'kids_0_1',\n    'w1_PPT25': 'kids_2_5',\n    'w1_PPT612': 'kids_6_12',\n    'w1_PPT1317': 'kids_13_17',\n    'w1_PPT18OV': 'kids_18_plus',\n    #covidvars\n    #'w1_coronavirus_effect_combo': 'rel_change_during_pandemic',\n    #'w1_pandemic_income': 'inc_change_during_pandemic',\n    #'w1_subject_had_COVID': 'subject_had_covid', \n    #'w1_partner_had_COVID': 'partner_had_covid', \n    #'w1_corona_vaccine': 'subject_vaccinated',\n    #'w1_partner_corona_vaccine': 'partner_vaccinated', \n    #'w1_COVID_agreement': 'agree_covid_approach',\n    #relationship_quality\n    'w1_sex_frequency': 'sex_frequency',\n    #'w3_flirt': 'flirts_with_partner',\n    #'w3_fight': 'fights_with_partner',\n}\n\n\ncolumn_renames_2020 = {\n    #subject_demographics\n    'w2_ppage': 'subject_age',\n    'w2_ppeduc': 'subject_education',\n    'w2_ppgender': 'subject_sex',\n    'w2_ppethm': 'subject_ethnicity',\n    'w2_ppincimp': 'subject_income_category',\n    'w2_ppwork': 'subject_employment_status',\n    #partner_demographics\n    'w2_Q4': 'partner_sex',\n    'w2_Q9': 'partner_age',\n    'w2_Q6B': 'partner_ethnicity',\n    'w2_Q10': 'partner_education',\n    #relationship_status\n    'w2_same_sex_couple': 'same_sex_couple',\n    'w2_married': 'married',\n    'w2_rel_qual_combo': 'relationship_quality',\n    #relationship_time\n    'w2_q21b_year': 'relationship_start_year',\n    'w2_q21d_year': 'marriage_year',\n    'w2_q21e_year': 'break_up_year',\n    'w2_relationship_duration': 'relationship_duration',\n    #children_info\n    'w2_PPT01': 'kids_0_1',\n    'w2_PPT25': 'kids_2_5',\n    'w2_PPT612': 'kids_6_12',\n    'w2_PPT1317': 'kids_13_17',\n    'w2_PPT18OV': 'kids_18_plus',\n    #covidvars\n    #'w2_coronavirus_effect_combo': 'rel_change_during_pandemic',\n    #'w2_pandemic_income': 'inc_change_during_pandemic',\n    #'w2_subject_had_COVID': 'subject_had_covid', \n    #'w2_partner_had_COVID': 'partner_had_covid', \n    #'w2_corona_vaccine': 'subject_vaccinated',\n    #'w2_partner_corona_vaccine': 'partner_vaccinated', \n    #'w2_COVID_agreement': 'agree_covid_approach',\n    #relationship_quality\n    'w2_sex_frequency': 'sex_frequency',\n    'w2_flirt': 'flirts_with_partner',\n    'w2_fight': 'fights_with_partner',\n}\n\n\ncolumn_renames_2022 = {\n    #subject_demographics\n    'w3_ppage': 'subject_age',\n    'w3_ppeduc': 'subject_education',\n    'w3_ppgender': 'subject_sex',\n    'w3_ppethm': 'subject_ethnicity',\n    'w3_ppincimp': 'subject_income_category',\n    'w3_ppwork': 'subject_employment_status',\n    #partner_demographics\n    'w3_Q4': 'partner_sex',\n    'w3_Q9': 'partner_age',\n    'w3_Q6B': 'partner_ethnicity',\n    'w3_Q10': 'partner_education',\n    #relationship_status\n    'w3_same_sex_couple': 'same_sex_couple',\n    'w3_married': 'married',\n    'w3_rel_qual': 'relationship_quality',\n    #relationship_time\n    'w3_Q21B_year': 'relationship_start_year',\n    'w3_Q21D_year': 'marriage_year',\n    'w3_Q21E_year': 'break_up_year',\n    'w3_relationship_duration_yrs': 'relationship_duration',\n    #children_info\n    'w3_PPT01': 'kids_0_1',\n    'w3_PPT25': 'kids_2_5',\n    'w3_PPT612': 'kids_6_12',\n    'w3_PPT1317': 'kids_13_17',\n    'w3_PPT18OV': 'kids_18_plus',\n    #covidvars\n    'w3_coronavirus_effect_combo': 'rel_change_during_pandemic',\n    'w3_pandemic_income': 'inc_change_during_pandemic',\n    'w3_subject_had_COVID': 'subject_had_covid', \n    'w3_partner_had_COVID': 'partner_had_covid', \n    'w3_corona_vaccine': 'subject_vaccinated',\n    'w3_partner_corona_vaccine': 'partner_vaccinated', \n    'w3_COVID_agreement': 'agree_covid_approach',\n    #relationship_quality\n    'w3_sex_frequency': 'sex_frequency',\n    'w3_flirt': 'flirts_with_partner',\n    'w3_fight': 'fights_with_partner',\n}\n\n\nDataframe per year\nWe need to create dataframes per year while renaming variables in each dictionary.\nWe will also create a column named “Wave” that contains the year of the survey.\nFirst, 2017:\n\ndf_2017 = df[['caseid_new'] + list(column_renames_2017.keys())].rename(columns=column_renames_2017)\ndf_2017['wave'] = '2017'\ndf_2017.head()\n\n\n\n\n\n\n\n\ncaseid_new\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\n...\nmarriage_year\nbreak_up_year\nrelationship_duration\nkids_0_1\nkids_2_5\nkids_6_12\nkids_13_17\nkids_18_plus\nsex_frequency\nwave\n\n\n\n\n0\n53001\n48\n9\n2\n5\n13\n1\n1.0\n46.0\n1.0\n...\n2014.0\nNaN\n3.583333\n0\n0\n0\n0\n1\n3.0\n2017\n\n\n1\n71609\n68\n10\n2\n1\n12\n1\n1.0\n71.0\n1.0\n...\n1969.0\nNaN\n52.750000\n0\n0\n0\n0\n2\n5.0\n2017\n\n\n2\n106983\n39\n11\n1\n1\n15\n1\n2.0\n49.0\n1.0\n...\n2002.0\nNaN\n17.583334\n0\n0\n2\n0\n3\n3.0\n2017\n\n\n3\n121759\n54\n9\n1\n1\n16\n1\n2.0\n59.0\n4.0\n...\n1991.0\nNaN\n27.416666\n0\n0\n0\n0\n4\n4.0\n2017\n\n\n4\n158083\n48\n10\n1\n1\n14\n1\n2.0\n34.0\n1.0\n...\n2013.0\n2014.0\nNaN\n0\n0\n0\n0\n1\nNaN\n2017\n\n\n\n\n5 rows × 25 columns\n\n\n\n\ndf_2017.shape\n\n(3510, 25)\n\n\nThen, 2020:\n\ndf_2020 = df[['caseid_new'] + list(column_renames_2020.keys())].rename(columns=column_renames_2020)\ndf_2020['wave'] = '2020'\ndf_2020.head()\n\n\n\n\n\n\n\n\ncaseid_new\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\n...\nrelationship_duration\nkids_0_1\nkids_2_5\nkids_6_12\nkids_13_17\nkids_18_plus\nsex_frequency\nflirts_with_partner\nfights_with_partner\nwave\n\n\n\n\n0\n53001\n51.0\n9.0\n2.0\n1.0\n10.0\n1.0\n1.0\n51.0\n1.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n2.0\n5.0\n6.0\n1.0\n2020\n\n\n1\n71609\n71.0\n10.0\n2.0\n1.0\n13.0\n1.0\nNaN\nNaN\nNaN\n...\n56.0\n0.0\n0.0\n0.0\n0.0\n1.0\n5.0\n6.0\n4.0\n2020\n\n\n2\n106983\n42.0\n11.0\n1.0\n1.0\n15.0\n1.0\nNaN\nNaN\nNaN\n...\n21.0\n0.0\n0.0\n1.0\n1.0\n3.0\n3.0\n2.0\n3.0\n2020\n\n\n3\n121759\n57.0\n9.0\n1.0\n1.0\n16.0\n1.0\nNaN\nNaN\nNaN\n...\n31.0\n0.0\n0.0\n0.0\n0.0\n2.0\n4.0\n6.0\n1.0\n2020\n\n\n4\n158083\n52.0\n10.0\n1.0\n1.0\n18.0\n1.0\nNaN\nNaN\nNaN\n...\nNaN\n0.0\n0.0\n0.0\n0.0\n3.0\nNaN\nNaN\nNaN\n2020\n\n\n\n\n5 rows × 27 columns\n\n\n\n\ndf_2020.shape\n\n(3510, 27)\n\n\nThen, 2022:\n\ndf_2022 = df[['caseid_new'] + list(column_renames_2022.keys())].rename(columns=column_renames_2022)\ndf_2022['wave'] = '2022'\ndf_2022.head()\n\n\n\n\n\n\n\n\ncaseid_new\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\n...\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nsex_frequency\nflirts_with_partner\nfights_with_partner\nwave\n\n\n\n\n0\n53001\n53.0\n9.0\n2.0\n1.0\n10.0\n1.0\nNaN\nNaN\nNaN\n...\n3.0\n0.0\n1.0\n4.0\n4.0\n1.0\n3.0\n2.0\n1.0\n2022\n\n\n1\n71609\n72.0\n10.0\n2.0\n1.0\n14.0\n1.0\nNaN\nNaN\nNaN\n...\n2.0\n0.0\n0.0\n1.0\n1.0\n2.0\n5.0\n6.0\n8.0\n2022\n\n\n2\n106983\n43.0\n11.0\n1.0\n1.0\n14.0\n1.0\nNaN\nNaN\nNaN\n...\n2.0\n0.0\n0.0\n1.0\n1.0\n1.0\n3.0\n2.0\n3.0\n2022\n\n\n3\n121759\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\n\n\n4\n158083\n53.0\n10.0\n1.0\n1.0\n18.0\n1.0\nNaN\nNaN\nNaN\n...\n3.0\n0.0\nNaN\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\n\n\n\n\n5 rows × 34 columns\n\n\n\n\ndf_2022.shape\n\n(3510, 34)"
  },
  {
    "objectID": "scripts/HCMST_clean.html#a-single-dataframe",
    "href": "scripts/HCMST_clean.html#a-single-dataframe",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "A single Dataframe",
    "text": "A single Dataframe\nNow, we can concatenate the 3 dataframes since they have the same variables. We’ll have the “wave” column to differentiate by year.\n\ndf_cleaned = pd.concat([df_2017, df_2020, df_2022], ignore_index=True)\n\n\ndf_cleaned.shape\n\n(10530, 34)\n\n\n\ndf_cleaned.head()\n\n\n\n\n\n\n\n\ncaseid_new\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\n...\nwave\nflirts_with_partner\nfights_with_partner\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\n\n\n\n\n0\n53001\n48.0\n9.0\n2.0\n5.0\n13.0\n1.0\n1.0\n46.0\n1.0\n...\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n71609\n68.0\n10.0\n2.0\n1.0\n12.0\n1.0\n1.0\n71.0\n1.0\n...\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n106983\n39.0\n11.0\n1.0\n1.0\n15.0\n1.0\n2.0\n49.0\n1.0\n...\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n121759\n54.0\n9.0\n1.0\n1.0\n16.0\n1.0\n2.0\n59.0\n4.0\n...\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n158083\n48.0\n10.0\n1.0\n1.0\n14.0\n1.0\n2.0\n34.0\n1.0\n...\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 34 columns\n\n\n\nWe are just going to rename the ‘caseid_new’ to something more simple:\n\ndf_cleaned = df_cleaned.rename(columns={'caseid_new': 'id'})\n\n\nSelected variables\n\ndf_cleaned.columns.tolist()\n\n['id',\n 'subject_age',\n 'subject_education',\n 'subject_sex',\n 'subject_ethnicity',\n 'subject_income_category',\n 'subject_employment_status',\n 'partner_sex',\n 'partner_age',\n 'partner_ethnicity',\n 'partner_education',\n 'same_sex_couple',\n 'married',\n 'relationship_quality',\n 'relationship_start_year',\n 'marriage_year',\n 'break_up_year',\n 'relationship_duration',\n 'kids_0_1',\n 'kids_2_5',\n 'kids_6_12',\n 'kids_13_17',\n 'kids_18_plus',\n 'sex_frequency',\n 'wave',\n 'flirts_with_partner',\n 'fights_with_partner',\n 'rel_change_during_pandemic',\n 'inc_change_during_pandemic',\n 'subject_had_covid',\n 'partner_had_covid',\n 'subject_vaccinated',\n 'partner_vaccinated',\n 'agree_covid_approach']\n\n\nMerging kids of all ages to a single feature:\n\ndf_cleaned['children'] = df_cleaned['kids_0_1'] + df_cleaned['kids_2_5'] + df_cleaned['kids_6_12'] + df_cleaned['kids_13_17'] + df_cleaned['kids_18_plus']\n\ndf_cleaned.drop(columns=['kids_0_1', 'kids_2_5', 'kids_6_12', 'kids_13_17', 'kids_18_plus'], inplace=True)\n\n\ndf_cleaned.head()\n\n\n\n\n\n\n\n\nid\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\n...\nflirts_with_partner\nfights_with_partner\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nchildren\n\n\n\n\n0\n53001\n48.0\n9.0\n2.0\n5.0\n13.0\n1.0\n1.0\n46.0\n1.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n1\n71609\n68.0\n10.0\n2.0\n1.0\n12.0\n1.0\n1.0\n71.0\n1.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n2\n106983\n39.0\n11.0\n1.0\n1.0\n15.0\n1.0\n2.0\n49.0\n1.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n5.0\n\n\n3\n121759\n54.0\n9.0\n1.0\n1.0\n16.0\n1.0\n2.0\n59.0\n4.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n4\n158083\n48.0\n10.0\n1.0\n1.0\n14.0\n1.0\n2.0\n34.0\n1.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n\n\n5 rows × 30 columns"
  },
  {
    "objectID": "scripts/HCMST_clean.html#data-type-exploration",
    "href": "scripts/HCMST_clean.html#data-type-exploration",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Data Type Exploration",
    "text": "Data Type Exploration\nWe can see what data type each column has. We can note that all columns are encoded with numerical values.\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nprint(df_cleaned.dtypes)\n\nid                              int64\nsubject_age                   float64\nsubject_education             float64\nsubject_sex                   float64\nsubject_ethnicity             float64\nsubject_income_category       float64\nsubject_employment_status     float64\npartner_sex                   float64\npartner_age                   float64\npartner_ethnicity             float64\npartner_education             float64\nsame_sex_couple               float64\nmarried                       float64\nrelationship_quality          float64\nrelationship_start_year       float64\nmarriage_year                 float64\nbreak_up_year                 float64\nrelationship_duration         float64\nsex_frequency                 float64\nwave                           object\nflirts_with_partner           float64\nfights_with_partner           float64\nrel_change_during_pandemic    float64\ninc_change_during_pandemic    float64\nsubject_had_covid             float64\npartner_had_covid             float64\nsubject_vaccinated            float64\npartner_vaccinated            float64\nagree_covid_approach          float64\nchildren                      float64\ndtype: object"
  },
  {
    "objectID": "scripts/HCMST_clean.html#decoding-variables",
    "href": "scripts/HCMST_clean.html#decoding-variables",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Decoding Variables",
    "text": "Decoding Variables\nWe’ll need to re-map column content to something more interpretable.\nGoing column by column…\nFirst, education level:\n\nedu_mapping = {\n    1: 'no_education',\n    2: '1st_4th_grade',\n    3: '5th_6th_grade',\n    4: '7th_8th_grade',\n    5: '9th',\n    6: '10th',\n    7: '11th',\n    8: '12th_nodiploma',\n    9: 'high_school_grad',\n    10: 'some_college',\n    11: 'associate_degree',\n    12: 'bach_degree',\n    13: 'masters_degree',\n    14: 'prof_doct_degree'\n}\n\ndf_cleaned['subject_education'] = df_cleaned['subject_education'].map(edu_mapping)\ndf_cleaned['partner_education'] = df_cleaned['partner_education'].map(edu_mapping)\n\nordered_levels = [\n    'no_education',\n    '1st_4th_grade',\n    '5th_6th_grade',\n    '7th_8th_grade',\n    '9th',\n    '10th',\n    '11th',\n    '12th_nodiploma',\n    'high_school_grad',\n    'some_college',\n    'associate_degree',\n    'bach_degree',\n    'masters_degree',\n    'prof_doct_degree'\n]\n\n# Convert to ordered categorical\ndf_cleaned['subject_education'] = pd.Categorical(\n    df_cleaned['subject_education'],\n    categories=ordered_levels,\n    ordered=True\n)\n\ndf_cleaned['partner_education'] = pd.Categorical(\n    df_cleaned['partner_education'],\n    categories=ordered_levels,\n    ordered=True\n)\n\nThen gender:\n\ngender_mapping = {\n    1: 'male',\n    2: 'female',\n    3: 'other'\n}\n\ndf_cleaned['subject_sex'] = df_cleaned['subject_sex'].map(gender_mapping)\ndf_cleaned['partner_sex'] = df_cleaned['partner_sex'].map(gender_mapping)\n\nThen, ethniticy/race:\n\neth_sub_mapping = {\n    1: 'white',\n    2: 'black',\n    3: 'other',\n    4: 'hispanic',\n    5: '2_plus_eth'\n}\n\ndf_cleaned['subject_ethnicity'] = df_cleaned['subject_ethnicity'].map(eth_sub_mapping)\n\neth_part_mapping = {\n    1: 'white',\n    2: 'black',\n    3: 'american_indian',\n    4: 'asian',\n    5: 'other'\n}\n\ndf_cleaned['partner_ethnicity'] = df_cleaned['partner_ethnicity'].map(eth_part_mapping)\n\nThen, income level:\n\nincome_mapping = {\n    1: 'under_5k',\n    2: '5k_7k',\n    3: '7k_10k',\n    4: '10k_12k',\n    5: '12k_15k',\n    6: '15k_20k',\n    7: '20k_25k',\n    8: '25k_30k',\n    9: '30k_35k',\n    10: '35k_40k',\n    11: '40k_50k',\n    12: '50k_60k',\n    13: '60k_75k',\n    14: '75k_85k',\n    15: '85k_100k',\n    16: '100k_125k',\n    17: '125k_150k',\n    18: '150k_175k',\n    19: '175k_200k',\n    20: '200k_250k',\n    21: 'over_250k'\n}\n\ndf_cleaned['subject_income_category'] = df_cleaned['subject_income_category'].map(income_mapping)\n\nordered_income_levels = [\n    'under_5k', '5k_7k', '7k_10k', '10k_12k', '12k_15k', '15k_20k',\n    '20k_25k', '25k_30k', '30k_35k', '35k_40k', '40k_50k', '50k_60k',\n    '60k_75k', '75k_85k', '85k_100k', '100k_125k', '125k_150k',\n    '150k_175k', '175k_200k', '200k_250k', 'over_250k'\n]\n\ndf_cleaned['subject_income_category'] = pd.Categorical(\n    df_cleaned['subject_income_category'],\n    categories=ordered_income_levels,\n    ordered=True\n)\n\nThen, employment status:\n\nemployment_mapping = {\n    1: 'working_paid_employee',\n    2: 'working_self_employed',\n    3: 'not_working_temp_layoff',\n    4: 'not_working_looking',\n    5: 'not_working_retired',\n    6: 'not_working_disabled',\n    7: 'not_working_other'\n}\n\ndf_cleaned['subject_employment_status'] = df_cleaned['subject_employment_status'].map(employment_mapping)\n\nThen, same-sex couple encoding:\n\nsame_sex_couple_map = {\n    0: 'no',\n    1: 'yes'\n}\n\ndf_cleaned['same_sex_couple'] = df_cleaned['same_sex_couple'].map(same_sex_couple_map)\n\nThen, marital status:\n\nmarried_mapping = {\n    0: 'not_married',\n    1: 'married'\n}\n\ndf_cleaned['married'] = df_cleaned['married'].map(married_mapping)\n\nThen, relationship quality (THIS COULD BE A TARGET VARIABLE FOR MANY STUDIES):\n\nrel_qual_mapping = {\n    1: 'excellent',\n    2: 'good',\n    3: 'fair',\n    4: 'poor',\n    5: 'very_poor'\n}\n\ndf_cleaned['relationship_quality'] = df_cleaned['relationship_quality'].map(rel_qual_mapping)\n\nThen, the effect of COVID on the relationship. Note that all COVID variables only appear in the 2022 survey.\n\ncovid_effect_mapping = {\n    1: 'better_than_before',\n    2: 'no_change',\n    3: 'worse_than_before'\n}\n\ndf_cleaned['rel_change_during_pandemic'] = df_cleaned['rel_change_during_pandemic'].map(covid_effect_mapping)\n\nThen, the effect of COVID on income level.\n\ncovid_income_mapping = {\n    1: 'much_worse',\n    2: 'worse',\n    3: 'no_change',\n    4: 'better',\n    5: 'much_better'\n}\n\ndf_cleaned['inc_change_during_pandemic'] = df_cleaned['inc_change_during_pandemic'].map(covid_income_mapping)\n\nThen, if subject or partner had COVID\n\nhad_covid_mapping = {\n    0: 'no',\n    1: 'yes'\n}\n\ndf_cleaned['subject_had_covid'] = df_cleaned['subject_had_covid'].map(had_covid_mapping)\ndf_cleaned['partner_had_covid'] = df_cleaned['partner_had_covid'].map(had_covid_mapping)\n\nThen, status of COVID vaccination:\n\ncorona_vaccine_mapping = {\n    1: 'fully_vaccinated_and_booster',\n    2: 'fully_vaccinated_no_booster',\n    3: 'partially_vaccinated',\n    4: 'not_vaccinated'\n}\n\ndf_cleaned['subject_vaccinated'] = df_cleaned['subject_vaccinated'].map(corona_vaccine_mapping)\ndf_cleaned['partner_vaccinated'] = df_cleaned['partner_vaccinated'].map(corona_vaccine_mapping)\n\nThen, if the couple agrees on COVID approach:\n\ncovid_agreement_mapping = {\n    1: 'completely_agree',\n    2: 'mostly_agree',\n    3: 'mostly_disagree',\n    4: 'completely_disagree'\n}\n\ndf_cleaned['agree_covid_approach'] = df_cleaned['agree_covid_approach'].map(covid_agreement_mapping)\n\nThen, sex frequency:\n\nsex_frequency_mapping = {\n    1: 'once_or_more_a_day',\n    2: '3_to_6_times_a_week',\n    3: 'once_or_twice_a_week',\n    4: '2_to_3_times_a_month',\n    5: 'once_a_month_or_less'\n}\n\ndf_cleaned['sex_frequency'] = df_cleaned['sex_frequency'].map(sex_frequency_mapping)\n\nThen, how often the subject flirts with partner:\n\nflirt_mapping = {\n    1: 'every_day',\n    2: 'a_few_times_a_week',\n    3: 'once_a_week',\n    4: '1_to_3_times_a_month',\n    5: 'less_than_once_a_month',\n    6: 'never'\n}\n\ndf_cleaned['flirts_with_partner'] = df_cleaned['flirts_with_partner'].map(flirt_mapping)\n\nordered_flirt_frequency_levels = [\n    'every_day',\n    'a_few_times_a_week',\n    'once_a_week',\n    '1_to_3_times_a_month',\n    'less_than_once_a_month',\n    'never'\n]\n\ndf_cleaned['flirts_with_partner'] = pd.Categorical(\n    df_cleaned['flirts_with_partner'],\n    categories=ordered_flirt_frequency_levels,\n    ordered=True\n)\n\nThen, how often the subject fights with partner:\n\nfight_mapping = {\n    1: '0_times',\n    2: '1_time',\n    3: '2_times',\n    4: '3_times',\n    5: '4_times',\n    6: '5_times',\n    7: '6_times',\n    8: '7_or_more_times'\n}\n\ndf_cleaned['fights_with_partner'] = df_cleaned['fights_with_partner'].map(fight_mapping)\n\nordered_fight_frequency_levels = [\n    '0_times',\n    '1_time',\n    '2_times',\n    '3_times',\n    '4_times',\n    '5_times',\n    '6_times',\n    '7_or_more_times'\n]\n\ndf_cleaned['fights_with_partner'] = pd.Categorical(\n    df_cleaned['fights_with_partner'],\n    categories=ordered_fight_frequency_levels,\n    ordered=True\n)\n\nNow, we can see the updated data types for each variable.\nWe can also see a sample of how the data looks after the recoding process.\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nprint(df_cleaned.dtypes)\n\nid                               int64\nsubject_age                    float64\nsubject_education             category\nsubject_sex                     object\nsubject_ethnicity               object\nsubject_income_category       category\nsubject_employment_status       object\npartner_sex                     object\npartner_age                    float64\npartner_ethnicity               object\npartner_education             category\nsame_sex_couple                 object\nmarried                         object\nrelationship_quality            object\nrelationship_start_year        float64\nmarriage_year                  float64\nbreak_up_year                  float64\nrelationship_duration          float64\nsex_frequency                   object\nwave                            object\nflirts_with_partner           category\nfights_with_partner           category\nrel_change_during_pandemic      object\ninc_change_during_pandemic      object\nsubject_had_covid               object\npartner_had_covid               object\nsubject_vaccinated              object\npartner_vaccinated              object\nagree_covid_approach            object\nchildren                       float64\ndtype: object\n\n\n\ndf_cleaned.sample(20)\n\n\n\n\n\n\n\n\nid\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\npartner_education\nsame_sex_couple\nmarried\nrelationship_quality\nrelationship_start_year\nmarriage_year\nbreak_up_year\nrelationship_duration\nsex_frequency\nwave\nflirts_with_partner\nfights_with_partner\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nchildren\n\n\n\n\n1835\n2317447\n43.0\nbach_degree\nmale\nwhite\n75k_85k\nworking_paid_employee\nfemale\n44.0\nwhite\nassociate_degree\nno\nmarried\nexcellent\n2012.0\n2013.0\nNaN\n5.500000\nonce_or_twice_a_week\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n1203\n1974471\n70.0\nmasters_degree\nfemale\nwhite\n30k_35k\nnot_working_retired\nmale\n74.0\nwhite\nhigh_school_grad\nno\nnot_married\nNaN\n1986.0\nNaN\nNaN\nNaN\nNaN\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n3656\n813467\n63.0\nbach_degree\nfemale\nwhite\n60k_75k\nnot_working_retired\nNaN\nNaN\nNaN\nNaN\nno\nmarried\nexcellent\nNaN\nNaN\nNaN\n41.000000\nonce_a_month_or_less\n2020\n1_to_3_times_a_month\n2_times\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n1657\n2228497\n27.0\nhigh_school_grad\nmale\nwhite\n30k_35k\nnot_working_disabled\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n4525\n1902763\n62.0\nassociate_degree\nmale\nwhite\n20k_25k\nworking_paid_employee\nNaN\nNaN\nNaN\nNaN\nNaN\nnot_married\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2020\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n1888\n2338241\n38.0\n12th_nodiploma\nmale\nwhite\n35k_40k\nworking_paid_employee\nfemale\n37.0\nwhite\nhigh_school_grad\nno\nmarried\nexcellent\n1996.0\n2000.0\nNaN\n20.916666\nonce_or_twice_a_week\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n6896\n2948877\n62.0\nhigh_school_grad\nmale\nwhite\n25k_30k\nnot_working_retired\nNaN\nNaN\nNaN\nNaN\nno\nmarried\ngood\nNaN\nNaN\nNaN\n46.000000\nonce_a_month_or_less\n2020\nnever\n1_time\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n2260\n2565397\n69.0\nbach_degree\nmale\nwhite\n75k_85k\nnot_working_retired\nfemale\n65.0\nasian\nsome_college\nno\nmarried\ngood\n1971.0\n1973.0\nNaN\n45.583332\nonce_a_month_or_less\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.0\n\n\n6693\n2913341\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2020\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n7264\n1018305\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n6925\n2954057\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2020\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n10239\n2920753\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n9129\n2463691\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n10255\n2922621\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n773\n1760115\n64.0\nhigh_school_grad\nfemale\nwhite\n15k_20k\nnot_working_retired\nmale\n55.0\nwhite\nhigh_school_grad\nno\nnot_married\nexcellent\n2011.0\nNaN\nNaN\n6.333333\nonce_or_twice_a_week\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n2141\n2482081\n38.0\nbach_degree\nmale\nhispanic\n150k_175k\nworking_paid_employee\nfemale\n38.0\nwhite\nmasters_degree\nno\nmarried\nexcellent\n1999.0\n2003.0\nNaN\n17.833334\nonce_or_twice_a_week\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n341\n1181693\n68.0\nhigh_school_grad\nmale\nwhite\n100k_125k\nworking_paid_employee\nfemale\n67.0\nwhite\nsome_college\nno\nmarried\nexcellent\n1973.0\n1974.0\nNaN\n43.916668\nonce_or_twice_a_week\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.0\n\n\n6629\n2899207\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2020\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n9325\n2591515\n70.0\nsome_college\nmale\nwhite\n75k_85k\nworking_paid_employee\nNaN\nNaN\nNaN\nNaN\nno\nmarried\ngood\nNaN\nNaN\nNaN\n38.416668\nonce_or_twice_a_week\n2022\nnever\n2_times\nno_change\nworse\nno\nno\nfully_vaccinated_and_booster\nfully_vaccinated_and_booster\ncompletely_agree\n2.0\n\n\n2138\n2480385\n55.0\nassociate_degree\nmale\nhispanic\n30k_35k\nworking_paid_employee\nmale\n57.0\nwhite\nassociate_degree\nyes\nnot_married\ngood\n1990.0\nNaN\nNaN\n27.083334\nonce_a_month_or_less\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0"
  },
  {
    "objectID": "scripts/HCMST_clean.html#nan-percentage",
    "href": "scripts/HCMST_clean.html#nan-percentage",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "NaN Percentage",
    "text": "NaN Percentage\nBelow we can note the % of NaN values in each column.\nWe can note that most columns still has a major % of NaN values.\nThese high percentages are mostly dependent on the year of the survey.\nFor example:\n\n2017 is missing primarily COVID related info.\n2020 is missing primarily partner info, chronological info and COVID related info.\n2022 is missing primarily partner info and chronological info.\n\nThis makes sense as the documentation notes that:\n\nVariables in survey changed from year to year slightly.\n“Response rate was 3510/6753=52% in 2017, 2107/2431= 87% in 2020, and 1722/2073=83% in 2022. The Denominators in 2020 and 2022 include only subjects who remained in the KnowledgePanel, as they were the only subjects eligible to be contacted.”\n\n\ndf_cleaned.shape\n\n(10530, 30)\n\n\n\nnan_percentage_per_column = df_cleaned.isna().mean() * 100\nprint(nan_percentage_per_column)\n\nid                             0.000000\nsubject_age                   30.303894\nsubject_education             30.303894\nsubject_sex                   30.303894\nsubject_ethnicity             30.303894\nsubject_income_category       30.303894\nsubject_employment_status     30.303894\npartner_sex                   65.536562\npartner_age                   65.707502\npartner_ethnicity             65.660019\npartner_education             65.622032\nsame_sex_couple               39.563153\nmarried                       31.405508\nrelationship_quality          44.586895\nrelationship_start_year       66.666667\nmarriage_year                 79.116809\nbreak_up_year                 96.077873\nrelationship_duration         46.087369\nsex_frequency                 47.853751\nwave                           0.000000\nflirts_with_partner           70.940171\nfights_with_partner           71.975309\nrel_change_during_pandemic    87.388414\ninc_change_during_pandemic    83.741690\nsubject_had_covid             83.732194\npartner_had_covid             86.904084\nsubject_vaccinated            83.817664\npartner_vaccinated            87.245964\nagree_covid_approach          87.435897\nchildren                      30.303894\ndtype: float64\n\n\n\nnan_percentage_per_column_by_wave = (\n    df_cleaned\n    .groupby('wave')\n    .apply(lambda g: g.isna().mean() * 100)\n    .transpose()\n)\n\nprint(nan_percentage_per_column_by_wave)\n\nwave                              2017        2020       2022\nid                            0.000000    0.000000   0.000000\nsubject_age                   0.000000   39.971510  50.940171\nsubject_education             0.000000   39.971510  50.940171\nsubject_sex                   0.000000   39.971510  50.940171\nsubject_ethnicity             0.000000   39.971510  50.940171\nsubject_income_category       0.000000   39.971510  50.940171\nsubject_employment_status     0.000000   39.971510  50.940171\npartner_sex                   3.390313   95.868946  97.350427\npartner_age                   3.874644   95.868946  97.378917\npartner_ethnicity             3.732194   95.897436  97.350427\npartner_education             3.618234   95.897436  97.350427\nsame_sex_couple               3.304843   53.475783  61.908832\nmarried                       3.304843   39.971510  50.940171\nrelationship_quality         18.888889   52.962963  61.908832\nrelationship_start_year       6.666667   95.925926  97.407407\nmarriage_year                38.205128   99.658120  99.487179\nbreak_up_year                88.319088   99.943020  99.971510\nrelationship_duration        21.225071   54.045584  62.991453\nsex_frequency                23.475783   55.897436  64.188034\nwave                          0.000000    0.000000   0.000000\nflirts_with_partner         100.000000   51.225071  61.595442\nfights_with_partner         100.000000   53.589744  62.336182\nrel_change_during_pandemic  100.000000  100.000000  62.165242\ninc_change_during_pandemic  100.000000  100.000000  51.225071\nsubject_had_covid           100.000000  100.000000  51.196581\npartner_had_covid           100.000000  100.000000  60.712251\nsubject_vaccinated          100.000000  100.000000  51.452991\npartner_vaccinated          100.000000  100.000000  61.737892\nagree_covid_approach        100.000000  100.000000  62.307692\nchildren                      0.000000   39.971510  50.940171\n\n\nC:\\Users\\Paco\\AppData\\Local\\Temp\\ipykernel_56416\\437808906.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  .apply(lambda g: g.isna().mean() * 100)\n\n\nWe can remove some of the rows that are fully empty (even if they have values in “id” and “wave”)\n\ncols_to_check = df_cleaned.columns.difference(['id', 'wave'])\ndf_cleaned = df_cleaned.dropna(subset=cols_to_check, how='all')\n\n\ndf_cleaned.shape\n\n(7339, 30)\n\n\n\nnan_percentage_per_column_by_wave = (\n    df_cleaned\n    .groupby('wave')\n    .apply(lambda g: g.isna().mean() * 100)\n    .transpose()\n)\n\nprint(nan_percentage_per_column_by_wave)\n\nwave                              2017        2020       2022\nid                            0.000000    0.000000   0.000000\nsubject_age                   0.000000    0.000000   0.000000\nsubject_education             0.000000    0.000000   0.000000\nsubject_sex                   0.000000    0.000000   0.000000\nsubject_ethnicity             0.000000    0.000000   0.000000\nsubject_income_category       0.000000    0.000000   0.000000\nsubject_employment_status     0.000000    0.000000   0.000000\npartner_sex                   3.390313   93.118178  94.599303\npartner_age                   3.874644   93.118178  94.657375\npartner_ethnicity             3.732194   93.165638  94.599303\npartner_education             3.618234   93.165638  94.599303\nsame_sex_couple               3.304843   22.496440  22.357724\nmarried                       3.304843    0.000000   0.000000\nrelationship_quality         18.888889   21.642145  22.357724\nrelationship_start_year       6.666667   93.213099  94.715447\nmarriage_year                38.205128   99.430470  98.954704\nbreak_up_year                88.319088   99.905078  99.941928\nrelationship_duration        21.225071   23.445657  24.564460\nsex_frequency                23.475783   26.530612  27.003484\nwave                          0.000000    0.000000   0.000000\nflirts_with_partner         100.000000   18.747034  21.718931\nfights_with_partner         100.000000   22.686284  23.228804\nrel_change_during_pandemic  100.000000  100.000000  22.880372\ninc_change_during_pandemic  100.000000  100.000000   0.580720\nsubject_had_covid           100.000000  100.000000   0.522648\npartner_had_covid           100.000000  100.000000  19.918699\nsubject_vaccinated          100.000000  100.000000   1.045296\npartner_vaccinated          100.000000  100.000000  22.009292\nagree_covid_approach        100.000000  100.000000  23.170732\nchildren                      0.000000    0.000000   0.000000\n\n\nC:\\Users\\Paco\\AppData\\Local\\Temp\\ipykernel_56416\\437808906.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  .apply(lambda g: g.isna().mean() * 100)"
  },
  {
    "objectID": "scripts/HCMST_clean.html#final-reorganization-of-columns",
    "href": "scripts/HCMST_clean.html#final-reorganization-of-columns",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Final Reorganization of Columns",
    "text": "Final Reorganization of Columns\nGiving amount of missing data, “Partner variables” and “Chronological variables” that have significant %NaN rates in 2020 and 2022 could be removed for specific inquiries. However, I would propose to keep them in the overall dataset.\nTherefore, the final data set would be:\n\ndf_cleaned.columns\n\nIndex(['id', 'subject_age', 'subject_education', 'subject_sex',\n       'subject_ethnicity', 'subject_income_category',\n       'subject_employment_status', 'partner_sex', 'partner_age',\n       'partner_ethnicity', 'partner_education', 'same_sex_couple', 'married',\n       'relationship_quality', 'relationship_start_year', 'marriage_year',\n       'break_up_year', 'relationship_duration', 'sex_frequency', 'wave',\n       'flirts_with_partner', 'fights_with_partner',\n       'rel_change_during_pandemic', 'inc_change_during_pandemic',\n       'subject_had_covid', 'partner_had_covid', 'subject_vaccinated',\n       'partner_vaccinated', 'agree_covid_approach', 'children'],\n      dtype='object')\n\n\n\ndata = df_cleaned[['id', 'wave',  #Identifiers\n                   \n                   'subject_age', 'subject_education', 'subject_sex',  #Subject variables\n                   'subject_ethnicity', 'subject_income_category', 'subject_employment_status',\n                   \n                   'partner_sex', 'partner_age', 'partner_ethnicity', 'partner_education',  #Partner variables\n                   \n                   'same_sex_couple', 'married', 'sex_frequency', 'flirts_with_partner', 'fights_with_partner', #Couple Habits\n                   \n                   'relationship_start_year', 'marriage_year', 'break_up_year', #Chronology\n                   'relationship_duration', \n                   \n                   'children',  #Kids Info\n                   \n                   'rel_change_during_pandemic', 'inc_change_during_pandemic', #Pandemic Vars\n                   'subject_had_covid', 'partner_had_covid', 'subject_vaccinated',\n                   'partner_vaccinated', 'agree_covid_approach', \n                   \n                   'relationship_quality' #Outcome\n       ]]\n\ndata.head()\n\n\n\n\n\n\n\n\nid\nwave\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\npartner_education\nsame_sex_couple\nmarried\nsex_frequency\nflirts_with_partner\nfights_with_partner\nrelationship_start_year\nmarriage_year\nbreak_up_year\nrelationship_duration\nchildren\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nrelationship_quality\n\n\n\n\n0\n53001\n2017\n48.0\nhigh_school_grad\nfemale\n2_plus_eth\n60k_75k\nworking_paid_employee\nmale\n46.0\nwhite\nassociate_degree\nno\nmarried\nonce_or_twice_a_week\nNaN\nNaN\n2013.0\n2014.0\nNaN\n3.583333\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n1\n71609\n2017\n68.0\nsome_college\nfemale\nwhite\n50k_60k\nworking_paid_employee\nmale\n71.0\nwhite\nsome_college\nno\nmarried\nonce_a_month_or_less\nNaN\nNaN\n1964.0\n1969.0\nNaN\n52.750000\n2.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n2\n106983\n2017\n39.0\nassociate_degree\nmale\nwhite\n85k_100k\nworking_paid_employee\nfemale\n49.0\nwhite\nsome_college\nno\nmarried\nonce_or_twice_a_week\nNaN\nNaN\n1999.0\n2002.0\nNaN\n17.583334\n5.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n3\n121759\n2017\n54.0\nhigh_school_grad\nmale\nwhite\n100k_125k\nworking_paid_employee\nfemale\n59.0\nasian\nmasters_degree\nno\nmarried\n2_to_3_times_a_month\nNaN\nNaN\n1990.0\n1991.0\nNaN\n27.416666\n4.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n4\n158083\n2017\n48.0\nsome_college\nmale\nwhite\n75k_85k\nworking_paid_employee\nfemale\n34.0\nwhite\nassociate_degree\nno\nnot_married\nNaN\nNaN\nNaN\n2011.0\n2013.0\n2014.0\nNaN\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN"
  },
  {
    "objectID": "scripts/HCMST_clean.html#final-data-review",
    "href": "scripts/HCMST_clean.html#final-data-review",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Final Data Review",
    "text": "Final Data Review\n\nfor column in df_cleaned.columns:\n    print(f\"Column: {column}\")\n    print(f\"Data type: {df_cleaned[column].dtype}\")\n    print(f\"Unique values: {df_cleaned[column].unique()}\\n\")\n\nColumn: id\nData type: int64\nUnique values: [  53001   71609  106983 ... 2968971 2969933 2972135]\n\nColumn: subject_age\nData type: float64\nUnique values: [48. 68. 39. 54. 59. 72. 55. 73. 46. 43. 57. 50. 61. 79. 58. 64. 81. 70.\n 80. 53. 51. 74. 56. 40. 36. 22. 47. 78. 67. 25. 65. 38. 24. 66. 35. 26.\n 60. 71. 27. 29. 34. 76. 21. 41. 28. 19. 49. 86. 20. 23. 44. 84. 62. 63.\n 45. 52. 77. 75. 42. 82. 69. 92. 85. 32. 37. 33. 30. 31. 90. 83. 18. 87.\n 93. 89. 91. 88. 95. 97. 98.]\n\nColumn: subject_education\nData type: category\nUnique values: ['high_school_grad', 'some_college', 'associate_degree', 'bach_degree', 'masters_degree', ..., '11th', '7th_8th_grade', '1st_4th_grade', 'no_education', '5th_6th_grade']\nLength: 14\nCategories (14, object): ['no_education' &lt; '1st_4th_grade' &lt; '5th_6th_grade' &lt; '7th_8th_grade' ... 'associate_degree' &lt; 'bach_degree' &lt; 'masters_degree' &lt; 'prof_doct_degree']\n\nColumn: subject_sex\nData type: object\nUnique values: ['female' 'male']\n\nColumn: subject_ethnicity\nData type: object\nUnique values: ['2_plus_eth' 'white' 'black' 'other' 'hispanic']\n\nColumn: subject_income_category\nData type: category\nUnique values: ['60k_75k', '50k_60k', '85k_100k', '100k_125k', '75k_85k', ..., '15k_20k', '20k_25k', 'under_5k', '7k_10k', '5k_7k']\nLength: 21\nCategories (21, object): ['under_5k' &lt; '5k_7k' &lt; '7k_10k' &lt; '10k_12k' ... '150k_175k' &lt; '175k_200k' &lt; '200k_250k' &lt; 'over_250k']\n\nColumn: subject_employment_status\nData type: object\nUnique values: ['working_paid_employee' 'not_working_disabled' 'not_working_retired'\n 'not_working_looking' 'working_self_employed' 'not_working_other'\n 'not_working_temp_layoff']\n\nColumn: partner_sex\nData type: object\nUnique values: ['male' 'female' nan 'other']\n\nColumn: partner_age\nData type: float64\nUnique values: [46. 71. 49. 59. 34. 52. 75. 55. 79. 37. 63. 51. 61. 62. 74. 50. 65. 58.\n 83. 47. 70. 77. 42. 69. 24. 53. 56. 54. 57. 32. 44. 72. 28. 64. 30. nan\n 33. 60. 43. 25. 27. 31. 80. 21. 78. 67. 29. 40. 39. 76. 23. 41. 45. 82.\n 26. 66. 68. 86. 36. 84. 18. 20. 38. 73. 19. 81. 22. 91. 85. 48. -1. 87.\n 89. 35. 10. 90. 94. 95. 17. 14. 16. 11.]\n\nColumn: partner_ethnicity\nData type: object\nUnique values: ['white' 'asian' 'black' 'american_indian' 'other' nan]\n\nColumn: partner_education\nData type: category\nUnique values: ['associate_degree', 'some_college', 'masters_degree', 'bach_degree', 'high_school_grad', ..., '7th_8th_grade', '10th', 'no_education', '5th_6th_grade', '1st_4th_grade']\nLength: 15\nCategories (14, object): ['no_education' &lt; '1st_4th_grade' &lt; '5th_6th_grade' &lt; '7th_8th_grade' ... 'associate_degree' &lt; 'bach_degree' &lt; 'masters_degree' &lt; 'prof_doct_degree']\n\nColumn: same_sex_couple\nData type: object\nUnique values: ['no' nan 'yes']\n\nColumn: married\nData type: object\nUnique values: ['married' 'not_married' nan]\n\nColumn: relationship_quality\nData type: object\nUnique values: ['excellent' nan 'good' 'fair' 'very_poor' 'poor']\n\nColumn: relationship_start_year\nData type: float64\nUnique values: [2013. 1964. 1999. 1990. 2011. 1993. 1981. 1983. 1996. 2001. 2014. 1984.\n 1987. 1988. 1962. 1989. 1954. 1970. 2007.   nan 1960. 2015. 1978. 2006.\n 2016. 1991. 1986. 1997. 2010. 2017. 1968. 1998. 1980. 2004. 1982. 1972.\n 2002. 1977. 2008. 1974. 1985. 1994. 1979. 2009. 1959. 1965. 2012. 1971.\n 1976. 1961. 1958. 1995. 1969. 1953. 1973. 2003. 1992. 2000. 1967. 1966.\n 1963. 2005. 1975. 1955. 1952. 1947. 1957. 1951. 1950. 1956. 1948. 1949.\n 1942. 2020. 2019. 2018. 1920. 2021. 2022.]\n\nColumn: marriage_year\nData type: float64\nUnique values: [2014. 1969. 2002. 1991. 2013. 1997.   nan 1983. 2017. 2001. 1990. 2007.\n 1964. 1985. 1984. 1956. 1995. 1972. 2008. 1960. 1986. 2000. 2009. 1987.\n 1965. 1978. 1970. 2011. 1973. 2006. 1975. 1981. 1977. 1963. 1988. 1980.\n 1976. 1999. 1992. 1996. 1961. 1974. 1994. 1955. 2016. 2003. 1982. 1998.\n 1971. 1989. 1979. 1966. 2005. 1962. 1967. 1968. 2010. 2015. 2004. 1993.\n 1959. 2012. 1951. 1952. 1957. 1958. 1950. 1944. 1948. 1953. 2019. 2018.\n 2020. 2022. 2021.]\n\nColumn: break_up_year\nData type: float64\nUnique values: [  nan 2014. 1989. 1985. 1984. 2016. 2017. 2012. 2013. 2015. 2007. 2006.\n 2003. 2009. 1996. 2000. 1999. 2010. 1987. 1990. 1976. 2001. 1994. 1997.\n 1978. 2004. 1992. 1975. 2011. 2002. 2008. 1986. 1993. 1980. 1995. 1988.\n 1998. 1977. 2005. 1983. 1991. 2018. 2020. 2022.]\n\nColumn: relationship_duration\nData type: float64\nUnique values: [ 3.58333325e+00  5.27500000e+01  1.75833340e+01  2.74166660e+01\n             nan  2.35833340e+01  3.42500000e+01  2.36666660e+01\n  2.10000000e+01  1.64166660e+01  3.41666675e+00  3.34166679e+01\n  2.98333340e+01  2.89166660e+01  2.67500000e+01  2.80000000e+01\n  3.59166679e+01  6.29166679e+01  2.45000000e+01  2.44166660e+01\n  4.70833321e+01  1.03333330e+01  1.77500000e+01  1.66666663e+00\n  3.89166679e+01  1.80833340e+01  1.09166670e+01  3.58333321e+01\n  2.40833340e+01  2.88333340e+01  2.80833340e+01  2.65000000e+01\n  3.43333321e+01  3.11666660e+01  2.75000000e+00  5.83333349e+00\n  5.66666651e+00  1.95833340e+01  5.26666679e+01  3.95000000e+01\n  4.90833321e+01  6.41666651e+00  1.91666660e+01  3.65833321e+01\n  1.33333330e+01  3.47500000e+01  4.53333321e+01  1.46666670e+01\n  3.99166679e+01  9.16666698e+00  4.25833321e+01  3.18333340e+01\n  2.30000000e+01  3.81666679e+01  4.02500000e+01  1.15000000e+01\n  3.90833321e+01  4.93333321e+01  8.16666698e+00  3.02500000e+01\n  5.78333321e+01  5.15833321e+01  5.16666651e+00  3.10833340e+01\n  3.67500000e+01  3.88333321e+01  4.56666679e+01  3.30000000e+01\n  3.32500000e+01  4.61666679e+01  2.78333340e+01  1.33333337e+00\n  1.97500000e+01  3.80833321e+01  3.16666660e+01  3.97500000e+01\n  2.02500000e+01  5.95000000e+01  2.24166660e+01  3.40833321e+01\n  4.10000000e+01  6.66666687e-01  4.13333321e+01  4.12500000e+01\n  1.00000000e+01  2.08333325e+00  7.83333349e+00  3.22500000e+01\n  2.03333340e+01  9.41666698e+00  5.65833321e+01  3.75000000e+00\n  1.00833330e+01  2.58333325e+00  4.31666679e+01  4.87500000e+01\n  3.66666675e+00  2.77500000e+01  4.79166679e+01  2.69166660e+01\n  6.37500000e+01  2.16666675e+00  4.58333349e+00  3.51666679e+01\n  4.40000000e+01  1.26666670e+01  1.50000000e+01  2.20833340e+01\n  1.41666670e+01  3.52500000e+01  5.48333321e+01  2.30833340e+01\n  4.50833321e+01  3.72500000e+01  3.24166679e+01  5.28333321e+01\n  6.50000000e+00  2.96666660e+01  2.71666660e+01  5.90833321e+01\n  4.05000000e+01  1.93333340e+01  2.49166660e+01  1.65833340e+01\n  2.91666675e+00  5.19166679e+01  1.66666672e-01  1.40000000e+01\n  2.63333340e+01  4.98333321e+01  5.07500000e+01  2.90833340e+01\n  2.50000000e-01  2.56666660e+01  2.68333340e+01  4.26666679e+01\n  4.41666651e+00  1.04166670e+01  5.37500000e+01  0.00000000e+00\n  3.55833321e+01  4.91666651e+00  3.04166660e+01  1.78333340e+01\n  3.00833340e+01  5.46666679e+01  9.58333302e+00  2.12500000e+01\n  4.94166679e+01  3.57500000e+01  1.91666663e+00  2.94166660e+01\n  1.89166660e+01  1.54166670e+01  1.05833330e+01  1.94166660e+01\n  3.30833321e+01  1.25000000e+01  1.61666660e+01  4.24166679e+01\n  1.68333340e+01  4.60833321e+01  8.50000000e+00  3.91666675e+00\n  4.71666679e+01  5.00000000e-01  4.28333321e+01  4.15000000e+01\n  2.29166660e+01  3.84166679e+01  2.19166660e+01  1.57500000e+01\n  6.83333349e+00  3.96666679e+01  1.55000000e+01  6.16666679e+01\n  2.70833340e+01  4.16666679e+01  5.21666679e+01  2.00833340e+01\n  3.50000000e+00  2.82500000e+01  1.36666670e+01  6.50833359e+01\n  2.87500000e+01  2.52500000e+01  5.13333321e+01  5.25000000e+01\n  2.51666660e+01  3.68333321e+01  2.91666660e+01  3.54166679e+01\n  4.75833321e+01  2.06666660e+01  5.72500000e+01  3.41666679e+01\n  1.10000000e+01  4.92500000e+01  5.10833321e+01  3.20000000e+01\n  2.79166660e+01  2.33333340e+01  2.64166660e+01  2.76666660e+01\n  4.46666679e+01  5.66666679e+01  3.20833321e+01  5.55833321e+01\n  5.79166679e+01  2.48333340e+01  5.30000000e+01  5.55000000e+01\n  1.58333337e+00  1.08333337e+00  3.39166679e+01  1.24166670e+01\n  7.91666651e+00  9.00000000e+00  4.00000000e+01  5.08333321e+01\n  2.00000000e+01  3.35000000e+01  5.36666679e+01  4.33333349e+00\n  3.37500000e+01  1.58333330e+01  4.39166679e+01  4.83333321e+01\n  4.60000000e+01  8.33333358e-02  5.00000000e+01  4.10833321e+01\n  2.04166660e+01  2.99166660e+01  2.50000000e+00  4.50000000e+01\n  5.00000000e+00  1.20000000e+01  1.90833340e+01  1.88333340e+01\n  7.50000000e+00  2.38333340e+01  1.62500000e+01  8.91666698e+00\n  8.41666698e+00  7.00000000e+01  2.33333325e+00  2.14166660e+01\n  4.85000000e+01  1.80000000e+01  5.25833321e+01  4.89166679e+01\n  2.55000000e+01  2.09166660e+01  6.00000000e+00  2.34166660e+01\n  2.83333340e+01  4.01666679e+01  5.99166679e+01  5.60000000e+01\n  3.77500000e+01  2.57500000e+01  3.25000000e+00  9.25000000e+00\n  3.63333321e+01  1.59166670e+01  1.32500000e+01  1.25833330e+01\n  1.85833340e+01  7.50000000e-01  4.38333321e+01  3.86666679e+01\n  3.66666679e+01  5.83333313e-01  2.92500000e+01  2.16666660e+01\n  6.60000000e+01  5.50833321e+01  1.16666663e+00  5.20000000e+01\n  5.44166679e+01  3.65000000e+01  3.23333321e+01  8.83333302e+00\n  4.04166679e+01  4.69166679e+01  2.17500000e+01  3.21666679e+01\n  5.03333321e+01  1.39166670e+01  4.57500000e+01  1.75000000e+01\n  7.75000000e+00  2.73333340e+01  5.58333321e+01  2.46666660e+01\n  2.62500000e+01  1.30000000e+01  9.91666698e+00  2.28333340e+01\n  1.83333337e+00  2.58333340e+01  2.15833340e+01  2.95833340e+01\n  2.26666660e+01  3.76666679e+01  4.45833321e+01  9.75000000e+00\n  3.25833321e+01  5.11666679e+01  3.17500000e+01  2.01666660e+01\n  2.75833340e+01  5.47500000e+01  1.87500000e+01  4.80833321e+01\n  4.97500000e+01  4.90000000e+01  3.45000000e+01  5.91666651e+00\n  3.13333340e+01  3.64166679e+01  3.70000000e+01  5.09166679e+01\n  4.81666679e+01  6.50000000e+01  4.03333321e+01  3.93333321e+01\n  4.76666679e+01  4.08333349e+00  4.48333321e+01  1.35000000e+01\n  4.07500000e+01  4.16666651e+00  3.75833321e+01  4.23333321e+01\n  5.50000000e+00  4.64166679e+01  1.11666670e+01  1.41666663e+00\n  2.50833340e+01  1.44166670e+01  2.11666660e+01  5.49166679e+01\n  4.20833321e+01  2.60000000e+01  4.30833321e+01  1.83333340e+01\n  3.28333321e+01  1.69166660e+01  1.82500000e+01  3.90000000e+01\n  3.50000000e+01  1.63333340e+01  1.74166660e+01  1.23333330e+01\n  1.37500000e+01  5.41666651e+00  2.23333340e+01  5.70833321e+01\n  8.33333302e+00  3.55000000e+01  4.59166679e+01  2.95000000e+01\n  3.53333321e+01  3.74166679e+01  5.39166679e+01  6.30000000e+01\n  6.91666651e+00  1.19166670e+01  8.66666698e+00  4.34166679e+01\n  2.41666675e+00  6.58333349e+00  4.83333349e+00  5.69166679e+01\n  8.00000000e+00  1.47500000e+01  2.22500000e+01  3.61666679e+01\n  4.00833321e+01  1.52500000e+01  3.19166660e+01  3.06666660e+01\n  5.24166679e+01  5.77500000e+01  3.08333340e+01  5.42500000e+01\n  4.30000000e+01  5.60833321e+01  1.72500000e+01  3.08333325e+00\n  2.47500000e+01  4.88333321e+01  4.18333321e+01  2.90000000e+01\n  3.91666679e+01  3.25000000e+01  1.13333330e+01  3.38333321e+01\n  2.42500000e+01  4.17500000e+01  2.05000000e+01  4.49166679e+01\n  4.73333321e+01  3.83333325e+00  3.83333321e+01  1.45000000e+01\n  6.75000000e+00  4.55833321e+01  4.95833321e+01  2.75000000e+01\n  2.70000000e+01  1.05000000e+01  8.33333313e-01  2.05833340e+01\n  3.00000000e+00  9.66666698e+00  1.76666660e+01  4.84166679e+01\n  2.53333340e+01  1.67500000e+01  6.33333349e+00  3.50833321e+01\n  2.81666660e+01  1.18333330e+01  2.25000000e+01  5.02500000e+01\n  4.35833321e+01  5.06666679e+01  3.33333343e-01  1.60833340e+01\n  4.70000000e+01  6.25000000e+00  1.21666670e+01  4.82500000e+01\n  1.16666670e+01  9.83333302e+00  3.85000000e+01  5.63333321e+01\n  1.50000000e+00  4.75000000e+01  3.95833321e+01  6.58333359e+01\n -3.33333343e-01  2.41666660e+01  1.50833330e+01  8.58333302e+00\n  6.67500000e+01  4.50000000e+00  5.58333349e+00  1.84166660e+01\n  2.08333340e+01  4.06666679e+01  5.53333321e+01  7.41666651e+00\n  4.75000000e+00  2.86666660e+01  2.15000000e+01  1.45833330e+01\n  5.17500000e+01  2.59166660e+01  1.55833330e+01  4.36666679e+01\n  1.25000000e+00  1.06666670e+01  4.19166679e+01  1.73333340e+01\n  1.10833330e+01  5.91666679e+01  1.70833340e+01  3.40000000e+01\n  1.66666660e+01  2.43333340e+01  4.20000000e+01  1.70000000e+01\n  7.16666651e+00  5.57500000e+01  2.40000000e+01  6.08333349e+00\n  1.92500000e+01  4.08333321e+01  1.01666670e+01  2.93333340e+01\n  2.66666660e+01  5.75000000e+00  6.26666679e+01  4.22500000e+01\n  1.95000000e+01  1.90000000e+01  3.60000000e+01  4.68333321e+01\n  1.29166670e+01  1.75000000e+00  1.27500000e+01  9.16666687e-01\n  6.21666679e+01  4.54166679e+01  9.08333302e+00  8.08333302e+00\n  5.40833321e+01  4.78333321e+01  7.08333349e+00  4.11666679e+01\n  3.15000000e+01  7.25000000e+00  4.14166679e+01  1.99166660e+01\n  6.08333321e+01  2.25000000e+00  1.30833330e+01  1.56666670e+01\n  1.15833330e+01  8.25000000e+00  7.00000000e+00  4.00000000e+00\n  3.33333325e+00  4.65833321e+01  6.16666651e+00  1.02500000e+01\n  6.00000000e+01  4.33333321e+01  4.65000000e+01  2.60833340e+01\n  1.31666670e+01  1.17500000e+01  2.55833340e+01  4.42500000e+01\n  1.51666670e+01  3.09166660e+01  2.65833340e+01  1.48333330e+01\n  5.38333321e+01  9.33333302e+00  2.66666675e+00  2.25833340e+01\n  6.28333321e+01  4.72500000e+01  2.50000000e+01  1.42500000e+01\n  1.38333330e+01  4.16666657e-01  2.13333340e+01  2.37500000e+01\n  3.98333321e+01  5.22500000e+01  1.53333330e+01  3.85833321e+01\n  3.00000000e+01  7.58333349e+00  4.25000000e+00  3.78333321e+01\n  3.87500000e+01  5.50000000e+01  4.85833321e+01  2.21666660e+01\n  6.47500000e+01  8.75000000e+00  3.16666675e+00  1.20833330e+01\n  6.66666651e+00  3.75000000e+01  1.43333330e+01  3.56666679e+01\n  1.40833330e+01  3.82500000e+01  4.58333321e+01  1.35833330e+01\n  5.33333349e+00  4.66666651e+00  1.22500000e+01  5.20833321e+01\n  1.08333330e+01  3.71666679e+01  2.83333325e+00  4.41666679e+01\n  6.90833359e+01  3.92500000e+01  3.80000000e+01  4.21666679e+01\n  3.46666679e+01  5.76666679e+01  1.07500000e+01  5.25000000e+00\n  6.07500000e+01  4.51666679e+01  5.10000000e+01  2.00000000e+00\n  1.28333330e+01  1.34166670e+01  6.40833359e+01  5.68333321e+01\n  2.07500000e+01  3.49166679e+01  4.09166679e+01  5.45000000e+01\n  5.35833321e+01  1.60000000e+01  3.60833321e+01  6.80000000e+01\n  2.61666660e+01  5.54166679e+01  4.77500000e+01  1.00000000e+00\n  3.33333321e+01  1.12500000e+01  6.00833321e+01  1.86666660e+01\n  1.79166660e+01  3.03333340e+01  3.73333321e+01  5.43333321e+01\n  5.15000000e+01  3.05833340e+01  4.55000000e+01  1.49166670e+01\n  4.15833321e+01  3.10000000e+01  3.05000000e+01  6.06666679e+01\n  3.48333321e+01  3.94166679e+01  4.47500000e+01  2.72500000e+01\n  3.15833340e+01  3.44166679e+01  2.84166660e+01  4.67500000e+01\n  2.35000000e+01  3.14166660e+01  4.37500000e+01  3.69166679e+01\n  2.45833340e+01  5.01666679e+01  6.12500000e+01  1.14166670e+01\n  2.20000000e+01  7.51666641e+01  6.45833359e+01  7.33333349e+00\n  6.69166641e+01  3.29166679e+01  5.12500000e+01  1.71666660e+01\n  5.45833321e+01  2.27500000e+01  5.62500000e+01  5.90000000e+01\n  5.08333349e+00  4.63333321e+01  2.32500000e+01  6.11666679e+01\n  4.74166679e+01  2.10833340e+01  9.50000000e+00  5.30833321e+01\n  1.81666660e+01  2.85833340e+01  3.36666679e+01  4.25000000e+01\n  4.66666679e+01  3.70833321e+01  6.73333359e+01  4.05833321e+01\n  5.65000000e+01  1.96666660e+01  2.18333340e+01  2.85000000e+01\n  4.44166679e+01  3.12500000e+01  4.45000000e+01  6.23333321e+01\n  4.40833321e+01  5.00833321e+01  6.10833321e+01  1.98333340e+01\n  4.99166679e+01  5.34166679e+01  2.97500000e+01  5.35000000e+01\n  5.88333321e+01  6.19166679e+01  4.29166679e+01  5.95833321e+01\n  5.40000000e+01  5.05000000e+01  1.65000000e+01  2.54166660e+01\n  5.86666679e+01  3.79166679e+01  3.45833321e+01  7.66666651e+00\n  2.31666660e+01  6.10000000e+01  6.70000000e+01  5.80000000e+01\n  5.70000000e+01  4.80000000e+01  7.40000000e+01  6.90000000e+01\n  7.10000000e+01  6.20000000e+01  6.40000000e+01  7.20000000e+01\n  5.74166679e+01  3.35833321e+01  6.75833359e+01  5.73333321e+01\n  6.25000000e+01  4.35000000e+01  4.27500000e+01  6.41666641e+01\n  5.18333321e+01  6.97500000e+01  5.71666679e+01  6.02500000e+01\n  5.83333321e+01  7.46666641e+01  5.31666679e+01  3.01666660e+01\n  5.97500000e+01  6.05000000e+01  5.23333321e+01  5.05833321e+01\n  3.26666679e+01  5.89166679e+01  5.16666679e+01  5.29166679e+01\n  7.14166641e+01  3.27500000e+01  5.64166679e+01  3.07500000e+01\n  5.85000000e+01  4.32500000e+01  2.39166660e+01  5.32500000e+01\n  6.04166679e+01  4.62500000e+01  6.54166641e+01  5.56666679e+01\n  5.04166679e+01  6.15000000e+01  5.82500000e+01  7.26666641e+01\n  5.85833321e+01  5.61666679e+01  6.55000000e+01  5.67500000e+01\n  6.53333359e+01  3.62500000e+01  5.14166679e+01  5.87500000e+01\n  1.85000000e+01  7.15833359e+01  6.09166679e+01  6.13333321e+01\n  3.31666679e+01  4.52500000e+01  4.96666679e+01  5.94166679e+01\n  1.01750000e+02]\n\nColumn: sex_frequency\nData type: object\nUnique values: ['once_or_twice_a_week' 'once_a_month_or_less' '2_to_3_times_a_month' nan\n '3_to_6_times_a_week' 'once_or_more_a_day']\n\nColumn: wave\nData type: object\nUnique values: ['2017' '2020' '2022']\n\nColumn: flirts_with_partner\nData type: category\nUnique values: [NaN, 'never', 'a_few_times_a_week', 'less_than_once_a_month', '1_to_3_times_a_month', 'every_day', 'once_a_week']\nCategories (6, object): ['every_day' &lt; 'a_few_times_a_week' &lt; 'once_a_week' &lt; '1_to_3_times_a_month' &lt; 'less_than_once_a_month' &lt; 'never']\n\nColumn: fights_with_partner\nData type: category\nUnique values: [NaN, '0_times', '3_times', '2_times', '1_time', '7_or_more_times', '4_times', '5_times', '6_times']\nCategories (8, object): ['0_times' &lt; '1_time' &lt; '2_times' &lt; '3_times' &lt; '4_times' &lt; '5_times' &lt; '6_times' &lt; '7_or_more_times']\n\nColumn: rel_change_during_pandemic\nData type: object\nUnique values: [nan 'better_than_before' 'no_change' 'worse_than_before']\n\nColumn: inc_change_during_pandemic\nData type: object\nUnique values: [nan 'no_change' 'worse' 'much_worse' 'better' 'much_better']\n\nColumn: subject_had_covid\nData type: object\nUnique values: [nan 'no' 'yes']\n\nColumn: partner_had_covid\nData type: object\nUnique values: [nan 'yes' 'no']\n\nColumn: subject_vaccinated\nData type: object\nUnique values: [nan 'not_vaccinated' 'fully_vaccinated_and_booster'\n 'fully_vaccinated_no_booster' 'partially_vaccinated']\n\nColumn: partner_vaccinated\nData type: object\nUnique values: [nan 'not_vaccinated' 'fully_vaccinated_and_booster'\n 'partially_vaccinated' 'fully_vaccinated_no_booster']\n\nColumn: agree_covid_approach\nData type: object\nUnique values: [nan 'completely_agree' 'mostly_agree' 'completely_disagree'\n 'mostly_disagree']\n\nColumn: children\nData type: float64\nUnique values: [ 1.  2.  5.  4.  6.  3.  8. 10.  7.  9. 12.]"
  },
  {
    "objectID": "scripts/HCMST_clean.html#saving-csv",
    "href": "scripts/HCMST_clean.html#saving-csv",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Saving CSV",
    "text": "Saving CSV\n\ndata.to_csv(\"../data/clean/hcmst.csv\", index=False)"
  },
  {
    "objectID": "scripts/HCMST_clean.html#testing-a-2022-data-set",
    "href": "scripts/HCMST_clean.html#testing-a-2022-data-set",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Testing a 2022 data set:",
    "text": "Testing a 2022 data set:\nDuring the client meeting on May 21st, 2025. It was decided to only keep 2022 data, while removing mostly sparse columns, id and wave values.\n\nclean = pd.read_csv(\"../data/clean/hcmst.csv\")\n\nclean.head()\n\n\n\n\n\n\n\n\nid\nwave\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\npartner_education\nsame_sex_couple\nmarried\nsex_frequency\nflirts_with_partner\nfights_with_partner\nrelationship_start_year\nmarriage_year\nbreak_up_year\nrelationship_duration\nchildren\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nrelationship_quality\n\n\n\n\n0\n53001\n2017\n48.0\nhigh_school_grad\nfemale\n2_plus_eth\n60k_75k\nworking_paid_employee\nmale\n46.0\nwhite\nassociate_degree\nno\nmarried\nonce_or_twice_a_week\nNaN\nNaN\n2013.0\n2014.0\nNaN\n3.583333\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n1\n71609\n2017\n68.0\nsome_college\nfemale\nwhite\n50k_60k\nworking_paid_employee\nmale\n71.0\nwhite\nsome_college\nno\nmarried\nonce_a_month_or_less\nNaN\nNaN\n1964.0\n1969.0\nNaN\n52.750000\n2.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n2\n106983\n2017\n39.0\nassociate_degree\nmale\nwhite\n85k_100k\nworking_paid_employee\nfemale\n49.0\nwhite\nsome_college\nno\nmarried\nonce_or_twice_a_week\nNaN\nNaN\n1999.0\n2002.0\nNaN\n17.583334\n5.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n3\n121759\n2017\n54.0\nhigh_school_grad\nmale\nwhite\n100k_125k\nworking_paid_employee\nfemale\n59.0\nasian\nmasters_degree\nno\nmarried\n2_to_3_times_a_month\nNaN\nNaN\n1990.0\n1991.0\nNaN\n27.416666\n4.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n4\n158083\n2017\n48.0\nsome_college\nmale\nwhite\n75k_85k\nworking_paid_employee\nfemale\n34.0\nwhite\nassociate_degree\nno\nnot_married\nNaN\nNaN\nNaN\n2011.0\n2013.0\n2014.0\nNaN\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\ndata_2022 = clean[clean['wave'] == 2022].dropna(subset=['rel_change_during_pandemic', 'relationship_quality'])\n\n\ndata_2022.columns.tolist()\n\n['id',\n 'wave',\n 'subject_age',\n 'subject_education',\n 'subject_sex',\n 'subject_ethnicity',\n 'subject_income_category',\n 'subject_employment_status',\n 'partner_sex',\n 'partner_age',\n 'partner_ethnicity',\n 'partner_education',\n 'same_sex_couple',\n 'married',\n 'sex_frequency',\n 'flirts_with_partner',\n 'fights_with_partner',\n 'relationship_start_year',\n 'marriage_year',\n 'break_up_year',\n 'relationship_duration',\n 'children',\n 'rel_change_during_pandemic',\n 'inc_change_during_pandemic',\n 'subject_had_covid',\n 'partner_had_covid',\n 'subject_vaccinated',\n 'partner_vaccinated',\n 'agree_covid_approach',\n 'relationship_quality']\n\n\n\ndata_2022 = data_2022[[\n 'subject_age',\n 'subject_education',\n 'subject_sex',\n 'subject_ethnicity',\n 'subject_income_category',\n 'subject_employment_status',\n 'same_sex_couple',\n 'married',\n 'sex_frequency',\n 'flirts_with_partner',\n 'fights_with_partner',\n 'relationship_duration',\n 'children',\n 'rel_change_during_pandemic',\n 'inc_change_during_pandemic',\n 'subject_had_covid',\n 'partner_had_covid',\n 'subject_vaccinated',\n 'partner_vaccinated',\n 'agree_covid_approach',\n 'relationship_quality']]\n\n\ndata_2022.head()\n\n\n\n\n\n\n\n\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\nsame_sex_couple\nmarried\nsex_frequency\nflirts_with_partner\nfights_with_partner\nrelationship_duration\nchildren\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nrelationship_quality\n\n\n\n\n5617\n53.0\nhigh_school_grad\nfemale\nwhite\n35k_40k\nworking_paid_employee\nno\nnot_married\nonce_or_twice_a_week\na_few_times_a_week\n0_times\n1.500000\n2.0\nbetter_than_before\nno_change\nno\nyes\nnot_vaccinated\nnot_vaccinated\ncompletely_agree\nexcellent\n\n\n5618\n72.0\nsome_college\nfemale\nwhite\n75k_85k\nworking_paid_employee\nno\nmarried\nonce_a_month_or_less\nnever\n7_or_more_times\n57.416668\n1.0\nno_change\nworse\nno\nno\nfully_vaccinated_and_booster\nfully_vaccinated_and_booster\nmostly_agree\ngood\n\n\n5619\n43.0\nassociate_degree\nmale\nwhite\n75k_85k\nworking_paid_employee\nno\nmarried\nonce_or_twice_a_week\na_few_times_a_week\n2_times\n22.333334\n5.0\nno_change\nworse\nno\nno\nfully_vaccinated_and_booster\nfully_vaccinated_and_booster\ncompletely_agree\nexcellent\n\n\n5621\n64.0\nsome_college\nmale\nwhite\n75k_85k\nworking_paid_employee\nno\nmarried\nonce_or_twice_a_week\n1_to_3_times_a_month\n0_times\n28.250000\n2.0\nno_change\nno_change\nno\nno\nfully_vaccinated_and_booster\nfully_vaccinated_and_booster\ncompletely_agree\ngood\n\n\n5623\n60.0\nhigh_school_grad\nfemale\nblack\n75k_85k\nworking_paid_employee\nno\nmarried\nonce_or_twice_a_week\na_few_times_a_week\n0_times\n38.916668\n3.0\nbetter_than_before\nno_change\nno\nno\nnot_vaccinated\npartially_vaccinated\ncompletely_agree\nexcellent\n\n\n\n\n\n\n\n\ndata_2022.shape\n\n(1328, 21)\n\n\n\ndata_2022.to_csv(\"../data/clean/hcmst.csv\", index=False)"
  },
  {
    "objectID": "scripts/march_madness_clean.html",
    "href": "scripts/march_madness_clean.html",
    "title": "Clean up for womens-march-madness.csv",
    "section": "",
    "text": "Load the necessary libraries for the clean-up, as well as the provided dataset\n\nimport pandas as pd\nimport re\nimport numpy as np\n\n\ndata = pd.read_csv(\"../data/raw/womens-march-madness/womens-march-madness.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nYear\nSchool\nSeed\nConference\nConf. W\nConf. L\nConf. %\nConf. place\nReg. W\nReg. L\nReg. %\nHow qual\n1st game at home?\nTourney W\nTourney L\nTourney finish\nFull W\nFull L\nFull %\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n79.3\nat-large\nY\n1\n1\nRSF\n24\n7\n77.4\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n85.7\nat-large\nN\n0\n1\n1st\n24\n5\n82.8\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n92.3\nat-large\nY\n4\n1\nN2nd\n28\n3\n90.3\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n64.5\nat-large\nN\n0\n1\n1st\n20\n12\n62.5\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n81.3\nauto\nY\n2\n1\nRF\n28\n7\n80"
  },
  {
    "objectID": "scripts/march_madness_clean.html#loading-csv",
    "href": "scripts/march_madness_clean.html#loading-csv",
    "title": "Clean up for womens-march-madness.csv",
    "section": "",
    "text": "Load the necessary libraries for the clean-up, as well as the provided dataset\n\nimport pandas as pd\nimport re\nimport numpy as np\n\n\ndata = pd.read_csv(\"../data/raw/womens-march-madness/womens-march-madness.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nYear\nSchool\nSeed\nConference\nConf. W\nConf. L\nConf. %\nConf. place\nReg. W\nReg. L\nReg. %\nHow qual\n1st game at home?\nTourney W\nTourney L\nTourney finish\nFull W\nFull L\nFull %\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n79.3\nat-large\nY\n1\n1\nRSF\n24\n7\n77.4\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n85.7\nat-large\nN\n0\n1\n1st\n24\n5\n82.8\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n92.3\nat-large\nY\n4\n1\nN2nd\n28\n3\n90.3\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n64.5\nat-large\nN\n0\n1\n1st\n20\n12\n62.5\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n81.3\nauto\nY\n2\n1\nRF\n28\n7\n80"
  },
  {
    "objectID": "scripts/march_madness_clean.html#renaming-columns",
    "href": "scripts/march_madness_clean.html#renaming-columns",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Renaming columns",
    "text": "Renaming columns\nChanging the column names to a more interpretable version:\n\ncolumn_names = {\n    'Year' : 'year',\n    'School' : 'school',\n    'Seed' : 'seed',\n    'Conference' : 'conference',\n    'Conf. W' : 'conf_wins',\n    'Conf. L' : 'conf_losses',\n    'Conf. %' : 'conf_wins_pct',\n    'Conf. place' : 'conf_place',\n    'Reg. W' : 'reg_wins',\n    'Reg. L' : 'reg_losses',\n    'Reg. %' : 'reg_wins_pct',\n    'How qual' : 'bid',\n    '1st game at home?' : 'first_game_at_home',\n    'Tourney W' : 'tourney_wins',\n    'Tourney L' : 'tourney_losses',\n    'Tourney finish' : 'tourney_finish',\n    'Full W' : 'total_wins',\n    'Full L' : 'total_losses',\n    'Full %' : 'total_wins_pct'\n}\ndata = data.rename(columns = column_names)\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_place\nreg_wins\nreg_losses\nreg_wins_pct\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n79.3\nat-large\nY\n1\n1\nRSF\n24\n7\n77.4\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n85.7\nat-large\nN\n0\n1\n1st\n24\n5\n82.8\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n92.3\nat-large\nY\n4\n1\nN2nd\n28\n3\n90.3\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n64.5\nat-large\nN\n0\n1\n1st\n20\n12\n62.5\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n81.3\nauto\nY\n2\n1\nRF\n28\n7\n80"
  },
  {
    "objectID": "scripts/march_madness_clean.html#column-analysis-and-reformatting",
    "href": "scripts/march_madness_clean.html#column-analysis-and-reformatting",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Column Analysis and Reformatting",
    "text": "Column Analysis and Reformatting\nAnalyzing and replacing the contents of the ‘Conf. place’ : ‘conf_place’ column:\n\ndata['conf_place'].unique()\n\narray(['-', '4th', '1st', '2nd', '3rd', 'T1st W', '3rd E', '2nd E',\n       'T2nd', '1st E', 'T2nd W', 'T1st E', 'T1st', 'T1st N', 'T3rd',\n       '1st W', '2nd W', '1st S', '2nd S', 'T4th', 'T2nd E', 'T6th',\n       '5th', '6th', 'T5th', 'T8th', 'T7th', '7th', '1st-B', '1st-W',\n       '2nd-E', '2nd-6', '1st-E', '1st-R', 'T2nd-W', '1st-6', 'T1st-B',\n       'T1st-W', '1st-P', '1st-M', 'T1st-M', '2nd-A', '1st-A', '1st-N',\n       '2nd-7', 'T3rd-M', 'T2nd-6', '1st-7', 'T2nd-P', '2nd-N', '2nd-W',\n       '8th', 'T1st-A', '2nd-M', '3rd-W', '4th-N', '9th', 'T1st-E',\n       '10th', 'T9th', '1st Div.', '3rd Div', 'T3rd Div.'], dtype=object)\n\n\n\nNumerical Places:\n\n‘1st’, ‘2nd’, ‘3rd’, etc. — clearly ranked within the conference.\n\nTied Places:\n\n‘T1st’, ‘T2nd’, etc. — team tied for that position.\n‘T1st-W’, ‘T2nd-E’, etc. — tied for a position within a division (e.g., West, East).\n\nDivisions within Conferences:\n\n‘1st W’, ‘2nd E’, ‘3rd-W’, etc. — first, second, or third place in a regional division (West, East, etc.).\n\nAmbiguous Codes:\n\n‘1st-6’, ‘T2nd-6’, ‘2nd-7’ — unknown for divisions (e.g., “Group 6” or region 6).\n‘1st-B’, ‘1st-R’, ‘1st-P’, ‘1st-M’, etc. — probably shorthand for colored or named divisions (e.g., Blue, Red, Pacific, Mountain).\n‘1st Div.’, ‘3rd Div’, ‘T3rd Div.’ — older way of denoting division standing.\n\n‘-’ — missing or not applicable (e.g., for Independent schools not in a conference).\n\nFunctions to replace ‘conf_place’ with two columns ‘conf_rank’ and ‘division’\n\ndef extract_conf_rank(conf_place):\n    if pd.isna(conf_place) or conf_place == '-':\n        return np.nan\n    # Match patterns like '1st', 'T2nd', '3rd-W', 'T1st-N', etc.\n    match = re.search(r'(\\d+)(st|nd|rd|th)', conf_place)\n    if match:\n        return int(match.group(1))\n    return np.nan\n\ndef extract_division(conf_place):\n    if pd.isna(conf_place) or conf_place == '-':\n        return np.nan\n    # Look for division info after rank (like 'W', 'E', '6', etc.)\n    match = re.search(r'(?:\\d+(?:st|nd|rd|th)[\\s-]?)([A-Za-z0-9]+)?', conf_place)\n    if match:\n        return match.group(1)\n    return np.nan\n\n\ndata['conf_rank'] = data['conf_place'].apply(extract_conf_rank)\ndata['division'] = data['conf_place'].apply(extract_division)\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_place\nreg_wins\nreg_losses\n...\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\nconf_rank\ndivision\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n...\nat-large\nY\n1\n1\nRSF\n24\n7\n77.4\nNaN\nNaN\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n...\nat-large\nN\n0\n1\n1st\n24\n5\n82.8\nNaN\nNaN\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n...\nat-large\nY\n4\n1\nN2nd\n28\n3\n90.3\nNaN\nNaN\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n...\nat-large\nN\n0\n1\n1st\n20\n12\n62.5\n4.0\nNone\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n...\nauto\nY\n2\n1\nRF\n28\n7\n80\nNaN\nNaN\n\n\n\n\n5 rows × 21 columns\n\n\n\nAnalyzing and replacing the contents of the ‘Tourney finish’ : ‘tourney_finish’ column:\nAccording to the documentation:\nThe round of the final game for each team. OR=opening-round loss (1983 only); 1st=first-round loss; 2nd=second-round loss; RSF=loss in the Sweet 16; RF=loss in the Elite Eight; NSF=loss in the national semifinals; N2nd=national runner-up; Champ=national champions.\nWe’ll recode the content of the column to more interpretable names.\n\ndata['tourney_finish'].unique()\n\narray(['RSF', '1st', 'N2nd', 'RF', 'Champ', 'NSF', 'OR', '2nd'],\n      dtype=object)\n\n\n\nfinish_map = {\n    'OR': 'opening_round_loss',\n    '1st': 'first_round_loss',\n    '2nd': 'second_round_loss',\n    'RSF': 'top_16_loss',\n    'RF': 'top_8_loss',\n    'NSF': 'top_4_loss',\n    'N2nd': 'top_2_loss',\n    'Champ': 'champ'\n}\n\ndata['tourney_finish'] = data['tourney_finish'].replace(finish_map)\n\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_place\nreg_wins\nreg_losses\n...\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\nconf_rank\ndivision\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n...\nat-large\nY\n1\n1\ntop_16_loss\n24\n7\n77.4\nNaN\nNaN\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n...\nat-large\nN\n0\n1\nfirst_round_loss\n24\n5\n82.8\nNaN\nNaN\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n...\nat-large\nY\n4\n1\ntop_2_loss\n28\n3\n90.3\nNaN\nNaN\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n...\nat-large\nN\n0\n1\nfirst_round_loss\n20\n12\n62.5\n4.0\nNone\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n...\nauto\nY\n2\n1\ntop_8_loss\n28\n7\n80\nNaN\nNaN\n\n\n\n\n5 rows × 21 columns\n\n\n\nWe’re going to make this column an ordered categorical.\n\nfinish_order = [\n    'opening_round_loss',\n    'first_round_loss',\n    'second_round_loss',\n    'top_16_loss',\n    'top_8_loss',\n    'top_4_loss',\n    'top_2_loss',\n    'champ'\n]\n\ndata['tourney_finish'] = pd.Categorical(\n    data['tourney_finish'], \n    categories=finish_order, \n    ordered=True\n)\n\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_place\nreg_wins\nreg_losses\n...\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\nconf_rank\ndivision\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n...\nat-large\nY\n1\n1\ntop_16_loss\n24\n7\n77.4\nNaN\nNaN\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n...\nat-large\nN\n0\n1\nfirst_round_loss\n24\n5\n82.8\nNaN\nNaN\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n...\nat-large\nY\n4\n1\ntop_2_loss\n28\n3\n90.3\nNaN\nNaN\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n...\nat-large\nN\n0\n1\nfirst_round_loss\n20\n12\n62.5\n4.0\nNone\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n...\nauto\nY\n2\n1\ntop_8_loss\n28\n7\n80\nNaN\nNaN\n\n\n\n\n5 rows × 21 columns\n\n\n\nAnalyzing and replacing the contents of the ‘Seed’ : ‘seed’ column:\n\ndata.loc[data['seed'] == '(OR)', 'seed'] = '0'"
  },
  {
    "objectID": "scripts/march_madness_clean.html#changing-datatypes",
    "href": "scripts/march_madness_clean.html#changing-datatypes",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Changing datatypes:",
    "text": "Changing datatypes:\n\ndata.replace(\"-\", np.nan, inplace=True)\n\ndata['seed'] = data['seed'].astype('int')\ndata['conf_wins'] = data['conf_wins'].astype('float')\ndata['conf_losses'] = data['conf_losses'].astype('float')\ndata['conf_wins_pct'] = data['conf_wins_pct'].astype('float')\ndata['total_wins_pct'] = data['total_wins_pct'].str.replace('\\\\', '')\ndata['first_game_at_home'] = data['first_game_at_home'].str.replace('^', '')\ndata['total_wins_pct'] = data['total_wins_pct'].astype('float')\n\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_place\nreg_wins\nreg_losses\n...\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\nconf_rank\ndivision\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\nNaN\nNaN\nNaN\nNaN\n23\n6\n...\nat-large\nY\n1\n1\ntop_16_loss\n24\n7\n77.4\nNaN\nNaN\n\n\n1\n1982\nAuburn\n7\nSoutheastern\nNaN\nNaN\nNaN\nNaN\n24\n4\n...\nat-large\nN\n0\n1\nfirst_round_loss\n24\n5\n82.8\nNaN\nNaN\n\n\n2\n1982\nCheyney\n2\nIndependent\nNaN\nNaN\nNaN\nNaN\n24\n2\n...\nat-large\nY\n4\n1\ntop_2_loss\n28\n3\n90.3\nNaN\nNaN\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6.0\n3.0\n66.7\n4th\n20\n11\n...\nat-large\nN\n0\n1\nfirst_round_loss\n20\n12\n62.5\n4.0\nNone\n\n\n4\n1982\nDrake\n4\nMissouri Valley\nNaN\nNaN\nNaN\nNaN\n26\n6\n...\nauto\nY\n2\n1\ntop_8_loss\n28\n7\n80.0\nNaN\nNaN\n\n\n\n\n5 rows × 21 columns"
  },
  {
    "objectID": "scripts/march_madness_clean.html#nan-standardization",
    "href": "scripts/march_madness_clean.html#nan-standardization",
    "title": "Clean up for womens-march-madness.csv",
    "section": "NaN Standardization",
    "text": "NaN Standardization\n\ndata.replace(to_replace=[pd.NA, \"nan\", \"NaN\", \"None\", None], value=np.nan, inplace=True)"
  },
  {
    "objectID": "scripts/march_madness_clean.html#results-review",
    "href": "scripts/march_madness_clean.html#results-review",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Results Review",
    "text": "Results Review\n\nfor column in data.columns:\n    print(f\"Column: {column}\")\n    print(f\"Data type: {data[column].dtype}\")\n    print(f\"Unique values: {data[column].unique()}\\n\")\n\nColumn: year\nData type: int64\nUnique values: [1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995\n 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009\n 2010 2011 2012 2013 2014 2015 2016 2017 2018]\n\nColumn: school\nData type: object\nUnique values: ['Arizona St.' 'Auburn' 'Cheyney' 'Clemson' 'Drake' 'East Carolina'\n 'Georgia' 'Howard' 'Illinois' 'Jackson St.' 'Kansas St.' 'Kent St.'\n 'Kentucky' 'Long Beach St.' 'Louisiana Tech' 'Maryland' 'Memphis'\n 'Missouri' 'NC State' 'Northwestern' 'Ohio St.' 'Old Dominion' 'Ole Miss'\n 'Oregon' 'Penn St.' \"Saint Peter's\" 'SFA' 'South Carolina'\n 'Southern California' 'Stanford' 'Tennessee' 'Tennessee Tech'\n 'Central Mich.' 'Dartmouth' 'Florida St.' 'Illinois St.' 'Indiana'\n 'La Salle' 'La.-Monroe' 'Louisville' 'Middle Tenn.' 'Monmouth' 'Montana'\n 'North Carolina' 'Oregon St.' 'South Carolina St.' \"St. John's (NY)\"\n 'Texas' 'UCLA' 'Utah' 'Alabama' 'BYU' 'LSU' 'San Diego St.' 'Texas Tech'\n 'UNLV' 'Virginia' 'Holy Cross' 'Idaho' \"Saint Joseph's\" 'Southern Miss.'\n 'Syracuse' 'Washington' 'Western Ky.' 'Western Mich.' 'Arkansas' 'Iowa'\n 'James Madison' 'North Texas' 'Ohio' 'Oklahoma' 'Providence' 'Rutgers'\n 'Southern Ill.' 'Vanderbilt' 'Villanova' 'Bowling Green' 'Duke'\n 'Eastern Wash.' 'Kansas' 'Manhattan' 'New Mexico St.' 'New Orleans'\n 'Northwestern St.' 'South Alabama' 'Colorado' 'Eastern Ill.' 'Fairfield'\n 'Houston' 'Nebraska' 'Wake Forest' 'Cal St. Fullerton' 'Chattanooga'\n 'Cincinnati' 'Hawaii' 'Miami (FL)' 'Oklahoma St.' 'Purdue' 'Temple'\n 'UConn' 'West Virginia' 'Appalachian St.' 'California' 'DePaul'\n 'Michigan' 'Northern Ill.' 'Richmond' 'George Washington' 'Lamar'\n 'Michigan St.' 'Missouri St.' 'Toledo' 'Washington St.' 'Creighton'\n 'Notre Dame' 'Santa Clara' 'UC Santa Barbara' 'Vermont' 'Wisconsin'\n 'Florida' 'Ga. Southern' 'Georgetown' 'Georgia Tech' 'Montana St.'\n 'San Diego' 'Xavier' 'Boise St.' 'Brown' 'FIU' 'Fordham' 'Grambling'\n 'Green Bay' 'Loyola (MD)' 'Marquette' 'Minnesota' \"Mt. St. Mary's\"\n 'N.C. A&T' 'Portland' 'Radford' 'Seton Hall' 'SMU' 'Tennessee St.'\n 'Texas A&M' 'UAB' 'Virginia Tech' 'Florida A&M' 'Furman' 'Maine'\n 'San Francisco' 'Tulane' 'UC Irvine' 'Western Ill.' 'Austin Peay'\n 'Butler' 'Colorado St.' 'Harvard' 'Massachusetts' 'Rhode Island'\n 'St. Francis (PA)' 'UCF' 'Youngstown St.' 'Arizona' 'Detroit Mercy'\n 'Eastern Ky.' 'Iowa St.' 'Lehigh' 'Liberty' 'Marshall' 'Texas St.' 'Troy'\n 'New Mexico' 'Saint Francis (PA)' 'UNC Greensboro' 'Boston College'\n 'CSUN' 'Evansville' 'Mississippi St.' 'Northeastern' 'Oral Roberts'\n \"St. Mary's (CA)\" 'Alcorn St.' 'Campbell' 'Hampton' 'Pepperdine' 'Rice'\n 'Baylor' 'Delaware' 'Denver' 'Georgia St.' 'Idaho St.' 'Long Island'\n 'Milwaukee' 'Penn' 'Siena' 'TCU' 'Bucknell' 'Hartford' 'Norfolk St.'\n 'Oakland' 'Southern' 'Weber St.' 'Alabama St.' 'Boston University'\n 'Charlotte' 'Valparaiso' 'Colgate' 'Eastern Mich.' 'Lipscomb'\n 'Loyola Marymount' 'Marist' 'Canisius' 'Coppin St.' 'Stetson'\n 'UT Arlington' 'Western Carolina' 'Army' 'Fla. Atlantic'\n 'Northern Arizona' 'Sacred Heart' 'South Florida' 'Southeast Mo. St.'\n 'Tulsa' 'UC Riverside' 'Belmont' 'Delaware St.' 'Gonzaga' 'Louisiana'\n 'Pittsburgh' 'Prairie View' 'Robert Morris' 'UMBC' 'Asheville'\n 'Cleveland St.' 'Cornell' 'ETSU' 'Fresno St.' 'Miami (OH)' 'Murray St.'\n 'UTEP' 'UTSA' 'Wyoming' 'Ball St.' 'Drexel' 'NC A&T' 'South Dakota St.'\n 'VCU' 'Dayton' 'Little Rock' 'Portland St.' 'Princeton' 'UNI'\n 'Gardner-Webb' 'McNeese' 'Navy' 'Samford' 'UC Davis' 'UT Martin' 'Albany'\n 'FGCU' 'St. Bonaventure' 'Cal Poly' 'Quinnipiac' 'Wichita St.' 'Akron'\n 'North Dakota' 'South Dakota' 'Winthrop' 'Wright St.' 'American'\n 'Savannah St.' 'St. Francis Brooklyn' 'Army West Point' 'Buffalo'\n 'Central Arkansas' 'Duquesne' 'Iona' 'Jacksonville' 'UNC Asheville'\n 'Elon' 'Texas Southern' 'Mercer' 'Nicholls St.' 'Northern Colo.'\n 'Seattle']\n\nColumn: seed\nData type: int64\nUnique values: [ 4  7  2  5  6  8  1  3  0 10  9 12 11 16 14 15 13]\n\nColumn: conference\nData type: object\nUnique values: ['Western Collegiate' 'Southeastern' 'Independent' 'Atlantic Coast'\n 'Missouri Valley' 'Mid-Eastern' 'Big Ten' 'Southwestern' 'Big Eight'\n 'Mid-American' 'Metro' 'Metro Atlantic' 'Northern California'\n 'Ohio Valley' 'Ivy' 'East Coast' 'Southland' 'Cosmopolitan'\n 'Mountain West Athl.' 'Sun Belt' 'Northern Pacific' 'Atlantic 10'\n 'Big East' 'Southwest' 'High Country' 'Pacific Coast' 'Colonial'\n 'Pacific West' 'Western Athletic' 'Gulf Star' 'Pacific-10' 'Big West'\n 'American South' 'Southern' 'Big Sky' 'North Star' 'Patriot'\n 'Great Midwest' 'Midwestern' 'West Coast' 'North Atlantic'\n 'Mid-Continent' 'Trans America' 'Northeast' 'Big South' 'Conference USA'\n 'Trans-America' 'Big 12' 'America East' 'Horizon' 'Mountain West'\n 'Atlantic Sun' ' Mountain West' 'Summit' 'Pac-12' 'American Atletic'\n 'American Athletic' 'ASUN' 'Colonial Athletic' 'Western Atlantic'\n 'Atlantic-10' 'SWAC' 'Atlantic']\n\nColumn: conf_wins\nData type: float64\nUnique values: [nan  6. 11.  5.  9. 10.  4. 12.  7. 18. 16. 13. 14. 17.  8. 15.  3. 19.\n 20.]\n\nColumn: conf_losses\nData type: float64\nUnique values: [nan  3.  1.  2.  0.  5.  4.  6.  8.  7.  9. 11. 10. 13. 14. 12.]\n\nColumn: conf_wins_pct\nData type: float64\nUnique values: [  nan  66.7  85.7  84.6 100.   75.   83.3  64.3  91.7  50.   76.9  92.3\n  87.5  62.5  90.   88.9  92.9  70.   71.4  94.4  81.3  78.6  80.   77.8\n  44.4  42.9  57.1  55.6  61.1  93.8  68.8  86.7  72.2  60.   63.6  56.3\n  90.9  54.5  81.8  36.4  58.3  72.7  21.4  53.8  46.7  41.7  93.3  41.2\n  43.8  95.   84.2  94.1  38.9  55.   82.4  27.8  37.5  22.2  61.9  85.\n  33.3]\n\nColumn: conf_place\nData type: object\nUnique values: [nan '4th' '1st' '2nd' '3rd' 'T1st W' '3rd E' '2nd E' 'T2nd' '1st E'\n 'T2nd W' 'T1st E' 'T1st' 'T1st N' 'T3rd' '1st W' '2nd W' '1st S' '2nd S'\n 'T4th' 'T2nd E' 'T6th' '5th' '6th' 'T5th' 'T8th' 'T7th' '7th' '1st-B'\n '1st-W' '2nd-E' '2nd-6' '1st-E' '1st-R' 'T2nd-W' '1st-6' 'T1st-B'\n 'T1st-W' '1st-P' '1st-M' 'T1st-M' '2nd-A' '1st-A' '1st-N' '2nd-7'\n 'T3rd-M' 'T2nd-6' '1st-7' 'T2nd-P' '2nd-N' '2nd-W' '8th' 'T1st-A' '2nd-M'\n '3rd-W' '4th-N' '9th' 'T1st-E' '10th' 'T9th' '1st Div.' '3rd Div'\n 'T3rd Div.']\n\nColumn: reg_wins\nData type: int64\nUnique values: [23 24 20 26 19 21 14 28 17 22 30 25 27 15 18 16 29 12 33 31 13 32 34 10]\n\nColumn: reg_losses\nData type: int64\nUnique values: [ 6  4  2 11  7  8 10  5 13  1  3  9 12 14 15  0 16 17 18]\n\nColumn: reg_wins_pct\nData type: float64\nUnique values: [ 79.3  85.7  92.3  64.5  81.3  73.1  72.4  58.3  80.   82.8  56.7  75.9\n  81.5  96.8  78.6  86.2  74.2  82.1  75.   76.   80.8  87.1  83.3  65.2\n  87.   67.9  66.7  76.7  71.4  92.9  72.   69.   64.3  85.2  57.1  96.4\n  50.   89.7  83.9  69.6  92.6  93.3  73.3  93.1  84.6  88.   51.6  89.3\n  63.3  93.8  70.4  77.8  96.6  90.   67.7  60.   70.   96.3  96.7  87.5\n  58.6  76.5  65.5 100.   90.6  62.1  86.7  61.3  74.1  80.6  60.9  71.9\n  60.7  68.8  78.8  71.   77.4  59.4  46.7  88.9  62.5  61.5  59.3  76.9\n  63.   41.4  69.2  88.5  84.4  51.7  93.5  90.9  75.8  53.6  81.8  69.7\n  65.4  93.9  65.6  90.3  53.3  63.6  58.1  68.6  96.9  55.2  54.8  43.3\n  78.1  87.9  43.8  72.7  55.6  46.9  84.8  56.3  97.   53.1  45.5  51.5\n  60.6  88.2  57.6  52.9  82.4  45.2  64.7  91.2  97.1  67.6  79.4  55.9\n  86.4  94.1]\n\nColumn: bid\nData type: object\nUnique values: ['at-large' 'auto']\n\nColumn: first_game_at_home\nData type: object\nUnique values: ['Y' 'N']\n\nColumn: tourney_wins\nData type: int64\nUnique values: [1 0 4 2 5 3 6]\n\nColumn: tourney_losses\nData type: int64\nUnique values: [1 0]\n\nColumn: tourney_finish\nData type: category\nUnique values: ['top_16_loss', 'first_round_loss', 'top_2_loss', 'top_8_loss', 'champ', 'top_4_loss', 'opening_round_loss', 'second_round_loss']\nCategories (8, object): ['opening_round_loss' &lt; 'first_round_loss' &lt; 'second_round_loss' &lt; 'top_16_loss' &lt; 'top_8_loss' &lt; 'top_4_loss' &lt; 'top_2_loss' &lt; 'champ']\n\nColumn: total_wins\nData type: int64\nUnique values: [24 28 20 19 21 14 26 17 23 35 25 22 27 15 18 16 31 29 30 32 34 33 12 39\n 36 37 13 40 38]\n\nColumn: total_losses\nData type: int64\nUnique values: [ 7  5  3 12  8  9 11  6 14  1  4 10 13  2 15 16  0 17 18 53 19]\n\nColumn: total_wins_pct\nData type: float64\nUnique values: [ 77.4  82.8  90.3  62.5  80.   70.4  70.   56.   77.8  81.3  54.8  75.\n  79.3  97.2  78.1  83.9  72.7  72.4  73.1  78.6  84.4  83.3  73.3  84.6\n  68.8  64.5  76.7  69.   90.   69.2  79.4  66.7  63.3  80.6  82.1  55.2\n  93.9  50.   86.7  82.9  78.8  72.   68.   93.8  75.8  90.9  62.1  75.9\n  71.9  85.2  51.5  65.5  61.3  87.9  69.7  91.4  67.9  85.3  93.3  71.\n  65.6  91.2  90.6  84.8  58.1  92.9  87.5  81.8  56.7  89.7  86.1  86.2\n  70.6 100.   88.9  60.   87.1  60.6  91.7  71.4  58.3  82.4  64.3  67.7\n  93.5  94.1  58.6  67.6  74.2  76.5  85.7  88.2  94.6  97.   57.6  56.3\n  45.2  96.7  77.1  61.8  59.3  57.1  96.6  88.6  40.   94.3  60.7  63.6\n  91.9  89.2  73.5  74.3  74.1  51.7  89.5  81.6  94.4  74.4  97.1  63.\n  79.6  48.3  78.9  51.6  97.3  89.3  68.4  65.7  68.6  81.1  81.5  59.4\n  58.8  86.8  97.4  53.1  36.9  41.9  48.4  86.5  42.4  53.6  45.5  83.8\n  48.5  64.7  72.2  55.9  94.7  62.9  78.4  44.1  87.2  69.4  73.   71.1\n  54.5  79.5  51.4  76.3  43.8  92.3  96.9  61.1  70.3  62.2  63.9  84.2\n  54.3  94.9  92.1]\n\nColumn: conf_rank\nData type: float64\nUnique values: [nan  4.  1.  2.  3.  6.  5.  8.  7.  9. 10.]\n\nColumn: division\nData type: object\nUnique values: [nan 'W' 'E' 'N' 'S' 'B' '6' 'R' 'P' 'M' 'A' '7' 'Div']"
  },
  {
    "objectID": "scripts/march_madness_clean.html#final-reorganization-of-columns",
    "href": "scripts/march_madness_clean.html#final-reorganization-of-columns",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Final Reorganization of Columns",
    "text": "Final Reorganization of Columns\n\ndata.columns\n\nIndex(['year', 'school', 'seed', 'conference', 'conf_wins', 'conf_losses',\n       'conf_wins_pct', 'conf_place', 'reg_wins', 'reg_losses', 'reg_wins_pct',\n       'bid', 'first_game_at_home', 'tourney_wins', 'tourney_losses',\n       'tourney_finish', 'total_wins', 'total_losses', 'total_wins_pct',\n       'conf_rank', 'division'],\n      dtype='object')\n\n\n\ndata = data[['year', 'school', 'seed', 'conference', 'conf_wins', 'conf_losses',\n       'conf_wins_pct', 'conf_rank', 'division', 'reg_wins', 'reg_losses', 'reg_wins_pct',\n       'bid', 'first_game_at_home', 'tourney_wins', 'tourney_losses',\n       'tourney_finish', 'total_wins', 'total_losses', 'total_wins_pct'\n       ]]\n\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_rank\ndivision\nreg_wins\nreg_losses\nreg_wins_pct\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\nNaN\nNaN\nNaN\nNaN\nNaN\n23\n6\n79.3\nat-large\nY\n1\n1\ntop_16_loss\n24\n7\n77.4\n\n\n1\n1982\nAuburn\n7\nSoutheastern\nNaN\nNaN\nNaN\nNaN\nNaN\n24\n4\n85.7\nat-large\nN\n0\n1\nfirst_round_loss\n24\n5\n82.8\n\n\n2\n1982\nCheyney\n2\nIndependent\nNaN\nNaN\nNaN\nNaN\nNaN\n24\n2\n92.3\nat-large\nY\n4\n1\ntop_2_loss\n28\n3\n90.3\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6.0\n3.0\n66.7\n4.0\nNaN\n20\n11\n64.5\nat-large\nN\n0\n1\nfirst_round_loss\n20\n12\n62.5\n\n\n4\n1982\nDrake\n4\nMissouri Valley\nNaN\nNaN\nNaN\nNaN\nNaN\n26\n6\n81.3\nauto\nY\n2\n1\ntop_8_loss\n28\n7\n80.0"
  },
  {
    "objectID": "scripts/march_madness_clean.html#saving-csv",
    "href": "scripts/march_madness_clean.html#saving-csv",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Saving CSV",
    "text": "Saving CSV\n\ndata.to_csv('../data/clean/womensmarchmadness.csv', index=False)"
  },
  {
    "objectID": "scripts/march_madness_clean.html#validating",
    "href": "scripts/march_madness_clean.html#validating",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Validating",
    "text": "Validating\n\nclean = pd.read_csv(\"../data/clean/womensmarchmadness.csv\")\n\nclean.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_rank\ndivision\nreg_wins\nreg_losses\nreg_wins_pct\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\nNaN\nNaN\nNaN\nNaN\nNaN\n23\n6\n79.3\nat-large\nY\n1\n1\ntop_16_loss\n24\n7\n77.4\n\n\n1\n1982\nAuburn\n7\nSoutheastern\nNaN\nNaN\nNaN\nNaN\nNaN\n24\n4\n85.7\nat-large\nN\n0\n1\nfirst_round_loss\n24\n5\n82.8\n\n\n2\n1982\nCheyney\n2\nIndependent\nNaN\nNaN\nNaN\nNaN\nNaN\n24\n2\n92.3\nat-large\nY\n4\n1\ntop_2_loss\n28\n3\n90.3\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6.0\n3.0\n66.7\n4.0\nNaN\n20\n11\n64.5\nat-large\nN\n0\n1\nfirst_round_loss\n20\n12\n62.5\n\n\n4\n1982\nDrake\n4\nMissouri Valley\nNaN\nNaN\nNaN\nNaN\nNaN\n26\n6\n81.3\nauto\nY\n2\n1\ntop_8_loss\n28\n7\n80.0\n\n\n\n\n\n\n\n\nclean.shape\n\n(2092, 20)"
  },
  {
    "objectID": "template/template.html",
    "href": "template/template.html",
    "title": "Diverse Data Hub Template",
    "section": "",
    "text": "Provide background information and context about the dataset. Think about answering the following questions:\n\nWhere does the data come from?\nWhy was it collected?\nWhy is the topic of the data socially relevant in the context of equity, diversity and inclusion?\n\n\n\n\n\n\nClearly define the problem or question being addressed by this analysis. What is the goal? What data science problem are you trying to solve or understand with this dataset?\n\n\n\nDescribe the approach taken to address the objective. This could include:\n\nData processing and cleaning steps\nExploratory Data Analysis (EDA)\nModels used\nStatistical tests\n\nInclude relevant code snippets and visualizations where necessary.\n\n\n\nSummarize the key findings, insights, and interpretations from the analysis. What did the data reveal? Were there any unexpected results or trends? How do these results relate to the original objective? In what ways do the findings from this analysis connect to real-world challenges?\n\n\n\n\n\nOriginal Data Source: [Link to the dataset or description of its origin]\n\nLicense: [Dataset license, e.g., “CC BY 4.0”]\n\nCitation: [If applicable, how to cite the data source or paper]\n\nReferences: [Links to or descriptions of key methods, algorithms, or resources used]\n\nAcknowledgements: [Contributors, collaborators, or any support received]"
  },
  {
    "objectID": "template/template.html#about-the-data",
    "href": "template/template.html#about-the-data",
    "title": "Diverse Data Hub Template",
    "section": "",
    "text": "Provide background information and context about the dataset. Think about answering the following questions:\n\nWhere does the data come from?\nWhy was it collected?\nWhy is the topic of the data socially relevant in the context of equity, diversity and inclusion?"
  },
  {
    "objectID": "template/template.html#case-study",
    "href": "template/template.html#case-study",
    "title": "Diverse Data Hub Template",
    "section": "",
    "text": "Clearly define the problem or question being addressed by this analysis. What is the goal? What data science problem are you trying to solve or understand with this dataset?\n\n\n\nDescribe the approach taken to address the objective. This could include:\n\nData processing and cleaning steps\nExploratory Data Analysis (EDA)\nModels used\nStatistical tests\n\nInclude relevant code snippets and visualizations where necessary.\n\n\n\nSummarize the key findings, insights, and interpretations from the analysis. What did the data reveal? Were there any unexpected results or trends? How do these results relate to the original objective? In what ways do the findings from this analysis connect to real-world challenges?"
  },
  {
    "objectID": "template/template.html#attribution",
    "href": "template/template.html#attribution",
    "title": "Diverse Data Hub Template",
    "section": "",
    "text": "Original Data Source: [Link to the dataset or description of its origin]\n\nLicense: [Dataset license, e.g., “CC BY 4.0”]\n\nCitation: [If applicable, how to cite the data source or paper]\n\nReferences: [Links to or descriptions of key methods, algorithms, or resources used]\n\nAcknowledgements: [Contributors, collaborators, or any support received]"
  },
  {
    "objectID": "website_files/datasets.html",
    "href": "website_files/datasets.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Women’s March Madness\n\n\nDescription: This data set tracks every NCAA Division I Women’s Basketball Tournament appearance since 1982 up until 2018. It includes team seeds, results, bid types, season and conference records, and regional placements. Useful for analyzing team success, seeding impact, conference strength, and historical trends in women’s college basketball over four decades.\n\nMore Details\n\n\n\n\nWildfire\n\n\nDescription: This data set on Canadian wildfires includes data on fire size, cause, location, detection method, response, and weather. Collected from official sources, it supports wildfire risk assessment and response. It also highlights social and geographic disparities, emphasizing impacts on remote and underserved communities facing climate-related and infrastructure challenges.\n\nMore Details\n\n\n\n\nHow Couples Meet and Stay Together\n\n\nDescription: This data set contains information from a 2022 survey of people across the U.S. to understand how couples meet and stay together. It focuses on how relationships were influenced by the COVID-19 pandemic and offers insight at modern relationships, including changes in dating habits and how couples adapted during a challenging time.\n\nMore Details\n\n\n\n\nIndigenous Businesses\n\n\nDescription: XXX\n\nMore Details\n\n\n\n\nGender Assessment\n\n\nDescription: XXX\n\nMore Details\n\n\n\n\nGlobal Rights\n\n\nDescription: XXX\n\nMore Details"
  },
  {
    "objectID": "website_files/description_pages/marchmadness.html",
    "href": "website_files/description_pages/marchmadness.html",
    "title": "Women’s March Madness",
    "section": "",
    "text": "Dataset contains data for every team that has participated in the NCAA Division I Women’s Basketball Tournament since it began in 1982 up until 2018. Every school is shown with its seed, conference record (when available), regular-season record, tournament record and full season record, including winning percentages. All data is sourced directly fromthe NCAA and contains the data behind the story The Rise and Fall Of Women’s NCAA Tournament Dynasties.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nwomensmarchmadness.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nWomen In Sports\n\n\nAssociated Tasks\n\n\nRegression, Classification\n\n\nFeature Type\n\n\nFactor, Integer, Numeric\n\n\nInstances\n\n\n2092\n\n\nFeatures\n\n\n20\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nyear\nFeature\ninteger\nYear\n-\nNo\n\n\nschool\nFeature\nnominal categorical\nSchool\n-\nNo\n\n\nseed\nFeature\nordinal categorical\nSeed. The 0 seeding designation in 1983 notes the eight teams that played an opening-round game to become the No. 8 seed in each region.\n-\nNo\n\n\nconference\nFeature\nnominal categorical\nConference\n-\nNo\n\n\nconf_wins\nFeature\nnumeric\nConference Wins\n-\nYes\n\n\nconf_losses\nFeature\nnumeric\nConference Losses\n-\nYes\n\n\nconf_wins_pct\nFeature\nnumeric\nConference Win Percentage\n-\nYes\n\n\nconf_rank\nFeature\nnumeric\nPlace in Conference\n-\nYes\n\n\ndivision\nFeature\nnominal categorical\nConference Division\n-\nYes\n\n\nreg_wins\nFeature\ninteger\nRegional Wins\n-\nNo\n\n\nreg_losses\nFeature\ninteger\nRegional Losses\n-\nNo\n\n\nreg_wins_pct\nFeature\nnumeric\nRegional Win Percentage\n%\nNo\n\n\nbid\nFeature\nnominal categorical\nWhether the school qualified with an automatic bid (by winning its conference or conference tournament) or an at-large bid. [‘at-large’, ‘auto’]\n-\nNo\n\n\nfirst_game_at_home\nFeature\nnominal categorical\nWhether the school played its first-round tournament games on its home court. [‘Y’, ‘N’]\n-\nNo\n\n\ntourney_wins\nFeature\ninteger\nTourney Wins\n-\nNo\n\n\ntourney_losses\nFeature\ninteger\nTourney Losses\n-\nNo\n\n\ntourney_finish\nTarget\nordinal categorical\nOrdered categories: [‘opening_round_loss’ &lt; ‘first_round_loss’ &lt; ‘second_round_loss’ &lt; ‘top_16_loss’ &lt; ‘top_8_loss’ &lt; ‘top_4_loss’ &lt; ‘top_2_loss’ &lt; ‘champ’]\n-\nNo\n\n\ntotal_wins\nFeature\ninteger\nTotal Wins\n-\nNo\n\n\ntotal_losses\nFeature\ninteger\nTotal Losses\n-\nNo\n\n\ntotal_wins_pct\nFeature\nnumeric\nTotal Win Percentage\n%\nNo"
  },
  {
    "objectID": "website_files/description_pages/marchmadness.html#data-set-information",
    "href": "website_files/description_pages/marchmadness.html#data-set-information",
    "title": "Women’s March Madness",
    "section": "",
    "text": "Dataset contains data for every team that has participated in the NCAA Division I Women’s Basketball Tournament since it began in 1982 up until 2018. Every school is shown with its seed, conference record (when available), regular-season record, tournament record and full season record, including winning percentages. All data is sourced directly fromthe NCAA and contains the data behind the story The Rise and Fall Of Women’s NCAA Tournament Dynasties.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nwomensmarchmadness.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nWomen In Sports\n\n\nAssociated Tasks\n\n\nRegression, Classification\n\n\nFeature Type\n\n\nFactor, Integer, Numeric\n\n\nInstances\n\n\n2092\n\n\nFeatures\n\n\n20\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nyear\nFeature\ninteger\nYear\n-\nNo\n\n\nschool\nFeature\nnominal categorical\nSchool\n-\nNo\n\n\nseed\nFeature\nordinal categorical\nSeed. The 0 seeding designation in 1983 notes the eight teams that played an opening-round game to become the No. 8 seed in each region.\n-\nNo\n\n\nconference\nFeature\nnominal categorical\nConference\n-\nNo\n\n\nconf_wins\nFeature\nnumeric\nConference Wins\n-\nYes\n\n\nconf_losses\nFeature\nnumeric\nConference Losses\n-\nYes\n\n\nconf_wins_pct\nFeature\nnumeric\nConference Win Percentage\n-\nYes\n\n\nconf_rank\nFeature\nnumeric\nPlace in Conference\n-\nYes\n\n\ndivision\nFeature\nnominal categorical\nConference Division\n-\nYes\n\n\nreg_wins\nFeature\ninteger\nRegional Wins\n-\nNo\n\n\nreg_losses\nFeature\ninteger\nRegional Losses\n-\nNo\n\n\nreg_wins_pct\nFeature\nnumeric\nRegional Win Percentage\n%\nNo\n\n\nbid\nFeature\nnominal categorical\nWhether the school qualified with an automatic bid (by winning its conference or conference tournament) or an at-large bid. [‘at-large’, ‘auto’]\n-\nNo\n\n\nfirst_game_at_home\nFeature\nnominal categorical\nWhether the school played its first-round tournament games on its home court. [‘Y’, ‘N’]\n-\nNo\n\n\ntourney_wins\nFeature\ninteger\nTourney Wins\n-\nNo\n\n\ntourney_losses\nFeature\ninteger\nTourney Losses\n-\nNo\n\n\ntourney_finish\nTarget\nordinal categorical\nOrdered categories: [‘opening_round_loss’ &lt; ‘first_round_loss’ &lt; ‘second_round_loss’ &lt; ‘top_16_loss’ &lt; ‘top_8_loss’ &lt; ‘top_4_loss’ &lt; ‘top_2_loss’ &lt; ‘champ’]\n-\nNo\n\n\ntotal_wins\nFeature\ninteger\nTotal Wins\n-\nNo\n\n\ntotal_losses\nFeature\ninteger\nTotal Losses\n-\nNo\n\n\ntotal_wins_pct\nFeature\nnumeric\nTotal Win Percentage\n%\nNo"
  },
  {
    "objectID": "website_files/description_pages/marchmadness.html#about-the-data",
    "href": "website_files/description_pages/marchmadness.html#about-the-data",
    "title": "Women’s March Madness",
    "section": "About the Data",
    "text": "About the Data\nThis adapted data set contains historical records of every NCAA Division I Women’s Basketball Tournament appearance since the tournament began in 1982 up until 2018. Sourced from official NCAA, the adapted data set captures tournament results across more than four decades of collegiate women’s basketball.\nThe rise in popularity of the NCAA Women’s March Madness, fueled by athletes like Caitlin Clark and Paige Bueckers, reflects a broader cultural shift in the recognition of women’s sports. Beyond entertainment and athletic achievement, women’s participation in sport has social and professional benefits.\nAs Beth A. Brooke notes in her article Here’s Why Women Who Play Sports Are More Successful, research from EY shows that 94% of women in executive leadership roles played sports, and over half competed at the university level. Participation in sports hel develop skills such as resilience, teamwork, and competitiveness, traits that critical for career success.\nAnalyzing NCAA Women’s March Madness results and promoting visibility of women in sports, beyond exercising our data skills, supports advocation for equity, opportunity, and empowerment of women in leadership.\n\nKey Features of the Dataset\nEach row represents a single team’s appearance in a specific tournament year and includes information such as:\n\nTournament Seed – Seed assigned to the team\nTournament Results – Number of wins, losses, and how far the team advanced\nBid Type – Whether the team received an automatic bid or was selected at-large.\nSeason Records – Regular season, conference, and total win/loss stats and percentages\nConference Information – Team’s conference name, record, and rank within the conference\nDivision – Regional placement in the tournament bracket (e.g., East, West)\nHome Game Indication – Whether the team played its first game at home\n\n\n\nPurpose and Use Cases\nThis dataset is designed to support analysis of:\n\nTeam performance over time\nImpact of seeding and bid types on tournament results\nConference strength\nEmergence and decline of winning teams in women’s college basketball"
  },
  {
    "objectID": "website_files/description_pages/marchmadness.html#case-study",
    "href": "website_files/description_pages/marchmadness.html#case-study",
    "title": "Women’s March Madness",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nHow much does a team’s tournament seed predict its success in the NCAA Division I Women’s Basketball Tournament?\nThis analysis explores the relationship between a team’s seed and its results on a tournament to evaluate whether teams with lower seeds consistently outperform ones with higher seeds.\nBy examining historical data, we aim to:\n\nIdentify trends in tournament advancement by seed level\n\nSeeding is intended to reflect a team’s regular-season performance. In theory, lower-numbered seeds (e.g., #1, #2) are given to the strongest teams, who should be more likely to advance. But upsets, bracket surprises, and standout performances from lower seeds raise questions like “How reliable is seeding as a predictor of success?”\nUnderstanding these dynamics can inform fan expectations and bracket predictions.\n\n\nMethodology\n\n1. Data Cleaning & Processing\nFirst, let’s load our data and remove all NA values for our variables of interest seed and tourney_wins.\n\nlibrary(tidyverse) \n\n# Reading Data\nmarchmadness &lt;- read_csv(\"../../data/clean/womensmarchmadness.csv\") \n\n# Review total rows\nnrow(marchmadness)\n\n[1] 2092\n\n# Removing NA but only in selected columns\nmarchmadness &lt;- marchmadness |&gt; drop_na(seed, tourney_wins)\n\n# Notice no rows were removed\nnrow(marchmadness)\n\n[1] 2092\n\n# Visualize the data set\nhead(marchmadness)\n\n# A tibble: 6 × 20\n   year school     seed conference conf_wins conf_losses conf_wins_pct conf_rank\n  &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n1  1982 Arizona …     4 Western C…        NA          NA          NA          NA\n2  1982 Auburn        7 Southeast…        NA          NA          NA          NA\n3  1982 Cheyney       2 Independe…        NA          NA          NA          NA\n4  1982 Clemson       5 Atlantic …         6           3          66.7         4\n5  1982 Drake         4 Missouri …        NA          NA          NA          NA\n6  1982 East Car…     6 Independe…        NA          NA          NA          NA\n# ℹ 12 more variables: division &lt;chr&gt;, reg_wins &lt;dbl&gt;, reg_losses &lt;dbl&gt;,\n#   reg_wins_pct &lt;dbl&gt;, bid &lt;chr&gt;, first_game_at_home &lt;chr&gt;,\n#   tourney_wins &lt;dbl&gt;, tourney_losses &lt;dbl&gt;, tourney_finish &lt;chr&gt;,\n#   total_wins &lt;dbl&gt;, total_losses &lt;dbl&gt;, total_wins_pct &lt;dbl&gt;\n\n\nNote that, the seed = 0 designation in 1983 notes the eight teams that played an opening-round game to become the No.8 seed in each region. For this exercise, we will not take them into consideration. Since seed is an ordinal categorical variable, we can set it as an ordered factor.\n\nmarchmadness &lt;- marchmadness |&gt; \n  filter(seed != 0)\n\n\n\n2. Exploratory Data Analysis\nWe can see which seeds appear more often.\n\nseed_count &lt;- marchmadness |&gt; \n  count(seed) |&gt; \n  arrange(desc(n)) |&gt;\n  mutate(seed = factor(seed, levels = seed))\n\nggplot(\n  seed_count, \n  aes(x = seed, y = n)\n  ) +\n  geom_col(fill = \"skyblue2\") +\n  labs(\n    title = \"Distribution of Tournament Seeds\",\n    x = \"Seed\",\n    y = \"Number of Teams\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can also take a look at the average tournament wins for each seed:\n\nmarchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  group_by(seed) |&gt; \n  summarise(\n    avg_tourney_wins = mean(tourney_wins, na.rm = TRUE)\n    ) |&gt;\n  arrange(desc(avg_tourney_wins)) |&gt;\n  mutate(seed = factor(seed, levels = seed)) |&gt;\n  ggplot(\n    aes(\n      x = as.factor(seed),\n      y = avg_tourney_wins)\n    ) +\n  geom_col(fill = \"skyblue2\") +\n  labs(\n    title = \"Average Tournament Wins by Seed\",\n    x = \"Seed\",\n    y = \"Avg. Tourney Wins\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can note that a teams with a higher seed tend to win more tournaments! We can also see the total amount of tourney wins for each seed.\n\nseed_order &lt;- marchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  group_by(seed) |&gt; \n  summarise(avg_wins = mean(tourney_wins, na.rm = TRUE)) |&gt; \n  arrange(desc(avg_wins)) |&gt; \n  pull(seed)\n\nmarchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  mutate(seed = factor(seed, levels = seed_order)) |&gt; \n  ggplot(\n    aes(x = seed, y = tourney_wins)\n  ) +\n  geom_violin(fill = \"skyblue2\") +\n  labs(\n    title = \"Distribution of Tournament Wins by Seed\",\n    x = \"Seed\",\n    y = \"Tournament Wins\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3. Hypothesis Testing: Are Seed and Wins Associated?\n\\(H_0\\)(Null): Seed and tournament wins are not associated\n\\(H_a\\)(Alternative): Seed and tournament wins are associated\n\ncor.test(marchmadness$seed, marchmadness$tourney_wins, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  marchmadness$seed and marchmadness$tourney_wins\nS = 2602468566, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.7252169 \n\n\nWe can note that from this correlation test, with a P-value below 0.05, we can reject the null hypothesis, denoting that seed and wins are likely associated. The strong negative Spearman’s rho suggests that lower seeds tend to win significantly more tournament games, as was confirmed from our exploratory analysis.\nThis can be visualized with the following plot:\n\nggplot(marchmadness, aes(x = seed, y = tourney_wins)) +\n  geom_jitter(width = 0.2, height = 0.2, alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"skyblue2\") +\n  labs(title = \"Seed vs Tournament Wins\",\n       x = \"Seed\",\n       y = \"Tournament Wins\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHowever, we can note that given that we’re setting tourney_wins as a response, our linear regression model may output negative values at high seed values. Therefore, a Poisson Regression model is better suited, considering that tourney wins is a count variable and is always non-negative.\n\npoisson_model &lt;- glm(tourney_wins ~ seed, family = \"poisson\", data = marchmadness)\nsummary(poisson_model)\n\n\nCall:\nglm(formula = tourney_wins ~ seed, family = \"poisson\", data = marchmadness)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.454260   0.035992   40.41   &lt;2e-16 ***\nseed        -0.260116   0.007231  -35.97   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3438.8  on 2083  degrees of freedom\nResidual deviance: 1610.3  on 2082  degrees of freedom\nAIC: 4238.8\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nmarchmadness$predicted_wins &lt;- predict(poisson_model, type = \"response\")\n\nmodel_plot &lt;- ggplot(marchmadness, aes(x = seed, y = tourney_wins)) +\n  geom_jitter(width = 0.3, alpha = 0.5) +\n  geom_line(aes(y = predicted_wins), color = \"skyblue2\", linewidth = 1.2) +\n  labs(title = \"Poisson Regression: Predicted Tournament Wins by Seed\",\n       x = \"Seed\",\n       y = \"Tournament Wins\") +\n  theme_minimal()\n\nmodel_plot\n\n\n\n\n\n\n\n\nThe seed coefficient \\(\\beta_1 = -0.2501\\) represents the log change in the expected number of tournament wins for every 1 unit increase in seed.\n\nexp(poisson_model$coefficients[\"seed\"])\n\n     seed \n0.7709619 \n\n\nThis means that for every increase in seed by 1, the expected tournament wins decreases by about 23% ( as 1-0.77 = 0.23)\n\n\n4. Overdispersion Testing\nIt is noteworthy that Poisson assumes that the mean is equal to the variance of the count variable. If the variance is much greater, we might need a Negative Binomial model. We can do an dispersion test to evaluate this matter.\nLetting \\(Y_i\\) be the \\(ith\\) Poisson response in the count regression model, in the presence of equidispersion, \\(Y_i\\) has the following parameters:\n\\(E(Y_i)=\\lambda_i, Var(Y_i)=\\lambda_i\\)\nThe test uses the following mathematical expression (using a \\(1+\\gamma\\) dispersion factor):\n\\(Var(Y_i)=(1+\\gamma)*\\lambda_i\\)\nwith the hypotheses:\n\\(H_0:1 + \\gamma = 1\\)\n\\(H_a: 1 + \\gamma &gt; 1\\)\nWhen there is evidence of overdispersion in our data, we will reject \\(H_o\\).\n\nlibrary(AER)\n\ndispersiontest(poisson_model)\n\n\n    Overdispersion test\n\ndata:  poisson_model\nz = -1.01, p-value = 0.8437\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n 0.9484459 \n\n\nSince the P-value (0.8437) is much greater than 0.05, we fail to reject the null hypothesis. This suggests that there is no significant evidence of overdispersion in the Poisson model.\n\n\n5. One Major Assumption…\nNote that throughout this analysis, we’ve made one big assumption: we have used seed as a numeric predictor. This assumes that the effect of seed is linear on the log scaled of the amount of tourney_wins.\n\nclass(marchmadness$seed)\n\n[1] \"numeric\"\n\n\nTo test if this assumption is appropraite, we can compare models that make different assumptions about seed.\nWe can create an equivalent Poisson model, but now, we can treat seed as a factor.\n\npoisson_model_factor &lt;- glm(tourney_wins ~ as.factor(as.character(seed)), family = \"poisson\", data = marchmadness)\nsummary(poisson_model_factor)\n\n\nCall:\nglm(formula = tourney_wins ~ as.factor(as.character(seed)), family = \"poisson\", \n    data = marchmadness)\n\nCoefficients:\n                                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                       1.24796    0.04390  28.430  &lt; 2e-16 ***\nas.factor(as.character(seed))10  -2.10541    0.14066 -14.969  &lt; 2e-16 ***\nas.factor(as.character(seed))11  -2.08421    0.14546 -14.329  &lt; 2e-16 ***\nas.factor(as.character(seed))12  -2.72794    0.19401 -14.061  &lt; 2e-16 ***\nas.factor(as.character(seed))13  -3.64585    0.33621 -10.844  &lt; 2e-16 ***\nas.factor(as.character(seed))14 -19.55054  574.63360  -0.034    0.973    \nas.factor(as.character(seed))15 -19.55054  571.75322  -0.034    0.973    \nas.factor(as.character(seed))16  -4.47678    0.50192  -8.919  &lt; 2e-16 ***\nas.factor(as.character(seed))2   -0.33849    0.06831  -4.955 7.23e-07 ***\nas.factor(as.character(seed))3   -0.66466    0.07531  -8.825  &lt; 2e-16 ***\nas.factor(as.character(seed))4   -0.79843    0.07898 -10.110  &lt; 2e-16 ***\nas.factor(as.character(seed))5   -1.25469    0.09319 -13.464  &lt; 2e-16 ***\nas.factor(as.character(seed))6   -1.41008    0.09963 -14.153  &lt; 2e-16 ***\nas.factor(as.character(seed))7   -1.56977    0.10576 -14.842  &lt; 2e-16 ***\nas.factor(as.character(seed))8   -1.90626    0.12500 -15.250  &lt; 2e-16 ***\nas.factor(as.character(seed))9   -1.87466    0.12733 -14.723  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3438.8  on 2083  degrees of freedom\nResidual deviance: 1534.5  on 2068  degrees of freedom\nAIC: 4191\n\nNumber of Fisher Scoring iterations: 16\n\n\nWe can visualize how the two models fit the data to evaluate if treating seed as numeric or factor would have a significant impact on our modelling process.\n\nmarchmadness &lt;- marchmadness |&gt; \n  mutate(\n    Numeric_Seed = predict(poisson_model, type = \"response\"),\n    Factor_Seed = predict(poisson_model_factor, type = \"response\")\n  )\n\nplot_data &lt;- marchmadness |&gt; \n  select(seed, tourney_wins, Numeric_Seed, Factor_Seed) |&gt; \n  pivot_longer(cols = c(\"Numeric_Seed\",\"Factor_Seed\"), names_to = \"model\", values_to = \"predicted\")\n\nggplot(plot_data, aes(x = seed, y = predicted, color = model)) +\n  geom_point(aes(y = tourney_wins), alpha = 0.3, color = \"black\") +\n  geom_line(stat = \"smooth\", method = \"loess\", se = FALSE, linewidth = 1.2) +\n  labs(title = \"Predicted Tournament Wins by Seed\",\n       x = \"Seed\",\n       y = \"Predicted Wins\",\n       color = \"Model\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHowever, is we wanted to formally evaluate which is the better approach we could use likelihood-based model selection tools.\n\nlibrary(broom)\n\nglance(poisson_model)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         3439.    2083 -2117. 4239. 4250.    1610.        2082  2084\n\nglance(poisson_model_factor)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         3439.    2083 -2080. 4191. 4281.    1535.        2068  2084\n\n\nBased on lower residual deviance, higher log-likelihood, and a lower AIC, the model that treats seed as a factor fits the data better. This would suggest that the relationship between tournament seed and number of wins is not linear, and would support using an approach that does not assume a constant effect per unit change in seed.\n\n\n6. Discussion\nThis analysis examined the relationship between a team’s tournament seed and its performance in the NCAA Division I Women’s Basketball Tournament. The results suggest that:\n\nSeed strongly predicts performance: Lower-numbered seeds (higher-ranked teams) tend to win more games on average. The correlation between seed and wins was statistically significant, with higher seeds associated with fewer wins.\nPoisson regression supports seeding as a predictor: The Poisson regression model confirmed that seed is a significant predictor of tournament wins, as expected for a count variable like wins.\nModel assumptions are key: Treating seed as a numeric variable assumes a linear effect across all seed values, which oversimplifies the relationship with the outcome. Ensuring that explanatory variables are approapriately coded is key. In this case, the influence of seeds could be described as slightly non-linear, which opens the door to discussion over model selection.\nThere is a lot of variation around the prediction: While seeding generally reflects team strength, upsets and unexpected performances do occur, showing that other factors also influence tournament outcomes.\n\nSeeding is an important predictor of success, but clearly other factors influence the results. It sets expectations, but unexpected performances still shape March Madness."
  },
  {
    "objectID": "website_files/description_pages/marchmadness.html#attribution",
    "href": "website_files/description_pages/marchmadness.html#attribution",
    "title": "Women’s March Madness",
    "section": "Attribution",
    "text": "Attribution\nData sourced from FiveThirtyEight’s NCAA Women’s Basketball Tournament dataset, available under a Creative Commons Attribution 4.0 International License. Original dataset: FiveThirtyEight GitHub Repository. Story: Louisiana Tech Was the UConn of the ’80s."
  },
  {
    "objectID": "website_files/grid_items/genderassessment.html",
    "href": "website_files/grid_items/genderassessment.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Gender Assessment\n\n\nDescription: XXX\n\nMore Details"
  },
  {
    "objectID": "website_files/grid_items/hcmst.html",
    "href": "website_files/grid_items/hcmst.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "How Couples Meet and Stay Together\n\n\nDescription: This data set contains information from a 2022 survey of people across the U.S. to understand how couples meet and stay together. It focuses on how relationships were influenced by the COVID-19 pandemic and offers insight at modern relationships, including changes in dating habits and how couples adapted during a challenging time.\n\nMore Details"
  },
  {
    "objectID": "website_files/grid_items/marchmadness.html",
    "href": "website_files/grid_items/marchmadness.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Women’s March Madness\n\n\nDescription: This data set tracks every NCAA Division I Women’s Basketball Tournament appearance since 1982 up until 2018. It includes team seeds, results, bid types, season and conference records, and regional placements. Useful for analyzing team success, seeding impact, conference strength, and historical trends in women’s college basketball over four decades.\n\nMore Details"
  },
  {
    "objectID": "website_files/notebooks/hcmst.html",
    "href": "website_files/notebooks/hcmst.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "X\n\n\nX\n\n\n\nX"
  },
  {
    "objectID": "website_files/notebooks/hcmst.html#about-the-data",
    "href": "website_files/notebooks/hcmst.html#about-the-data",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "X\n\n\nX\n\n\n\nX"
  },
  {
    "objectID": "website_files/notebooks/hcmst.html#case-study",
    "href": "website_files/notebooks/hcmst.html#case-study",
    "title": "Diverse Data Hub",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nX\n\n\nMethodology\n\n1. Data Cleaning & Processing\n\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Reading Data\nhcmst &lt;- read_csv(\"../../data/clean/hcmst.csv\") \n\nRows: 1328 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (18): subject_education, subject_sex, subject_ethnicity, subject_income_...\ndbl  (3): subject_age, relationship_duration, children\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Review total rows\nnrow(hcmst)\n\n[1] 1328\n\n# Removing NA since we plan on using all columns in our analysis\nhcmst &lt;- hcmst |&gt; \n  drop_na()\n\n# Notice no rows were removed\nnrow(hcmst)\n\n[1] 1192\n\n# Visualize the data set\nhead(hcmst)\n\n# A tibble: 6 × 21\n  subject_age subject_education subject_sex subject_ethnicity\n        &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;            \n1          53 high_school_grad  female      white            \n2          72 some_college      female      white            \n3          43 associate_degree  male        white            \n4          64 some_college      male        white            \n5          60 high_school_grad  female      black            \n6          78 high_school_grad  female      white            \n# ℹ 17 more variables: subject_income_category &lt;chr&gt;,\n#   subject_employment_status &lt;chr&gt;, same_sex_couple &lt;chr&gt;, married &lt;chr&gt;,\n#   sex_frequency &lt;chr&gt;, flirts_with_partner &lt;chr&gt;, fights_with_partner &lt;chr&gt;,\n#   relationship_duration &lt;dbl&gt;, children &lt;dbl&gt;,\n#   rel_change_during_pandemic &lt;chr&gt;, inc_change_during_pandemic &lt;chr&gt;,\n#   subject_had_covid &lt;chr&gt;, partner_had_covid &lt;chr&gt;, subject_vaccinated &lt;chr&gt;,\n#   partner_vaccinated &lt;chr&gt;, agree_covid_approach &lt;chr&gt;, …\n\n\n\n\n2. Exploratory Data Analysis\n\nnumeric_vars &lt;- c(\"subject_age\", \"relationship_duration\", \"children\")\n\nhcmst_long &lt;- hcmst |&gt;\n  select(all_of(numeric_vars)) |&gt;\n  pivot_longer(cols = everything(), names_to = \"variable\", values_to = \"value\")\n\nggplot(\n  hcmst_long, \n  aes(x = value)\n  ) +\n  geom_density(fill = \"skyblue2\") +\n  labs(title = \"Density Plots for Numeric Variables\", x = NULL, y = \"Density\") +\n  facet_wrap(~ variable, scales = \"free\", ncol = 2) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncols_to_plot &lt;- c(\"subject_education\", \"subject_sex\", \"subject_ethnicity\", \"subject_income_category\", \"subject_employment_status\", \"same_sex_couple\", \"married\", \"sex_frequency\", \"flirts_with_partner\", \"fights_with_partner\")\n\nhcmst_long &lt;- hcmst |&gt;\n  select(all_of(cols_to_plot)) |&gt;\n  pivot_longer(cols = everything(), names_to = \"variable\", values_to = \"value\") |&gt;\n  count(variable, value)\n\n\nggplot(\n  hcmst_long, \n  aes(y = reorder(value, n))\n  ) +\n  geom_bar(aes(x = n), stat = \"identity\", fill = \"skyblue2\") +\n  labs(\n    title = \"Counts by Category\",\n    x = \"Count\",\n    y = NULL\n  ) +\n  facet_wrap(~ variable, scales = \"free\", ncol = 1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncols_to_plot &lt;- c(\"rel_change_during_pandemic\", \"inc_change_during_pandemic\", \"subject_had_covid\", \"partner_had_covid\", \"subject_vaccinated\", \"partner_vaccinated\", \"agree_covid_approach\", \"sex_frequency\", \"flirts_with_partner\", \"fights_with_partner\")\n\nhcmst_long &lt;- hcmst |&gt;\n  select(all_of(cols_to_plot)) |&gt;\n  pivot_longer(cols = everything(), names_to = \"variable\", values_to = \"value\") |&gt;\n  count(variable, value)\n\n\nggplot(\n  hcmst_long, \n  aes(y = reorder(value, n))\n  ) +\n  geom_bar(aes(x = n), stat = \"identity\", fill = \"skyblue2\") +\n  labs(\n    title = \"Counts by Category\",\n    x = \"Count\",\n    y = NULL\n  ) +\n  facet_wrap(~ variable, scales = \"free\", ncol = 1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nrelationship_quality &lt;- hcmst |&gt; \n  add_count(relationship_quality) |&gt; \n  ggplot(aes(y = reorder(relationship_quality, n))) +\n  geom_bar(fill = \"skyblue2\") +\n  labs(\n    title = \"Quality of Relationships\",\n    x = \"Count\",\n    y = NULL\n  ) +\n  theme_minimal()\n\nrelationship_quality\n\n\n\n\n\n\n\n\n\nggsave(\"../img/hcmst.png\", plot = relationship_quality, width = 6, height = 4, dpi = 300)\n\n\n\n3. More…\n\nhcmst$subject_sex &lt;- as.factor(hcmst$subject_sex)\nlevels(hcmst$subject_sex)\n\n[1] \"female\" \"male\"  \n\nhcmst$subject_ethnicity &lt;- as.factor(hcmst$subject_ethnicity)\nlevels(hcmst$subject_ethnicity)\n\n[1] \"2_plus_eth\" \"black\"      \"hispanic\"   \"other\"      \"white\"     \n\nhcmst$subject_employment_status &lt;- as.factor(hcmst$subject_employment_status)\nlevels(hcmst$subject_employment_status)\n\n[1] \"not_working_disabled\"    \"not_working_looking\"    \n[3] \"not_working_other\"       \"not_working_retired\"    \n[5] \"not_working_temp_layoff\" \"working_paid_employee\"  \n[7] \"working_self_employed\"  \n\nhcmst$same_sex_couple &lt;- as.factor(hcmst$same_sex_couple)\nlevels(hcmst$same_sex_couple)\n\n[1] \"no\"  \"yes\"\n\nhcmst$married &lt;- as.factor(hcmst$married)\nlevels(hcmst$married)\n\n[1] \"married\"     \"not_married\"\n\nhcmst$subject_had_covid &lt;- as.factor(hcmst$subject_had_covid)\nlevels(hcmst$subject_had_covid)\n\n[1] \"no\"  \"yes\"\n\nhcmst$partner_had_covid &lt;- as.factor(hcmst$partner_had_covid)\nlevels(hcmst$partner_had_covid)\n\n[1] \"no\"  \"yes\"\n\nhcmst$subject_education &lt;- as.ordered(hcmst$subject_education)\nhcmst$subject_education &lt;- fct_relevel(\n  hcmst$subject_education,\n  c(\"prof_doct_degree\", \"masters_degree\", \"bach_degree\", \"associate_degree\", \"some_college\", \"high_school_grad\", \"12th_nodiploma\", \"11th\", \"10th\", \"9th\", \"7th_8th_grade\", \"5th_6th_grade\", \"1st_4th_grade\", \"no_education\")\n)\nlevels(hcmst$subject_education)\n\n [1] \"prof_doct_degree\" \"masters_degree\"   \"bach_degree\"      \"associate_degree\"\n [5] \"some_college\"     \"high_school_grad\" \"12th_nodiploma\"   \"11th\"            \n [9] \"10th\"             \"9th\"              \"7th_8th_grade\"    \"5th_6th_grade\"   \n[13] \"1st_4th_grade\"    \"no_education\"    \n\nhcmst$subject_income_category &lt;- as.ordered(hcmst$subject_income_category)\nhcmst$subject_income_category &lt;- fct_relevel(\n  hcmst$subject_income_category,\n  c(\"under_5k\", \"5k_7k\", \"7k_10k\", \"10k_12k\", \"12k_15k\", \"15k_20k\", \"20k_25k\", \"25k_30k\", \"30k_35k\", \"35k_40k\", \"40k_50k\", \"50k_60k\", \"60k_75k\", \"75k_85k\", \"85k_100k\", \"100k_125k\", \"125k_150k\", \"150k_175k\", \"175k_200k\", \"200k_250k\", \"over_250k\")\n)\nlevels(hcmst$subject_income_category)\n\n [1] \"under_5k\"  \"5k_7k\"     \"7k_10k\"    \"10k_12k\"   \"12k_15k\"   \"15k_20k\"  \n [7] \"20k_25k\"   \"25k_30k\"   \"30k_35k\"   \"35k_40k\"   \"40k_50k\"   \"50k_60k\"  \n[13] \"60k_75k\"   \"75k_85k\"   \"85k_100k\"  \"100k_125k\" \"125k_150k\" \"150k_175k\"\n[19] \"175k_200k\" \"200k_250k\" \"over_250k\"\n\nhcmst$sex_frequency &lt;- as.ordered(hcmst$sex_frequency)\nhcmst$sex_frequency &lt;- fct_relevel(\n  hcmst$sex_frequency,\n  c(\"once_or_more_a_day\", \"once_or_twice_a_week\", \"3_to_6_times_a_week\", \"2_to_3_times_a_month\", \"once_a_month_or_less\")\n)\nlevels(hcmst$sex_frequency)\n\n[1] \"once_or_more_a_day\"   \"once_or_twice_a_week\" \"3_to_6_times_a_week\" \n[4] \"2_to_3_times_a_month\" \"once_a_month_or_less\"\n\nhcmst$flirts_with_partner &lt;- as.ordered(hcmst$flirts_with_partner)\nhcmst$flirts_with_partner &lt;- fct_relevel(\n  hcmst$flirts_with_partner,\n  c(\"never\", \"less_than_once_a_month\", \"1_to_3_times_a_month\", \"once_a_week\", \"a_few_times_a_week\", \"every_day\")\n)\nlevels(hcmst$flirts_with_partner)\n\n[1] \"never\"                  \"less_than_once_a_month\" \"1_to_3_times_a_month\"  \n[4] \"once_a_week\"            \"a_few_times_a_week\"     \"every_day\"             \n\nhcmst$fights_with_partner &lt;- as.ordered(hcmst$fights_with_partner)\nhcmst$fights_with_partner &lt;- fct_relevel(\n  hcmst$fights_with_partner,\n  c(\"0_times\", \"1_time\", \"2_times\", \"3_times\", \"4_times\", \"5_times\", \"6_times\", \"7_or_more_times\")\n)\nlevels(hcmst$fights_with_partner)\n\n[1] \"0_times\"         \"1_time\"          \"2_times\"         \"3_times\"        \n[5] \"4_times\"         \"5_times\"         \"6_times\"         \"7_or_more_times\"\n\nhcmst$rel_change_during_pandemic &lt;- as.ordered(hcmst$rel_change_during_pandemic)\nhcmst$rel_change_during_pandemic &lt;- fct_relevel(\n  hcmst$rel_change_during_pandemic,\n  c(\"better_than_before\", \"no_change\", \"worse_than_before\")\n)\nlevels(hcmst$rel_change_during_pandemic)\n\n[1] \"better_than_before\" \"no_change\"          \"worse_than_before\" \n\nhcmst$inc_change_during_pandemic &lt;- as.ordered(hcmst$inc_change_during_pandemic)\nhcmst$inc_change_during_pandemic &lt;- fct_relevel(\n  hcmst$inc_change_during_pandemic,\n  c(\"much_worse\", \"worse\", \"no_change\", \"better\", \"much_better\")\n)\nlevels(hcmst$inc_change_during_pandemic)\n\n[1] \"much_worse\"  \"worse\"       \"no_change\"   \"better\"      \"much_better\"\n\nhcmst$subject_vaccinated &lt;- as.ordered(hcmst$subject_vaccinated)\nhcmst$subject_vaccinated &lt;- fct_relevel(\n  hcmst$subject_vaccinated,\n  c(\"not_vaccinated\", \"partially_vaccinated\", \"fully_vaccinated_no_booster\", \"fully_vaccinated_and_booster\")\n)\nlevels(hcmst$subject_vaccinated)\n\n[1] \"not_vaccinated\"               \"partially_vaccinated\"        \n[3] \"fully_vaccinated_no_booster\"  \"fully_vaccinated_and_booster\"\n\nhcmst$partner_vaccinated &lt;- as.ordered(hcmst$partner_vaccinated)\nhcmst$partner_vaccinated &lt;- fct_relevel(\n  hcmst$partner_vaccinated,\n  c(\"not_vaccinated\", \"partially_vaccinated\", \"fully_vaccinated_no_booster\", \"fully_vaccinated_and_booster\")\n)\nlevels(hcmst$partner_vaccinated)\n\n[1] \"not_vaccinated\"               \"partially_vaccinated\"        \n[3] \"fully_vaccinated_no_booster\"  \"fully_vaccinated_and_booster\"\n\nhcmst$agree_covid_approach &lt;- as.ordered(hcmst$agree_covid_approach)\nhcmst$agree_covid_approach &lt;- fct_relevel(\n  hcmst$agree_covid_approach,\n  c(\"completely_agree\", \"mostly_agree\", \"mostly_disagree\", \"completely_disagree\")\n)\nlevels(hcmst$agree_covid_approach)\n\n[1] \"completely_agree\"    \"mostly_agree\"        \"mostly_disagree\"    \n[4] \"completely_disagree\"\n\nhcmst$relationship_quality &lt;- as.ordered(hcmst$relationship_quality)\nhcmst$relationship_quality &lt;- fct_relevel(\n  hcmst$relationship_quality,\n  c(\"excellent\", \"good\", \"fair\", \"poor\", \"very_poor\")\n)\nlevels(hcmst$relationship_quality)\n\n[1] \"excellent\" \"good\"      \"fair\"      \"poor\"      \"very_poor\"\n\nhead(hcmst)\n\n# A tibble: 6 × 21\n  subject_age subject_education subject_sex subject_ethnicity\n        &lt;dbl&gt; &lt;ord&gt;             &lt;fct&gt;       &lt;fct&gt;            \n1          53 high_school_grad  female      white            \n2          72 some_college      female      white            \n3          43 associate_degree  male        white            \n4          64 some_college      male        white            \n5          60 high_school_grad  female      black            \n6          78 high_school_grad  female      white            \n# ℹ 17 more variables: subject_income_category &lt;ord&gt;,\n#   subject_employment_status &lt;fct&gt;, same_sex_couple &lt;fct&gt;, married &lt;fct&gt;,\n#   sex_frequency &lt;ord&gt;, flirts_with_partner &lt;ord&gt;, fights_with_partner &lt;ord&gt;,\n#   relationship_duration &lt;dbl&gt;, children &lt;dbl&gt;,\n#   rel_change_during_pandemic &lt;ord&gt;, inc_change_during_pandemic &lt;ord&gt;,\n#   subject_had_covid &lt;fct&gt;, partner_had_covid &lt;fct&gt;, subject_vaccinated &lt;ord&gt;,\n#   partner_vaccinated &lt;ord&gt;, agree_covid_approach &lt;ord&gt;, …\n\n\n\ncolnames(hcmst)\n\n [1] \"subject_age\"                \"subject_education\"         \n [3] \"subject_sex\"                \"subject_ethnicity\"         \n [5] \"subject_income_category\"    \"subject_employment_status\" \n [7] \"same_sex_couple\"            \"married\"                   \n [9] \"sex_frequency\"              \"flirts_with_partner\"       \n[11] \"fights_with_partner\"        \"relationship_duration\"     \n[13] \"children\"                   \"rel_change_during_pandemic\"\n[15] \"inc_change_during_pandemic\" \"subject_had_covid\"         \n[17] \"partner_had_covid\"          \"subject_vaccinated\"        \n[19] \"partner_vaccinated\"         \"agree_covid_approach\"      \n[21] \"relationship_quality\"      \n\n\n\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nlibrary(broom)\n\noptions(contrasts = c(\"contr.treatment\", \"contr.sdif\"))\n\nfull_ordinal_model &lt;- polr(relationship_quality ~ subject_age + subject_education + subject_sex + subject_ethnicity + subject_income_category + subject_employment_status + same_sex_couple + married + sex_frequency + flirts_with_partner + fights_with_partner + relationship_duration + children + rel_change_during_pandemic + inc_change_during_pandemic + subject_had_covid + partner_had_covid + subject_vaccinated + partner_vaccinated + agree_covid_approach,\n  data = hcmst, Hess = TRUE\n)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nsummary_full_ordinal_model &lt;- cbind(tidy(full_ordinal_model),\n  p.value = pnorm(abs(tidy(full_ordinal_model)$statistic), lower.tail = FALSE) * 2) |&gt;\n  mutate_if(is.numeric, round, 2)\n\nsummary_full_ordinal_model |&gt; \n  filter(p.value &lt; 0.05, \n         coef.type == \"coefficient\")\n\n                                                     term estimate std.error\n1                    subject_education11th-12th_nodiploma     1.98      0.89\n2             subject_educationno_education-1st_4th_grade   -18.17      0.06\n3                                      marriednot_married     0.78      0.21\n4   sex_frequency2_to_3_times_a_month-3_to_6_times_a_week     0.74      0.29\n5  sex_frequencyonce_a_month_or_less-2_to_3_times_a_month     0.94      0.17\n6         flirts_with_partnerevery_day-a_few_times_a_week    -0.69      0.30\n7                       fights_with_partner1_time-0_times     0.78      0.16\n8  rel_change_during_pandemicno_change-better_than_before     1.00      0.19\n9   rel_change_during_pandemicworse_than_before-no_change     1.94      0.28\n10              inc_change_during_pandemicno_change-worse    -0.58      0.18\n11      agree_covid_approachmostly_agree-completely_agree     0.47      0.15\n12       agree_covid_approachmostly_disagree-mostly_agree     1.38      0.43\n   statistic   coef.type p.value\n1       2.22 coefficient    0.03\n2    -308.64 coefficient    0.00\n3       3.76 coefficient    0.00\n4       2.54 coefficient    0.01\n5       5.44 coefficient    0.00\n6      -2.28 coefficient    0.02\n7       5.02 coefficient    0.00\n8       5.31 coefficient    0.00\n9       6.82 coefficient    0.00\n10     -3.19 coefficient    0.00\n11      3.23 coefficient    0.00\n12      3.19 coefficient    0.00\n\n\n\npredict(full_ordinal_model, tibble(\n  subject_age = 40, \n  subject_education = \"bach_degree\",\n  subject_sex = \"male\",\n  subject_ethnicity = \"hispanic\",\n  subject_income_category = \"60k_75k\",\n  subject_employment_status = \"working_paid_employee\",\n  same_sex_couple = \"yes\",\n  married = \"not_married\",\n  sex_frequency = \"2_to_3_times_a_month\",\n  flirts_with_partner = \"a_few_times_a_week\",\n  fights_with_partner = \"3_times\",\n  relationship_duration = 10,\n  children = 2,\n  rel_change_during_pandemic = \"no_change\",\n  inc_change_during_pandemic = \"much_worse\",\n  subject_had_covid = \"yes\",\n  partner_had_covid = \"yes\",\n  subject_vaccinated = \"fully_vaccinated_no_booster\",\n  partner_vaccinated = \"not_vaccinated\",\n  agree_covid_approach = \"completely_disagree\"), \n  type = \"probs\")\n\n excellent       good       fair       poor  very_poor \n0.03780206 0.43096376 0.42696611 0.09113980 0.01312827 \n\n\n\npartial_ordinal_model &lt;- polr(relationship_quality ~ subject_age + subject_education + subject_sex + subject_ethnicity + subject_income_category + subject_employment_status + same_sex_couple + married + sex_frequency + flirts_with_partner + fights_with_partner + relationship_duration + children + rel_change_during_pandemic + inc_change_during_pandemic + subject_had_covid + partner_had_covid + subject_vaccinated + partner_vaccinated + agree_covid_approach,\n  data = hcmst, Hess = TRUE\n)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nsummary_partial_ordinal_model &lt;- cbind(tidy(partial_ordinal_model),\n  p.value = pnorm(abs(tidy(partial_ordinal_model)$statistic), lower.tail = FALSE) * 2) |&gt;\n  mutate_if(is.numeric, round, 2)\n\nsummary_partial_ordinal_model |&gt; \n  filter(p.value &lt; 0.05, \n         coef.type == \"coefficient\")\n\n                                                     term estimate std.error\n1                    subject_education11th-12th_nodiploma     1.98      0.89\n2             subject_educationno_education-1st_4th_grade   -18.17      0.06\n3                                      marriednot_married     0.78      0.21\n4   sex_frequency2_to_3_times_a_month-3_to_6_times_a_week     0.74      0.29\n5  sex_frequencyonce_a_month_or_less-2_to_3_times_a_month     0.94      0.17\n6         flirts_with_partnerevery_day-a_few_times_a_week    -0.69      0.30\n7                       fights_with_partner1_time-0_times     0.78      0.16\n8  rel_change_during_pandemicno_change-better_than_before     1.00      0.19\n9   rel_change_during_pandemicworse_than_before-no_change     1.94      0.28\n10              inc_change_during_pandemicno_change-worse    -0.58      0.18\n11      agree_covid_approachmostly_agree-completely_agree     0.47      0.15\n12       agree_covid_approachmostly_disagree-mostly_agree     1.38      0.43\n   statistic   coef.type p.value\n1       2.22 coefficient    0.03\n2    -308.64 coefficient    0.00\n3       3.76 coefficient    0.00\n4       2.54 coefficient    0.01\n5       5.44 coefficient    0.00\n6      -2.28 coefficient    0.02\n7       5.02 coefficient    0.00\n8       5.31 coefficient    0.00\n9       6.82 coefficient    0.00\n10     -3.19 coefficient    0.00\n11      3.23 coefficient    0.00\n12      3.19 coefficient    0.00\n\n\n\n\n4. Discussion\nX"
  },
  {
    "objectID": "website_files/notebooks/notebook_py.html",
    "href": "website_files/notebooks/notebook_py.html",
    "title": "Python Page With Code",
    "section": "",
    "text": "import matplotlib.pyplot as plt\n\nplt.plot([1, 2, 3], [4, 9, 5])\nplt.title(\"Simple Python Plot\")\nplt.show()"
  },
  {
    "objectID": "website_files/notebooks/template.html",
    "href": "website_files/notebooks/template.html",
    "title": "Notebook Template",
    "section": "",
    "text": "Provide background information and context about the dataset. Think about answering the following questions:\n\nWhere does the data come from?\nWhy was it collected?\nWhy is the topic of the data socially relevant in the context of equity, diversity and inclusion?\n\n\n\n\n\n\nClearly define the problem or question being addressed by this analysis. What is the goal? What data science problem are you trying to solve or understand with this dataset?\n\n\n\nDescribe the approach taken to address the objective. This could include:\n\nData processing and cleaning steps\nExploratory Data Analysis (EDA)\nModels used\nStatistical tests\n\nInclude relevant code snippets and visualizations where necessary.\n\n\n\nSummarize the key findings, insights, and interpretations from the analysis. What did the data reveal? Were there any unexpected results or trends? How do these results relate to the original objective? In what ways do the findings from this analysis connect to real-world challenges?\n\n\n\n\n\nOriginal Data Source: [Link to the dataset or description of its origin]\n\nLicense: [Dataset license, e.g., “CC BY 4.0”]\n\nCitation: [If applicable, how to cite the data source or paper]\n\nReferences: [Links to or descriptions of key methods, algorithms, or resources used]\n\nAcknowledgements: [Contributors, collaborators, or any support received]"
  },
  {
    "objectID": "website_files/notebooks/template.html#about-the-data",
    "href": "website_files/notebooks/template.html#about-the-data",
    "title": "Notebook Template",
    "section": "",
    "text": "Provide background information and context about the dataset. Think about answering the following questions:\n\nWhere does the data come from?\nWhy was it collected?\nWhy is the topic of the data socially relevant in the context of equity, diversity and inclusion?"
  },
  {
    "objectID": "website_files/notebooks/template.html#case-study",
    "href": "website_files/notebooks/template.html#case-study",
    "title": "Notebook Template",
    "section": "",
    "text": "Clearly define the problem or question being addressed by this analysis. What is the goal? What data science problem are you trying to solve or understand with this dataset?\n\n\n\nDescribe the approach taken to address the objective. This could include:\n\nData processing and cleaning steps\nExploratory Data Analysis (EDA)\nModels used\nStatistical tests\n\nInclude relevant code snippets and visualizations where necessary.\n\n\n\nSummarize the key findings, insights, and interpretations from the analysis. What did the data reveal? Were there any unexpected results or trends? How do these results relate to the original objective? In what ways do the findings from this analysis connect to real-world challenges?"
  },
  {
    "objectID": "website_files/notebooks/template.html#attribution",
    "href": "website_files/notebooks/template.html#attribution",
    "title": "Notebook Template",
    "section": "",
    "text": "Original Data Source: [Link to the dataset or description of its origin]\n\nLicense: [Dataset license, e.g., “CC BY 4.0”]\n\nCitation: [If applicable, how to cite the data source or paper]\n\nReferences: [Links to or descriptions of key methods, algorithms, or resources used]\n\nAcknowledgements: [Contributors, collaborators, or any support received]"
  }
]