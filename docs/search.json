[
  {
    "objectID": "website_files/notebooks/wildfire.html",
    "href": "website_files/notebooks/wildfire.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "This dataset contains information on wildfires in Canada, compiled from official government sources.\n\n\n\nFire size (in hectares)\nCause of fire (e.g., lightning, human activity)\nDetection method\nResponse team size\nLatitude/longitude of the fire\nWeather conditions at the time of fire\n\n\n\n\nThe data was collected to monitor, assess, and respond to wildfire risks across regions. Wildfires have significant environmental, social, and economic impacts—especially for remote, Indigenous, and underserved communities that may lack the infrastructure to respond effectively.\nFrom an equity and inclusion perspective, studying wildfire data can help identify geographic and resource disparities in fire detection and containment efforts, as well as the disproportionate risks certain populations face due to climate change and infrastructure gaps."
  },
  {
    "objectID": "website_files/notebooks/wildfire.html#about-the-data",
    "href": "website_files/notebooks/wildfire.html#about-the-data",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "This dataset contains information on wildfires in Canada, compiled from official government sources.\n\n\n\nFire size (in hectares)\nCause of fire (e.g., lightning, human activity)\nDetection method\nResponse team size\nLatitude/longitude of the fire\nWeather conditions at the time of fire\n\n\n\n\nThe data was collected to monitor, assess, and respond to wildfire risks across regions. Wildfires have significant environmental, social, and economic impacts—especially for remote, Indigenous, and underserved communities that may lack the infrastructure to respond effectively.\nFrom an equity and inclusion perspective, studying wildfire data can help identify geographic and resource disparities in fire detection and containment efforts, as well as the disproportionate risks certain populations face due to climate change and infrastructure gaps."
  },
  {
    "objectID": "website_files/notebooks/wildfire.html#case-study",
    "href": "website_files/notebooks/wildfire.html#case-study",
    "title": "Diverse Data Hub",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nCan we identify the environmental and human factors most associated with large wildfires (&gt;10 hectares)?\nThe goal is to explore potential predictors of fire size, such as weather, fire cause, and detection method, and provide insights that could inform early interventions and resource planning.\n\n\nMethodology\n\n1. Data Cleaning & Processing\n\nConverted fire size to numeric\nCreated a binary variable large_fire (TRUE if &gt;10 ha)\nFiltered out incomplete records\n\n\n\n2. Exploratory Data Analysis (EDA)\nFire Size Distribution\n\nlibrary(ggplot2)\n\nggplot(wildfire_clean, aes(x = ASSESSMENT_HECTARES)) +\n  geom_histogram(bins = 40) +\n  scale_x_log10() +\n  labs(\n    title = \"Distribution of Fire Size (Assessment Hectares)\",\n    x = \"Fire Size (log scale)\",\n    y = \"Number of Fires\"\n  )\n\n\n\n\n\n\n\n\nProportion of Large Fires by Cause\n\nwildfire_clean %&gt;%\n  group_by(TRUE_CAUSE) %&gt;%\n  summarize(prop_large = mean(large_fire, na.rm = TRUE)) %&gt;%\n  ggplot(aes(x = reorder(TRUE_CAUSE, prop_large), y = prop_large)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Proportion of Large Fires by True Cause\",\n    x = \"True Cause\",\n    y = \"Proportion of Fires &gt; 10 ha\"\n  )\n\n\n\n\n\n\n\n\n\n\n3. Logistic Regression Model\nWe build a logistic regression model to predict the likelihood of a fire becoming large based on temperature, wind speed, and cause.\n\nlibrary(broom)\n\nmodel &lt;- glm(\n  large_fire ~ TEMPERATURE + WIND_SPEED + TRUE_CAUSE + DETECTION_AGENT_TYPE,\n  data = wildfire_clean,\n  family = \"binomial\"\n)\n\n\n# Tidy and clean model output\ntidy_model &lt;- broom::tidy(model) %&gt;%\n  dplyr::mutate(\n    estimate = round(estimate, 3),\n    std.error = round(std.error, 3),\n    statistic = round(statistic, 2),\n    p.value = round(p.value, 4)\n  )\n\n# Create a nice table\ngt_table &lt;- tidy_model %&gt;%\n  gt::gt() %&gt;%\n  gt::tab_header(\n    title = \"Logistic Regression Results\",\n    subtitle = \"Predicting Large Fires (&gt; 10 ha)\"\n  ) %&gt;%\n  gt::cols_label(\n    term = \"Variable\",\n    estimate = \"Estimate (Log-Odds)\",\n    std.error = \"Std. Error\",\n    statistic = \"z value\",\n    p.value = \"p-value\"\n  ) %&gt;%\n  gt::fmt_missing(everything(), missing_text = \"-\") %&gt;%\n  gt::tab_options(\n    table.font.size = \"small\",\n    data_row.padding = gt::px(4),\n    heading.title.font.size = 16,\n    heading.subtitle.font.size = 12\n  )\n\ngt_table\n\n\n\n\n\n\n\nLogistic Regression Results\n\n\nPredicting Large Fires (&gt; 10 ha)\n\n\nVariable\nEstimate (Log-Odds)\nStd. Error\nz value\np-value\n\n\n\n\n(Intercept)\n-4.262\n0.512\n-8.32\n0.0000\n\n\nTEMPERATURE\n-0.040\n0.012\n-3.22\n0.0013\n\n\nWIND_SPEED\n0.051\n0.007\n7.01\n0.0000\n\n\nTRUE_CAUSEAnimals\n-15.465\n2121.042\n-0.01\n0.9942\n\n\nTRUE_CAUSEArson Known\n-16.045\n2200.700\n-0.01\n0.9942\n\n\nTRUE_CAUSEArson Suspected\n-0.219\n0.671\n-0.33\n0.7443\n\n\nTRUE_CAUSEBurning Substance\n-0.016\n0.450\n-0.04\n0.9716\n\n\nTRUE_CAUSEFlammable Fluids\n-16.016\n4207.738\n0.00\n0.9970\n\n\nTRUE_CAUSEFriction Spark\n0.401\n0.678\n0.59\n0.5541\n\n\nTRUE_CAUSEHigh Hazard\n-16.284\n1926.733\n-0.01\n0.9933\n\n\nTRUE_CAUSEHot Exhaust\n0.346\n0.793\n0.44\n0.6628\n\n\nTRUE_CAUSEIncendiary Device\n0.489\n1.075\n0.45\n0.6492\n\n\nTRUE_CAUSEInsufficient Buffer\n0.231\n0.514\n0.45\n0.6531\n\n\nTRUE_CAUSEInsufficient Resources\n3.811\n1.241\n3.07\n0.0021\n\n\nTRUE_CAUSELine Impact\n-2.123\n1.069\n-1.99\n0.0470\n\n\nTRUE_CAUSEMechanical Failure\n-0.532\n0.790\n-0.67\n0.5011\n\n\nTRUE_CAUSEPermit Related\n0.326\n0.425\n0.77\n0.4439\n\n\nTRUE_CAUSEUnattended Fire\n0.041\n1.064\n0.04\n0.9696\n\n\nTRUE_CAUSEUnclassified\n0.375\n0.791\n0.47\n0.6355\n\n\nTRUE_CAUSEUnpredictable Event\n-0.738\n0.800\n-0.92\n0.3562\n\n\nTRUE_CAUSEUnsafe Fire\n-0.146\n0.401\n-0.36\n0.7161\n\n\nTRUE_CAUSEVehicle Fire\n-0.631\n1.060\n-0.60\n0.5516\n\n\nTRUE_CAUSEWinter Burning\n0.433\n0.454\n0.95\n0.3409\n\n\nDETECTION_AGENT_TYPEGRP\n-16.143\n438.705\n-0.04\n0.9706\n\n\nDETECTION_AGENT_TYPELKT\n0.023\n0.371\n0.06\n0.9502\n\n\nDETECTION_AGENT_TYPEUNP\n-0.613\n0.363\n-1.69\n0.0907\n\n\n\n\n\n\n\n\n\n4. Discussion\nThe logistic regression model revealed that higher wind speeds are strongly associated with an increased likelihood of a fire becoming large (over 10 hectares), consistent with our expectations about fire spread dynamics.\nSurprisingly, temperature showed a small negative association with fire size, though this may be influenced by interactions with other environmental factors like humidity or fuel type.\nAmong causes, “Insufficient Resources” and “Line Impact” were associated with significantly higher odds of large fires. This suggests that both human-related limitations and infrastructure vulnerability (like power lines) play a role in fire escalation.\nThe detection agent type showed weak evidence that fires detected by UNP agents may be less likely to become large, compared to FPD Staff, but the effect was not statistically strong (p = 0.09). Further exploration is needed here, especially considering the early intervention ability of different detection teams.\nThese findings provide insights into key environmental and operational factors influencing wildfire severity. Importantly, they point to the need for targeted mitigation strategies in areas with poor detection access or high infrastructure risks.\nIn the broader context of equity, this analysis reinforces that resource constraints and delayed detection—often more common in remote or underfunded regions—can amplify wildfire impacts. Data-informed strategies can help ensure more equitable protection against climate-driven disasters.\n\n\n5. Interpretation Boost using marginaleffects\nWind Speed\nAs wind speed increases, the model estimates a higher probability of a fire becoming large (&gt;10 hectares). However, the variability in the predicted probabilities also increases at higher wind speeds, as indicated by the wider confidence intervals. This suggests that while there is a general upward trend, the model’s certainty about the exact magnitude of the effect decreases in this range—likely due to fewer observations or greater variability in fire outcomes at high wind speeds.\n\nlibrary(marginaleffects)\n\nWarning: package 'marginaleffects' was built under R version 4.4.3\n\n## continuous variable\nplot_predictions(\n  model,\n  by = \"WIND_SPEED\"\n)\n\n\n\n\n\n\n\n\nTemperature\nAs temperature increases, the model predicts a relatively stable probability of a fire becoming large. The trend line flattens and the confidence intervals narrow, indicating that the model is more confident and consistent in its estimates across higher temperature ranges. This suggests that the relationship between temperature and fire size is more stable and predictable at higher temperatures, possibly due to a larger number of observations or less variability in outcomes.\n\n## continuous variable \"TEMPERATURE\"\n\nplot_predictions(\n  model,\n  by = \"TEMPERATURE\"\n)\n\n\n\n\n\n\n\n\nTrue Cause\nThe predicted probability of a large fire is near zero for most TRUE_CAUSE categories, indicating that these causes (e.g., natural ignition, campfires, equipment use) are generally not associated with large-scale fires. However, the category “Insufficient Resources” stands out with a significantly higher predicted probability and a wide confidence interval. This suggests that fires classified under this cause are much more likely to become large, though the wide interval reflects substantial uncertainty — likely due to a small number of observations in that category.\n\n## categorical variable \"TRUE_CAUSE\"\nplot_predictions(model, by = \"TRUE_CAUSE\") +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1)) +\n  ggplot2::labs(\n    title = \"Predicted Probability of Large Fire by True Cause\",\n    x = \"True Cause\",\n    y = \"Predicted Probability\"\n  )\n\n\n\n\n\n\n\n\nDetection Agent Type\nAlthough fires detected by AIR agents appear more likely to become large, the model is relatively uncertain about this pattern. The wide confidence interval indicates that this result should be interpreted cautiously, and may reflect data sparsity or high variability in fire outcomes for AIR-detected cases.\n\n## categorical variable \"DETECTION_AGENT_TYPE\"\nplot_predictions(\n  model,\n  by = \"DETECTION_AGENT_TYPE\"\n)"
  },
  {
    "objectID": "website_files/notebooks/notebook_r.html",
    "href": "website_files/notebooks/notebook_r.html",
    "title": "R Page With Code",
    "section": "",
    "text": "library(ggplot2)\n\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 37 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 37 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "website_files/notebooks/marchmadness.html",
    "href": "website_files/notebooks/marchmadness.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "This adapted data set contains historical records of every NCAA Division I Women’s Basketball Tournament appearance since the tournament began in 1982 up until 2018. Sourced from official NCAA, the adapted data set captures tournament results across more than four decades of collegiate women’s basketball.\nThe rise in popularity of the NCAA Women’s March Madness, fueled by athletes like Caitlin Clark and Paige Bueckers, reflects a broader cultural shift in the recognition of women’s sports. Beyond entertainment and athletic achievement, women’s participation in sport has social and professional benefits.\nAs Beth A. Brooke notes in her article Here’s Why Women Who Play Sports Are More Successful, research from EY shows that 94% of women in executive leadership roles played sports, and over half competed at the university level. Participation in sports hel develop skills such as resilience, teamwork, and competitiveness, traits that critical for career success.\nAnalyzing NCAA Women’s March Madness results and promoting visibility of women in sports, beyond exercising our data skills, supports advocation for equity, opportunity, and empowerment of women in leadership.\n\n\nEach row represents a single team’s appearance in a specific tournament year and includes information such as:\n\nTournament Seed – Seed assigned to the team\nTournament Results – Number of wins, losses, and how far the team advanced\nBid Type – Whether the team received an automatic bid or was selected at-large.\nSeason Records – Regular season, conference, and total win/loss stats and percentages\nConference Information – Team’s conference name, record, and rank within the conference\nDivision – Regional placement in the tournament bracket (e.g., East, West)\nHome Game Indication – Whether the team played its first game at home\n\n\n\n\nThis dataset is designed to support analysis of:\n\nTeam performance over time\nImpact of seeding and bid types on tournament results\nConference strength\nEmergence and decline of winning teams in women’s college basketball"
  },
  {
    "objectID": "website_files/notebooks/marchmadness.html#about-the-data",
    "href": "website_files/notebooks/marchmadness.html#about-the-data",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "This adapted data set contains historical records of every NCAA Division I Women’s Basketball Tournament appearance since the tournament began in 1982 up until 2018. Sourced from official NCAA, the adapted data set captures tournament results across more than four decades of collegiate women’s basketball.\nThe rise in popularity of the NCAA Women’s March Madness, fueled by athletes like Caitlin Clark and Paige Bueckers, reflects a broader cultural shift in the recognition of women’s sports. Beyond entertainment and athletic achievement, women’s participation in sport has social and professional benefits.\nAs Beth A. Brooke notes in her article Here’s Why Women Who Play Sports Are More Successful, research from EY shows that 94% of women in executive leadership roles played sports, and over half competed at the university level. Participation in sports hel develop skills such as resilience, teamwork, and competitiveness, traits that critical for career success.\nAnalyzing NCAA Women’s March Madness results and promoting visibility of women in sports, beyond exercising our data skills, supports advocation for equity, opportunity, and empowerment of women in leadership.\n\n\nEach row represents a single team’s appearance in a specific tournament year and includes information such as:\n\nTournament Seed – Seed assigned to the team\nTournament Results – Number of wins, losses, and how far the team advanced\nBid Type – Whether the team received an automatic bid or was selected at-large.\nSeason Records – Regular season, conference, and total win/loss stats and percentages\nConference Information – Team’s conference name, record, and rank within the conference\nDivision – Regional placement in the tournament bracket (e.g., East, West)\nHome Game Indication – Whether the team played its first game at home\n\n\n\n\nThis dataset is designed to support analysis of:\n\nTeam performance over time\nImpact of seeding and bid types on tournament results\nConference strength\nEmergence and decline of winning teams in women’s college basketball"
  },
  {
    "objectID": "website_files/notebooks/marchmadness.html#case-study",
    "href": "website_files/notebooks/marchmadness.html#case-study",
    "title": "Diverse Data Hub",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nHow much does a team’s tournament seed predict its success in the NCAA Division I Women’s Basketball Tournament?\nThis analysis explores the relationship between a team’s seed and its results on a tournament to evaluate whether teams with lower seeds consistently outperform ones with higher seeds.\nBy examining historical data, we aim to:\n\nIdentify trends in tournament advancement by seed level\n\nSeeding is intended to reflect a team’s regular-season performance. In theory, lower-numbered seeds (e.g., #1, #2) are given to the strongest teams, who should be more likely to advance. But upsets, bracket surprises, and standout performances from lower seeds raise questions like “How reliable is seeding as a predictor of success?”\nUnderstanding these dynamics can inform fan expectations and bracket predictions.\n\n\nMethodology\n\n0. Loading Libraries\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(AER)\n\nWarning: package 'AER' was built under R version 4.4.2\n\n\nLoading required package: car\nLoading required package: carData\n\nAttaching package: 'car'\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nLoading required package: lmtest\n\n\nWarning: package 'lmtest' was built under R version 4.4.2\n\n\nLoading required package: zoo\n\n\nWarning: package 'zoo' was built under R version 4.4.2\n\n\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\nLoading required package: sandwich\n\n\nWarning: package 'sandwich' was built under R version 4.4.2\n\n\nLoading required package: survival\n\nlibrary(broom)\n\n\n\n1. Data Cleaning & Processing\nFirst, let’s load our data and remove all NA values for our variables of interest seed and tourney_wins.\n\n# Reading Data\nmarchmadness &lt;- read_csv(\"../../data/clean/womensmarchmadness.csv\") \n\n# Review total rows\nnrow(marchmadness)\n\n[1] 2092\n\n# Removing NA but only in selected columns\nmarchmadness &lt;- marchmadness |&gt; drop_na(seed, tourney_wins)\n\n# Notice no rows were removed\nnrow(marchmadness)\n\n[1] 2092\n\n# Visualize the data set\nhead(marchmadness)\n\n# A tibble: 6 × 20\n   year school     seed conference conf_wins conf_losses conf_wins_pct conf_rank\n  &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n1  1982 Arizona …     4 Western C…        NA          NA          NA          NA\n2  1982 Auburn        7 Southeast…        NA          NA          NA          NA\n3  1982 Cheyney       2 Independe…        NA          NA          NA          NA\n4  1982 Clemson       5 Atlantic …         6           3          66.7         4\n5  1982 Drake         4 Missouri …        NA          NA          NA          NA\n6  1982 East Car…     6 Independe…        NA          NA          NA          NA\n# ℹ 12 more variables: division &lt;chr&gt;, reg_wins &lt;dbl&gt;, reg_losses &lt;dbl&gt;,\n#   reg_wins_pct &lt;dbl&gt;, bid &lt;chr&gt;, first_game_at_home &lt;chr&gt;,\n#   tourney_wins &lt;dbl&gt;, tourney_losses &lt;dbl&gt;, tourney_finish &lt;chr&gt;,\n#   total_wins &lt;dbl&gt;, total_losses &lt;dbl&gt;, total_wins_pct &lt;dbl&gt;\n\n\nNote that, the seed = 0 designation in 1983 notes the eight teams that played an opening-round game to become the No.8 seed in each region. For this exercise, we will not take them into consideration. Since seed is an ordinal categorical variable, we can set it as an ordered factor.\n\nmarchmadness &lt;- marchmadness |&gt; \n  filter(seed != 0)\n\n\n\n2. Exploratory Data Analysis\nWe can see which seeds appear more often.\n\nseed_count &lt;- marchmadness |&gt; \n  count(seed) |&gt; \n  arrange(desc(n)) |&gt;\n  mutate(seed = factor(seed, levels = seed))\n\nggplot(\n  seed_count, \n  aes(x = seed, y = n)\n  ) +\n  geom_col(fill = \"skyblue2\") +\n  labs(\n    title = \"Distribution of Tournament Seeds\",\n    x = \"Seed\",\n    y = \"Number of Teams\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can also take a look at the average tournament wins for each seed:\n\nmarchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  group_by(seed) |&gt; \n  summarise(\n    avg_tourney_wins = mean(tourney_wins, na.rm = TRUE)\n    ) |&gt;\n  arrange(desc(avg_tourney_wins)) |&gt;\n  mutate(seed = factor(seed, levels = seed)) |&gt;\n  ggplot(\n    aes(\n      x = as.factor(seed),\n      y = avg_tourney_wins)\n    ) +\n  geom_col(fill = \"skyblue2\") +\n  labs(\n    title = \"Average Tournament Wins by Seed\",\n    x = \"Seed\",\n    y = \"Avg. Tourney Wins\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can note that a teams with a higher seed tend to win more tournaments! We can also see the total amount of tourney wins for each seed.\n\nseed_order &lt;- marchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  group_by(seed) |&gt; \n  summarise(avg_wins = mean(tourney_wins, na.rm = TRUE)) |&gt; \n  arrange(desc(avg_wins)) |&gt; \n  pull(seed)\n\nmarchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  mutate(seed = factor(seed, levels = seed_order)) |&gt; \n  ggplot(\n    aes(x = seed, y = tourney_wins)\n  ) +\n  geom_violin(fill = \"skyblue2\") +\n  labs(\n    title = \"Distribution of Tournament Wins by Seed\",\n    x = \"Seed\",\n    y = \"Tournament Wins\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3. Hypothesis Testing: Are Seed and Wins Associated?\n\\(H_0\\)(Null): Seed and tournament wins are not associated\n\\(H_a\\)(Alternative): Seed and tournament wins are associated\n\ncor.test(marchmadness$seed, marchmadness$tourney_wins, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  marchmadness$seed and marchmadness$tourney_wins\nS = 2602468566, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.7252169 \n\n\nWe can note that from this correlation test, with a P-value below 0.05, we can reject the null hypothesis, denoting that seed and wins are likely associated. The strong negative Spearman’s rho suggests that lower seeds tend to win significantly more tournament games, as was confirmed from our exploratory analysis.\nThis can be visualized with the following plot:\n\nggplot(marchmadness, aes(x = seed, y = tourney_wins)) +\n  geom_jitter(width = 0.2, height = 0.2, alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"skyblue2\") +\n  labs(title = \"Seed vs Tournament Wins\",\n       x = \"Seed\",\n       y = \"Tournament Wins\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHowever, we can note that given that we’re setting tourney_wins as a response, our linear regression model may output negative values at high seed values. Therefore, a Poisson Regression model is better suited, considering that tourney wins is a count variable and is always non-negative.\n\npoisson_model &lt;- glm(tourney_wins ~ seed, family = \"poisson\", data = marchmadness)\nsummary(poisson_model)\n\n\nCall:\nglm(formula = tourney_wins ~ seed, family = \"poisson\", data = marchmadness)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.454260   0.035992   40.41   &lt;2e-16 ***\nseed        -0.260116   0.007231  -35.97   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3438.8  on 2083  degrees of freedom\nResidual deviance: 1610.3  on 2082  degrees of freedom\nAIC: 4238.8\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nmarchmadness$predicted_wins &lt;- predict(poisson_model, type = \"response\")\n\nmodel_plot &lt;- ggplot(marchmadness, aes(x = seed, y = tourney_wins)) +\n  geom_jitter(width = 0.3, alpha = 0.5) +\n  geom_line(aes(y = predicted_wins), color = \"skyblue2\", linewidth = 1.2) +\n  labs(title = \"Poisson Regression: Predicted Tournament Wins by Seed\",\n       x = \"Seed\",\n       y = \"Tournament Wins\") +\n  theme_minimal()\n\nmodel_plot\n\n\n\n\n\n\n\n\nThe seed coefficient \\(\\beta_1 = -0.2501\\) represents the log change in the expected number of tournament wins for every 1 unit increase in seed.\n\nexp(poisson_model$coefficients[\"seed\"])\n\n     seed \n0.7709619 \n\n\nThis means that for every increase in seed by 1, the expected tournament wins decreases by about 23% ( as 1-0.77 = 0.23)\n\n\n4. Overdispersion Testing\nIt is noteworthy that Poisson assumes that the mean is equal to the variance of the count variable. If the variance is much greater, we might need a Negative Binomial model. We can do an dispersion test to evaluate this matter.\nLetting \\(Y_i\\) be the \\(ith\\) Poisson response in the count regression model, in the presence of equidispersion, \\(Y_i\\) has the following parameters:\n\\(E(Y_i)=\\lambda_i, Var(Y_i)=\\lambda_i\\)\nThe test uses the following mathematical expression (using a \\(1+\\gamma\\) dispersion factor):\n\\(Var(Y_i)=(1+\\gamma)*\\lambda_i\\)\nwith the hypotheses:\n\\(H_0:1 + \\gamma = 1\\)\n\\(H_a: 1 + \\gamma &gt; 1\\)\nWhen there is evidence of overdispersion in our data, we will reject \\(H_o\\).\n\ndispersiontest(poisson_model)\n\n\n    Overdispersion test\n\ndata:  poisson_model\nz = -1.01, p-value = 0.8437\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n 0.9484459 \n\n\nSince the P-value (0.8437) is much greater than 0.05, we fail to reject the null hypothesis. This suggests that there is no significant evidence of overdispersion in the Poisson model.\n\n\n5. One Major Assumption…\nNote that throughout this analysis, we’ve made one big assumption: we have used seed as a numeric predictor. This assumes that the effect of seed is linear on the log scaled of the amount of tourney_wins.\n\nclass(marchmadness$seed)\n\n[1] \"numeric\"\n\n\nTo test if this assumption is appropraite, we can compare models that make different assumptions about seed.\nWe can create an equivalent Poisson model, but now, we can treat seed as a factor.\n\npoisson_model_factor &lt;- glm(tourney_wins ~ as.factor(as.character(seed)), family = \"poisson\", data = marchmadness)\nsummary(poisson_model_factor)\n\n\nCall:\nglm(formula = tourney_wins ~ as.factor(as.character(seed)), family = \"poisson\", \n    data = marchmadness)\n\nCoefficients:\n                                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                       1.24796    0.04390  28.430  &lt; 2e-16 ***\nas.factor(as.character(seed))10  -2.10541    0.14066 -14.969  &lt; 2e-16 ***\nas.factor(as.character(seed))11  -2.08421    0.14546 -14.329  &lt; 2e-16 ***\nas.factor(as.character(seed))12  -2.72794    0.19401 -14.061  &lt; 2e-16 ***\nas.factor(as.character(seed))13  -3.64585    0.33621 -10.844  &lt; 2e-16 ***\nas.factor(as.character(seed))14 -19.55054  574.63360  -0.034    0.973    \nas.factor(as.character(seed))15 -19.55054  571.75322  -0.034    0.973    \nas.factor(as.character(seed))16  -4.47678    0.50192  -8.919  &lt; 2e-16 ***\nas.factor(as.character(seed))2   -0.33849    0.06831  -4.955 7.23e-07 ***\nas.factor(as.character(seed))3   -0.66466    0.07531  -8.825  &lt; 2e-16 ***\nas.factor(as.character(seed))4   -0.79843    0.07898 -10.110  &lt; 2e-16 ***\nas.factor(as.character(seed))5   -1.25469    0.09319 -13.464  &lt; 2e-16 ***\nas.factor(as.character(seed))6   -1.41008    0.09963 -14.153  &lt; 2e-16 ***\nas.factor(as.character(seed))7   -1.56977    0.10576 -14.842  &lt; 2e-16 ***\nas.factor(as.character(seed))8   -1.90626    0.12500 -15.250  &lt; 2e-16 ***\nas.factor(as.character(seed))9   -1.87466    0.12733 -14.723  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3438.8  on 2083  degrees of freedom\nResidual deviance: 1534.5  on 2068  degrees of freedom\nAIC: 4191\n\nNumber of Fisher Scoring iterations: 16\n\n\nWe can visualize how the two models fit the data to evaluate if treating seed as numeric or factor would have a significant impact on our modelling process.\n\nmarchmadness &lt;- marchmadness |&gt; \n  mutate(\n    Numeric_Seed = predict(poisson_model, type = \"response\"),\n    Factor_Seed = predict(poisson_model_factor, type = \"response\")\n  )\n\nplot_data &lt;- marchmadness |&gt; \n  select(seed, tourney_wins, Numeric_Seed, Factor_Seed) |&gt; \n  pivot_longer(cols = c(\"Numeric_Seed\",\"Factor_Seed\"), names_to = \"model\", values_to = \"predicted\")\n\nggplot(plot_data, aes(x = seed, y = predicted, color = model)) +\n  geom_point(aes(y = tourney_wins), alpha = 0.3, color = \"black\") +\n  geom_line(stat = \"smooth\", method = \"loess\", se = FALSE, linewidth = 1.2) +\n  labs(title = \"Predicted Tournament Wins by Seed\",\n       x = \"Seed\",\n       y = \"Predicted Wins\",\n       color = \"Model\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHowever, is we wanted to formally evaluate which is the better approach we could use likelihood-based model selection tools.\n\nglance(poisson_model)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         3439.    2083 -2117. 4239. 4250.    1610.        2082  2084\n\nglance(poisson_model_factor)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         3439.    2083 -2080. 4191. 4281.    1535.        2068  2084\n\n\nBased on lower residual deviance, higher log-likelihood, and a lower AIC, the model that treats seed as a factor fits the data better. This would suggest that the relationship between tournament seed and number of wins is not linear, and would support using an approach that does not assume a constant effect per unit change in seed.\n\n\n6. Discussion\nThis analysis examined the relationship between a team’s tournament seed and its performance in the NCAA Division I Women’s Basketball Tournament. The results suggest that:\n\nSeed strongly predicts performance: Lower-numbered seeds (higher-ranked teams) tend to win more games on average. The correlation between seed and wins was statistically significant, with higher seeds associated with fewer wins.\nPoisson regression supports seeding as a predictor: The Poisson regression model confirmed that seed is a significant predictor of tournament wins, as expected for a count variable like wins.\nModel assumptions are key: Treating seed as a numeric variable assumes a linear effect across all seed values, which oversimplifies the relationship with the outcome. Ensuring that explanatory variables are approapriately coded is key. In this case, the influence of seeds could be described as slightly non-linear, which opens the door to discussion over model selection.\nThere is a lot of variation around the prediction: While seeding generally reflects team strength, upsets and unexpected performances do occur, showing that other factors also influence tournament outcomes.\n\nSeeding is an important predictor of success, but clearly other factors influence the results. It sets expectations, but unexpected performances still shape March Madness."
  },
  {
    "objectID": "website_files/how_to_publish_a_new_notebook.html",
    "href": "website_files/how_to_publish_a_new_notebook.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "These steps assume you already have a completed working .qmd notebook file that you want to publish to the website.\nStrong recommendation: Use equivalent “hcmst” or “marchmadness” files for reference.\n1 - Fill Out the Data Set Card\nFile: website_files/grid_items/&lt;datasetfile&gt;.qmd\nFields to Complete:\n\ndata-featured - true or false (should be false by default - K. Burak approves featured status)\ndata-tags - python or r (programming language used)\nimg src - Path to image to display in card\n&lt;h3&gt; - dataset title\nData set description\nhref - link to full notebook (e.g., https://diverse-data-hub.github.io/website_files/description_pages/&lt;datasetname&gt;.html)\n\n2 - Add the Data Set Description Page:\nFile: website_files/description_pages/&lt;datasetfile&gt;.qmd\nWhat to include:\n\nPage title (title:)\nData Set Information section\nDownload button (href) path\nComplete metadata table (field-value)\nVariable table (respect header structures)\nEnsure correct paths to notebooks\nAttribution\n\n3 - Add the Notebook File:\nFile: website_files/notebooks/&lt;datasetfile&gt;.qmd\nStructure:\n\nFollow the template format.\nShould include: About the Data (Key Features on Dataset, Purpose and Use Cases), Case Study (Objective, Methodology)\n\n4 - Add Link to Homepage Sidebar\nFile: _quarto.yml\nAction:\nAdd a newitem under the “Datasets” section:\nwebsite:\n  sidebar:\n    contents:\n      - section: \"Datasets\"\n        contents:\n          - text: \"&lt;Data Set Title&gt;\"\n            href: \"https://diverse-data-hub.github.io/website_files/description_pages/&lt;datasetname&gt;.html\"\n5 - Feature the Dataset (Optional).\nFile: website_files/grid_items/&lt;file&gt;.qmd\nAction:\nIf approved to be featured, update:\nclass=\"grid-item\" data-featured=\"true\" data-tags=\"r\"\n6 - Create a Reproducible Featured Image\nFile: website_files/img/&lt;image&gt;.png\nAction:\nGenerate and save the image directly from your notebook using a reproducible method. Make sure the filename matches what’s referenced in Step 1.\nExample (in R):\nggsave(\"../img/&lt;image&gt;.png\", plot = plot_object_name, width = 6, height = 4, dpi = 300)\n7 - Preview and Render Changes\nBefore pushing:\n\nRun quarto preview to check your edits.\nRun quarto render to build the site. Links to hosted notebooks won’t work locally—use the host URL to inspect the rendered version."
  },
  {
    "objectID": "website_files/how_to_publish_a_new_notebook.html#how-to-add-a-new-notebook",
    "href": "website_files/how_to_publish_a_new_notebook.html#how-to-add-a-new-notebook",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "These steps assume you already have a completed working .qmd notebook file that you want to publish to the website.\nStrong recommendation: Use equivalent “hcmst” or “marchmadness” files for reference.\n1 - Fill Out the Data Set Card\nFile: website_files/grid_items/&lt;datasetfile&gt;.qmd\nFields to Complete:\n\ndata-featured - true or false (should be false by default - K. Burak approves featured status)\ndata-tags - python or r (programming language used)\nimg src - Path to image to display in card\n&lt;h3&gt; - dataset title\nData set description\nhref - link to full notebook (e.g., https://diverse-data-hub.github.io/website_files/description_pages/&lt;datasetname&gt;.html)\n\n2 - Add the Data Set Description Page:\nFile: website_files/description_pages/&lt;datasetfile&gt;.qmd\nWhat to include:\n\nPage title (title:)\nData Set Information section\nDownload button (href) path\nComplete metadata table (field-value)\nVariable table (respect header structures)\nEnsure correct paths to notebooks\nAttribution\n\n3 - Add the Notebook File:\nFile: website_files/notebooks/&lt;datasetfile&gt;.qmd\nStructure:\n\nFollow the template format.\nShould include: About the Data (Key Features on Dataset, Purpose and Use Cases), Case Study (Objective, Methodology)\n\n4 - Add Link to Homepage Sidebar\nFile: _quarto.yml\nAction:\nAdd a newitem under the “Datasets” section:\nwebsite:\n  sidebar:\n    contents:\n      - section: \"Datasets\"\n        contents:\n          - text: \"&lt;Data Set Title&gt;\"\n            href: \"https://diverse-data-hub.github.io/website_files/description_pages/&lt;datasetname&gt;.html\"\n5 - Feature the Dataset (Optional).\nFile: website_files/grid_items/&lt;file&gt;.qmd\nAction:\nIf approved to be featured, update:\nclass=\"grid-item\" data-featured=\"true\" data-tags=\"r\"\n6 - Create a Reproducible Featured Image\nFile: website_files/img/&lt;image&gt;.png\nAction:\nGenerate and save the image directly from your notebook using a reproducible method. Make sure the filename matches what’s referenced in Step 1.\nExample (in R):\nggsave(\"../img/&lt;image&gt;.png\", plot = plot_object_name, width = 6, height = 4, dpi = 300)\n7 - Preview and Render Changes\nBefore pushing:\n\nRun quarto preview to check your edits.\nRun quarto render to build the site. Links to hosted notebooks won’t work locally—use the host URL to inspect the rendered version."
  },
  {
    "objectID": "website_files/grid_items/marchmadness.html",
    "href": "website_files/grid_items/marchmadness.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Women’s March Madness\n\n\nDescription: This data set tracks every NCAA Division I Women’s Basketball Tournament appearance since 1982 up until 2018. It includes team seeds, results, bid types, season and conference records, and regional placements. Useful for analyzing team success, seeding impact, conference strength, and historical trends in women’s college basketball over four decades.\n\nMore Details"
  },
  {
    "objectID": "website_files/grid_items/hcmst.html",
    "href": "website_files/grid_items/hcmst.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "How Couples Meet and Stay Together\n\n\nDescription: This data set contains information from a 2022 survey of people across the U.S. to understand how couples meet and stay together. It focuses on how relationships were influenced by the COVID-19 pandemic and offers insight at modern relationships, including changes in dating habits and how couples adapted during a challenging time.\n\nMore Details"
  },
  {
    "objectID": "website_files/grid_items/genderassessment.html",
    "href": "website_files/grid_items/genderassessment.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Gender Assessment\n\n\nDescription: XXX\n\nMore Details"
  },
  {
    "objectID": "website_files/description_pages/marchmadness.html",
    "href": "website_files/description_pages/marchmadness.html",
    "title": "Women’s March Madness",
    "section": "",
    "text": "Dataset contains data for every team that has participated in the NCAA Division I Women’s Basketball Tournament since it began in 1982 up until 2018. Every school is shown with its seed, conference record (when available), regular-season record, tournament record and full season record, including winning percentages. All data is sourced directly fromthe NCAA and contains the data behind the story The Rise and Fall Of Women’s NCAA Tournament Dynasties.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nwomensmarchmadness.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nWomen In Sports\n\n\nAssociated Tasks\n\n\nRegression, Classification\n\n\nFeature Type\n\n\nFactor, Integer, Numeric\n\n\nInstances\n\n\n2092\n\n\nFeatures\n\n\n20\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nyear\nFeature\ninteger\nYear\n-\nNo\n\n\nschool\nFeature\nnominal categorical\nSchool\n-\nNo\n\n\nseed\nFeature\nordinal categorical\nSeed. The 0 seeding designation in 1983 notes the eight teams that played an opening-round game to become the No. 8 seed in each region.\n-\nNo\n\n\nconference\nFeature\nnominal categorical\nConference\n-\nNo\n\n\nconf_wins\nFeature\nnumeric\nConference Wins\n-\nYes\n\n\nconf_losses\nFeature\nnumeric\nConference Losses\n-\nYes\n\n\nconf_wins_pct\nFeature\nnumeric\nConference Win Percentage\n-\nYes\n\n\nconf_rank\nFeature\nnumeric\nPlace in Conference\n-\nYes\n\n\ndivision\nFeature\nnominal categorical\nConference Division\n-\nYes\n\n\nreg_wins\nFeature\ninteger\nRegional Wins\n-\nNo\n\n\nreg_losses\nFeature\ninteger\nRegional Losses\n-\nNo\n\n\nreg_wins_pct\nFeature\nnumeric\nRegional Win Percentage\n%\nNo\n\n\nbid\nFeature\nnominal categorical\nWhether the school qualified with an automatic bid (by winning its conference or conference tournament) or an at-large bid. [‘at-large’, ‘auto’]\n-\nNo\n\n\nfirst_game_at_home\nFeature\nnominal categorical\nWhether the school played its first-round tournament games on its home court. [‘Y’, ‘N’]\n-\nNo\n\n\ntourney_wins\nFeature\ninteger\nTourney Wins\n-\nNo\n\n\ntourney_losses\nFeature\ninteger\nTourney Losses\n-\nNo\n\n\ntourney_finish\nTarget\nordinal categorical\nOrdered categories: [‘opening_round_loss’ &lt; ‘first_round_loss’ &lt; ‘second_round_loss’ &lt; ‘top_16_loss’ &lt; ‘top_8_loss’ &lt; ‘top_4_loss’ &lt; ‘top_2_loss’ &lt; ‘champ’]\n-\nNo\n\n\ntotal_wins\nFeature\ninteger\nTotal Wins\n-\nNo\n\n\ntotal_losses\nFeature\ninteger\nTotal Losses\n-\nNo\n\n\ntotal_wins_pct\nFeature\nnumeric\nTotal Win Percentage\n%\nNo"
  },
  {
    "objectID": "website_files/description_pages/marchmadness.html#data-set-information",
    "href": "website_files/description_pages/marchmadness.html#data-set-information",
    "title": "Women’s March Madness",
    "section": "",
    "text": "Dataset contains data for every team that has participated in the NCAA Division I Women’s Basketball Tournament since it began in 1982 up until 2018. Every school is shown with its seed, conference record (when available), regular-season record, tournament record and full season record, including winning percentages. All data is sourced directly fromthe NCAA and contains the data behind the story The Rise and Fall Of Women’s NCAA Tournament Dynasties.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nwomensmarchmadness.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nWomen In Sports\n\n\nAssociated Tasks\n\n\nRegression, Classification\n\n\nFeature Type\n\n\nFactor, Integer, Numeric\n\n\nInstances\n\n\n2092\n\n\nFeatures\n\n\n20\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nyear\nFeature\ninteger\nYear\n-\nNo\n\n\nschool\nFeature\nnominal categorical\nSchool\n-\nNo\n\n\nseed\nFeature\nordinal categorical\nSeed. The 0 seeding designation in 1983 notes the eight teams that played an opening-round game to become the No. 8 seed in each region.\n-\nNo\n\n\nconference\nFeature\nnominal categorical\nConference\n-\nNo\n\n\nconf_wins\nFeature\nnumeric\nConference Wins\n-\nYes\n\n\nconf_losses\nFeature\nnumeric\nConference Losses\n-\nYes\n\n\nconf_wins_pct\nFeature\nnumeric\nConference Win Percentage\n-\nYes\n\n\nconf_rank\nFeature\nnumeric\nPlace in Conference\n-\nYes\n\n\ndivision\nFeature\nnominal categorical\nConference Division\n-\nYes\n\n\nreg_wins\nFeature\ninteger\nRegional Wins\n-\nNo\n\n\nreg_losses\nFeature\ninteger\nRegional Losses\n-\nNo\n\n\nreg_wins_pct\nFeature\nnumeric\nRegional Win Percentage\n%\nNo\n\n\nbid\nFeature\nnominal categorical\nWhether the school qualified with an automatic bid (by winning its conference or conference tournament) or an at-large bid. [‘at-large’, ‘auto’]\n-\nNo\n\n\nfirst_game_at_home\nFeature\nnominal categorical\nWhether the school played its first-round tournament games on its home court. [‘Y’, ‘N’]\n-\nNo\n\n\ntourney_wins\nFeature\ninteger\nTourney Wins\n-\nNo\n\n\ntourney_losses\nFeature\ninteger\nTourney Losses\n-\nNo\n\n\ntourney_finish\nTarget\nordinal categorical\nOrdered categories: [‘opening_round_loss’ &lt; ‘first_round_loss’ &lt; ‘second_round_loss’ &lt; ‘top_16_loss’ &lt; ‘top_8_loss’ &lt; ‘top_4_loss’ &lt; ‘top_2_loss’ &lt; ‘champ’]\n-\nNo\n\n\ntotal_wins\nFeature\ninteger\nTotal Wins\n-\nNo\n\n\ntotal_losses\nFeature\ninteger\nTotal Losses\n-\nNo\n\n\ntotal_wins_pct\nFeature\nnumeric\nTotal Win Percentage\n%\nNo"
  },
  {
    "objectID": "website_files/description_pages/marchmadness.html#about-the-data",
    "href": "website_files/description_pages/marchmadness.html#about-the-data",
    "title": "Women’s March Madness",
    "section": "About the Data",
    "text": "About the Data\nThis adapted data set contains historical records of every NCAA Division I Women’s Basketball Tournament appearance since the tournament began in 1982 up until 2018. Sourced from official NCAA, the adapted data set captures tournament results across more than four decades of collegiate women’s basketball.\nThe rise in popularity of the NCAA Women’s March Madness, fueled by athletes like Caitlin Clark and Paige Bueckers, reflects a broader cultural shift in the recognition of women’s sports. Beyond entertainment and athletic achievement, women’s participation in sport has social and professional benefits.\nAs Beth A. Brooke notes in her article Here’s Why Women Who Play Sports Are More Successful, research from EY shows that 94% of women in executive leadership roles played sports, and over half competed at the university level. Participation in sports hel develop skills such as resilience, teamwork, and competitiveness, traits that critical for career success.\nAnalyzing NCAA Women’s March Madness results and promoting visibility of women in sports, beyond exercising our data skills, supports advocation for equity, opportunity, and empowerment of women in leadership.\n\nKey Features of the Dataset\nEach row represents a single team’s appearance in a specific tournament year and includes information such as:\n\nTournament Seed – Seed assigned to the team\nTournament Results – Number of wins, losses, and how far the team advanced\nBid Type – Whether the team received an automatic bid or was selected at-large.\nSeason Records – Regular season, conference, and total win/loss stats and percentages\nConference Information – Team’s conference name, record, and rank within the conference\nDivision – Regional placement in the tournament bracket (e.g., East, West)\nHome Game Indication – Whether the team played its first game at home\n\n\n\nPurpose and Use Cases\nThis dataset is designed to support analysis of:\n\nTeam performance over time\nImpact of seeding and bid types on tournament results\nConference strength\nEmergence and decline of winning teams in women’s college basketball"
  },
  {
    "objectID": "website_files/description_pages/marchmadness.html#case-study",
    "href": "website_files/description_pages/marchmadness.html#case-study",
    "title": "Women’s March Madness",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nHow much does a team’s tournament seed predict its success in the NCAA Division I Women’s Basketball Tournament?\nThis analysis explores the relationship between a team’s seed and its results on a tournament to evaluate whether teams with lower seeds consistently outperform ones with higher seeds.\nBy examining historical data, we aim to:\n\nIdentify trends in tournament advancement by seed level\n\nSeeding is intended to reflect a team’s regular-season performance. In theory, lower-numbered seeds (e.g., #1, #2) are given to the strongest teams, who should be more likely to advance. But upsets, bracket surprises, and standout performances from lower seeds raise questions like “How reliable is seeding as a predictor of success?”\nUnderstanding these dynamics can inform fan expectations and bracket predictions.\n\n\nMethodology\n\n0. Loading Libraries\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(AER)\n\nWarning: package 'AER' was built under R version 4.4.2\n\n\nLoading required package: car\nLoading required package: carData\n\nAttaching package: 'car'\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nLoading required package: lmtest\n\n\nWarning: package 'lmtest' was built under R version 4.4.2\n\n\nLoading required package: zoo\n\n\nWarning: package 'zoo' was built under R version 4.4.2\n\n\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\nLoading required package: sandwich\n\n\nWarning: package 'sandwich' was built under R version 4.4.2\n\n\nLoading required package: survival\n\nlibrary(broom)\n\n\n\n1. Data Cleaning & Processing\nFirst, let’s load our data and remove all NA values for our variables of interest seed and tourney_wins.\n\n# Reading Data\nmarchmadness &lt;- read_csv(\"../../data/clean/womensmarchmadness.csv\") \n\n# Review total rows\nnrow(marchmadness)\n\n[1] 2092\n\n# Removing NA but only in selected columns\nmarchmadness &lt;- marchmadness |&gt; drop_na(seed, tourney_wins)\n\n# Notice no rows were removed\nnrow(marchmadness)\n\n[1] 2092\n\n# Visualize the data set\nhead(marchmadness)\n\n# A tibble: 6 × 20\n   year school     seed conference conf_wins conf_losses conf_wins_pct conf_rank\n  &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n1  1982 Arizona …     4 Western C…        NA          NA          NA          NA\n2  1982 Auburn        7 Southeast…        NA          NA          NA          NA\n3  1982 Cheyney       2 Independe…        NA          NA          NA          NA\n4  1982 Clemson       5 Atlantic …         6           3          66.7         4\n5  1982 Drake         4 Missouri …        NA          NA          NA          NA\n6  1982 East Car…     6 Independe…        NA          NA          NA          NA\n# ℹ 12 more variables: division &lt;chr&gt;, reg_wins &lt;dbl&gt;, reg_losses &lt;dbl&gt;,\n#   reg_wins_pct &lt;dbl&gt;, bid &lt;chr&gt;, first_game_at_home &lt;chr&gt;,\n#   tourney_wins &lt;dbl&gt;, tourney_losses &lt;dbl&gt;, tourney_finish &lt;chr&gt;,\n#   total_wins &lt;dbl&gt;, total_losses &lt;dbl&gt;, total_wins_pct &lt;dbl&gt;\n\n\nNote that, the seed = 0 designation in 1983 notes the eight teams that played an opening-round game to become the No.8 seed in each region. For this exercise, we will not take them into consideration. Since seed is an ordinal categorical variable, we can set it as an ordered factor.\n\nmarchmadness &lt;- marchmadness |&gt; \n  filter(seed != 0)\n\n\n\n2. Exploratory Data Analysis\nWe can see which seeds appear more often.\n\nseed_count &lt;- marchmadness |&gt; \n  count(seed) |&gt; \n  arrange(desc(n)) |&gt;\n  mutate(seed = factor(seed, levels = seed))\n\nggplot(\n  seed_count, \n  aes(x = seed, y = n)\n  ) +\n  geom_col(fill = \"skyblue2\") +\n  labs(\n    title = \"Distribution of Tournament Seeds\",\n    x = \"Seed\",\n    y = \"Number of Teams\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can also take a look at the average tournament wins for each seed:\n\nmarchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  group_by(seed) |&gt; \n  summarise(\n    avg_tourney_wins = mean(tourney_wins, na.rm = TRUE)\n    ) |&gt;\n  arrange(desc(avg_tourney_wins)) |&gt;\n  mutate(seed = factor(seed, levels = seed)) |&gt;\n  ggplot(\n    aes(\n      x = as.factor(seed),\n      y = avg_tourney_wins)\n    ) +\n  geom_col(fill = \"skyblue2\") +\n  labs(\n    title = \"Average Tournament Wins by Seed\",\n    x = \"Seed\",\n    y = \"Avg. Tourney Wins\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can note that a teams with a higher seed tend to win more tournaments! We can also see the total amount of tourney wins for each seed.\n\nseed_order &lt;- marchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  group_by(seed) |&gt; \n  summarise(avg_wins = mean(tourney_wins, na.rm = TRUE)) |&gt; \n  arrange(desc(avg_wins)) |&gt; \n  pull(seed)\n\nmarchmadness |&gt; \n  filter(!is.na(seed), seed != 0) |&gt; \n  mutate(seed = factor(seed, levels = seed_order)) |&gt; \n  ggplot(\n    aes(x = seed, y = tourney_wins)\n  ) +\n  geom_violin(fill = \"skyblue2\") +\n  labs(\n    title = \"Distribution of Tournament Wins by Seed\",\n    x = \"Seed\",\n    y = \"Tournament Wins\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3. Hypothesis Testing: Are Seed and Wins Associated?\n\\(H_0\\)(Null): Seed and tournament wins are not associated\n\\(H_a\\)(Alternative): Seed and tournament wins are associated\n\ncor.test(marchmadness$seed, marchmadness$tourney_wins, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  marchmadness$seed and marchmadness$tourney_wins\nS = 2602468566, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.7252169 \n\n\nWe can note that from this correlation test, with a P-value below 0.05, we can reject the null hypothesis, denoting that seed and wins are likely associated. The strong negative Spearman’s rho suggests that lower seeds tend to win significantly more tournament games, as was confirmed from our exploratory analysis.\nThis can be visualized with the following plot:\n\nggplot(marchmadness, aes(x = seed, y = tourney_wins)) +\n  geom_jitter(width = 0.2, height = 0.2, alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"skyblue2\") +\n  labs(title = \"Seed vs Tournament Wins\",\n       x = \"Seed\",\n       y = \"Tournament Wins\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHowever, we can note that given that we’re setting tourney_wins as a response, our linear regression model may output negative values at high seed values. Therefore, a Poisson Regression model is better suited, considering that tourney wins is a count variable and is always non-negative.\n\npoisson_model &lt;- glm(tourney_wins ~ seed, family = \"poisson\", data = marchmadness)\nsummary(poisson_model)\n\n\nCall:\nglm(formula = tourney_wins ~ seed, family = \"poisson\", data = marchmadness)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.454260   0.035992   40.41   &lt;2e-16 ***\nseed        -0.260116   0.007231  -35.97   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3438.8  on 2083  degrees of freedom\nResidual deviance: 1610.3  on 2082  degrees of freedom\nAIC: 4238.8\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nmarchmadness$predicted_wins &lt;- predict(poisson_model, type = \"response\")\n\nmodel_plot &lt;- ggplot(marchmadness, aes(x = seed, y = tourney_wins)) +\n  geom_jitter(width = 0.3, alpha = 0.5) +\n  geom_line(aes(y = predicted_wins), color = \"skyblue2\", linewidth = 1.2) +\n  labs(title = \"Poisson Regression: Predicted Tournament Wins by Seed\",\n       x = \"Seed\",\n       y = \"Tournament Wins\") +\n  theme_minimal()\n\nmodel_plot\n\n\n\n\n\n\n\n\nThe seed coefficient \\(\\beta_1 = -0.2501\\) represents the log change in the expected number of tournament wins for every 1 unit increase in seed.\n\nexp(poisson_model$coefficients[\"seed\"])\n\n     seed \n0.7709619 \n\n\nThis means that for every increase in seed by 1, the expected tournament wins decreases by about 23% ( as 1-0.77 = 0.23)\n\n\n4. Overdispersion Testing\nIt is noteworthy that Poisson assumes that the mean is equal to the variance of the count variable. If the variance is much greater, we might need a Negative Binomial model. We can do an dispersion test to evaluate this matter.\nLetting \\(Y_i\\) be the \\(ith\\) Poisson response in the count regression model, in the presence of equidispersion, \\(Y_i\\) has the following parameters:\n\\(E(Y_i)=\\lambda_i, Var(Y_i)=\\lambda_i\\)\nThe test uses the following mathematical expression (using a \\(1+\\gamma\\) dispersion factor):\n\\(Var(Y_i)=(1+\\gamma)*\\lambda_i\\)\nwith the hypotheses:\n\\(H_0:1 + \\gamma = 1\\)\n\\(H_a: 1 + \\gamma &gt; 1\\)\nWhen there is evidence of overdispersion in our data, we will reject \\(H_o\\).\n\ndispersiontest(poisson_model)\n\n\n    Overdispersion test\n\ndata:  poisson_model\nz = -1.01, p-value = 0.8437\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n 0.9484459 \n\n\nSince the P-value (0.8437) is much greater than 0.05, we fail to reject the null hypothesis. This suggests that there is no significant evidence of overdispersion in the Poisson model.\n\n\n5. One Major Assumption…\nNote that throughout this analysis, we’ve made one big assumption: we have used seed as a numeric predictor. This assumes that the effect of seed is linear on the log scaled of the amount of tourney_wins.\n\nclass(marchmadness$seed)\n\n[1] \"numeric\"\n\n\nTo test if this assumption is appropraite, we can compare models that make different assumptions about seed.\nWe can create an equivalent Poisson model, but now, we can treat seed as a factor.\n\npoisson_model_factor &lt;- glm(tourney_wins ~ as.factor(as.character(seed)), family = \"poisson\", data = marchmadness)\nsummary(poisson_model_factor)\n\n\nCall:\nglm(formula = tourney_wins ~ as.factor(as.character(seed)), family = \"poisson\", \n    data = marchmadness)\n\nCoefficients:\n                                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                       1.24796    0.04390  28.430  &lt; 2e-16 ***\nas.factor(as.character(seed))10  -2.10541    0.14066 -14.969  &lt; 2e-16 ***\nas.factor(as.character(seed))11  -2.08421    0.14546 -14.329  &lt; 2e-16 ***\nas.factor(as.character(seed))12  -2.72794    0.19401 -14.061  &lt; 2e-16 ***\nas.factor(as.character(seed))13  -3.64585    0.33621 -10.844  &lt; 2e-16 ***\nas.factor(as.character(seed))14 -19.55054  574.63360  -0.034    0.973    \nas.factor(as.character(seed))15 -19.55054  571.75322  -0.034    0.973    \nas.factor(as.character(seed))16  -4.47678    0.50192  -8.919  &lt; 2e-16 ***\nas.factor(as.character(seed))2   -0.33849    0.06831  -4.955 7.23e-07 ***\nas.factor(as.character(seed))3   -0.66466    0.07531  -8.825  &lt; 2e-16 ***\nas.factor(as.character(seed))4   -0.79843    0.07898 -10.110  &lt; 2e-16 ***\nas.factor(as.character(seed))5   -1.25469    0.09319 -13.464  &lt; 2e-16 ***\nas.factor(as.character(seed))6   -1.41008    0.09963 -14.153  &lt; 2e-16 ***\nas.factor(as.character(seed))7   -1.56977    0.10576 -14.842  &lt; 2e-16 ***\nas.factor(as.character(seed))8   -1.90626    0.12500 -15.250  &lt; 2e-16 ***\nas.factor(as.character(seed))9   -1.87466    0.12733 -14.723  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3438.8  on 2083  degrees of freedom\nResidual deviance: 1534.5  on 2068  degrees of freedom\nAIC: 4191\n\nNumber of Fisher Scoring iterations: 16\n\n\nWe can visualize how the two models fit the data to evaluate if treating seed as numeric or factor would have a significant impact on our modelling process.\n\nmarchmadness &lt;- marchmadness |&gt; \n  mutate(\n    Numeric_Seed = predict(poisson_model, type = \"response\"),\n    Factor_Seed = predict(poisson_model_factor, type = \"response\")\n  )\n\nplot_data &lt;- marchmadness |&gt; \n  select(seed, tourney_wins, Numeric_Seed, Factor_Seed) |&gt; \n  pivot_longer(cols = c(\"Numeric_Seed\",\"Factor_Seed\"), names_to = \"model\", values_to = \"predicted\")\n\nggplot(plot_data, aes(x = seed, y = predicted, color = model)) +\n  geom_point(aes(y = tourney_wins), alpha = 0.3, color = \"black\") +\n  geom_line(stat = \"smooth\", method = \"loess\", se = FALSE, linewidth = 1.2) +\n  labs(title = \"Predicted Tournament Wins by Seed\",\n       x = \"Seed\",\n       y = \"Predicted Wins\",\n       color = \"Model\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nHowever, is we wanted to formally evaluate which is the better approach we could use likelihood-based model selection tools.\n\nglance(poisson_model)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         3439.    2083 -2117. 4239. 4250.    1610.        2082  2084\n\nglance(poisson_model_factor)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         3439.    2083 -2080. 4191. 4281.    1535.        2068  2084\n\n\nBased on lower residual deviance, higher log-likelihood, and a lower AIC, the model that treats seed as a factor fits the data better. This would suggest that the relationship between tournament seed and number of wins is not linear, and would support using an approach that does not assume a constant effect per unit change in seed.\n\n\n6. Discussion\nThis analysis examined the relationship between a team’s tournament seed and its performance in the NCAA Division I Women’s Basketball Tournament. The results suggest that:\n\nSeed strongly predicts performance: Lower-numbered seeds (higher-ranked teams) tend to win more games on average. The correlation between seed and wins was statistically significant, with higher seeds associated with fewer wins.\nPoisson regression supports seeding as a predictor: The Poisson regression model confirmed that seed is a significant predictor of tournament wins, as expected for a count variable like wins.\nModel assumptions are key: Treating seed as a numeric variable assumes a linear effect across all seed values, which oversimplifies the relationship with the outcome. Ensuring that explanatory variables are approapriately coded is key. In this case, the influence of seeds could be described as slightly non-linear, which opens the door to discussion over model selection.\nThere is a lot of variation around the prediction: While seeding generally reflects team strength, upsets and unexpected performances do occur, showing that other factors also influence tournament outcomes.\n\nSeeding is an important predictor of success, but clearly other factors influence the results. It sets expectations, but unexpected performances still shape March Madness."
  },
  {
    "objectID": "website_files/description_pages/marchmadness.html#attribution",
    "href": "website_files/description_pages/marchmadness.html#attribution",
    "title": "Women’s March Madness",
    "section": "Attribution",
    "text": "Attribution\nData sourced from FiveThirtyEight’s NCAA Women’s Basketball Tournament dataset, available under a Creative Commons Attribution 4.0 International License. Original dataset: FiveThirtyEight GitHub Repository. Story: Louisiana Tech Was the UConn of the ’80s."
  },
  {
    "objectID": "website_files/datasets.html",
    "href": "website_files/datasets.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Women’s March Madness\n\n\nDescription: This data set tracks every NCAA Division I Women’s Basketball Tournament appearance since 1982 up until 2018. It includes team seeds, results, bid types, season and conference records, and regional placements. Useful for analyzing team success, seeding impact, conference strength, and historical trends in women’s college basketball over four decades.\n\nMore Details\n\n\n\n\nWildfire\n\n\nDescription: This data set on Canadian wildfires includes data on fire size, cause, location, detection method, response, and weather. Collected from official sources, it supports wildfire risk assessment and response. It also highlights social and geographic disparities, emphasizing impacts on remote and underserved communities facing climate-related and infrastructure challenges.\n\nMore Details\n\n\n\n\nHow Couples Meet and Stay Together\n\n\nDescription: This data set contains information from a 2022 survey of people across the U.S. to understand how couples meet and stay together. It focuses on how relationships were influenced by the COVID-19 pandemic and offers insight at modern relationships, including changes in dating habits and how couples adapted during a challenging time.\n\nMore Details\n\n\n\n\nIndigenous Businesses\n\n\nDescription: XXX\n\nMore Details\n\n\n\n\nGender Assessment\n\n\nDescription: XXX\n\nMore Details\n\n\n\n\nGlobal Rights\n\n\nDescription: XXX\n\nMore Details"
  },
  {
    "objectID": "template/template.html",
    "href": "template/template.html",
    "title": "Diverse Data Hub Template",
    "section": "",
    "text": "Provide background information and context about the dataset. Think about answering the following questions:\n\nWhere does the data come from?\nWhy was it collected?\nWhy is the topic of the data socially relevant in the context of equity, diversity and inclusion?\n\n\n\n\n\n\nClearly define the problem or question being addressed by this analysis. What is the goal? What data science problem are you trying to solve or understand with this dataset?\n\n\n\nDescribe the approach taken to address the objective. This could include:\n\nData processing and cleaning steps\nExploratory Data Analysis (EDA)\nModels used\nStatistical tests\n\nInclude relevant code snippets and visualizations where necessary.\n\n\n\nSummarize the key findings, insights, and interpretations from the analysis. What did the data reveal? Were there any unexpected results or trends? How do these results relate to the original objective? In what ways do the findings from this analysis connect to real-world challenges?\n\n\n\n\n\nOriginal Data Source: [Link to the dataset or description of its origin]\n\nLicense: [Dataset license, e.g., “CC BY 4.0”]\n\nCitation: [If applicable, how to cite the data source or paper]\n\nReferences: [Links to or descriptions of key methods, algorithms, or resources used]\n\nAcknowledgements: [Contributors, collaborators, or any support received]"
  },
  {
    "objectID": "template/template.html#about-the-data",
    "href": "template/template.html#about-the-data",
    "title": "Diverse Data Hub Template",
    "section": "",
    "text": "Provide background information and context about the dataset. Think about answering the following questions:\n\nWhere does the data come from?\nWhy was it collected?\nWhy is the topic of the data socially relevant in the context of equity, diversity and inclusion?"
  },
  {
    "objectID": "template/template.html#case-study",
    "href": "template/template.html#case-study",
    "title": "Diverse Data Hub Template",
    "section": "",
    "text": "Clearly define the problem or question being addressed by this analysis. What is the goal? What data science problem are you trying to solve or understand with this dataset?\n\n\n\nDescribe the approach taken to address the objective. This could include:\n\nData processing and cleaning steps\nExploratory Data Analysis (EDA)\nModels used\nStatistical tests\n\nInclude relevant code snippets and visualizations where necessary.\n\n\n\nSummarize the key findings, insights, and interpretations from the analysis. What did the data reveal? Were there any unexpected results or trends? How do these results relate to the original objective? In what ways do the findings from this analysis connect to real-world challenges?"
  },
  {
    "objectID": "template/template.html#attribution",
    "href": "template/template.html#attribution",
    "title": "Diverse Data Hub Template",
    "section": "",
    "text": "Original Data Source: [Link to the dataset or description of its origin]\n\nLicense: [Dataset license, e.g., “CC BY 4.0”]\n\nCitation: [If applicable, how to cite the data source or paper]\n\nReferences: [Links to or descriptions of key methods, algorithms, or resources used]\n\nAcknowledgements: [Contributors, collaborators, or any support received]"
  },
  {
    "objectID": "scripts/march_madness_clean.html",
    "href": "scripts/march_madness_clean.html",
    "title": "Clean up for womens-march-madness.csv",
    "section": "",
    "text": "Load the necessary libraries for the clean-up, as well as the provided dataset\n\nimport pandas as pd\nimport re\nimport numpy as np\n\n\ndata = pd.read_csv(\"../data/raw/womens-march-madness/womens-march-madness.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nYear\nSchool\nSeed\nConference\nConf. W\nConf. L\nConf. %\nConf. place\nReg. W\nReg. L\nReg. %\nHow qual\n1st game at home?\nTourney W\nTourney L\nTourney finish\nFull W\nFull L\nFull %\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n79.3\nat-large\nY\n1\n1\nRSF\n24\n7\n77.4\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n85.7\nat-large\nN\n0\n1\n1st\n24\n5\n82.8\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n92.3\nat-large\nY\n4\n1\nN2nd\n28\n3\n90.3\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n64.5\nat-large\nN\n0\n1\n1st\n20\n12\n62.5\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n81.3\nauto\nY\n2\n1\nRF\n28\n7\n80"
  },
  {
    "objectID": "scripts/march_madness_clean.html#loading-csv",
    "href": "scripts/march_madness_clean.html#loading-csv",
    "title": "Clean up for womens-march-madness.csv",
    "section": "",
    "text": "Load the necessary libraries for the clean-up, as well as the provided dataset\n\nimport pandas as pd\nimport re\nimport numpy as np\n\n\ndata = pd.read_csv(\"../data/raw/womens-march-madness/womens-march-madness.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nYear\nSchool\nSeed\nConference\nConf. W\nConf. L\nConf. %\nConf. place\nReg. W\nReg. L\nReg. %\nHow qual\n1st game at home?\nTourney W\nTourney L\nTourney finish\nFull W\nFull L\nFull %\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n79.3\nat-large\nY\n1\n1\nRSF\n24\n7\n77.4\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n85.7\nat-large\nN\n0\n1\n1st\n24\n5\n82.8\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n92.3\nat-large\nY\n4\n1\nN2nd\n28\n3\n90.3\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n64.5\nat-large\nN\n0\n1\n1st\n20\n12\n62.5\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n81.3\nauto\nY\n2\n1\nRF\n28\n7\n80"
  },
  {
    "objectID": "scripts/march_madness_clean.html#renaming-columns",
    "href": "scripts/march_madness_clean.html#renaming-columns",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Renaming columns",
    "text": "Renaming columns\nChanging the column names to a more interpretable version:\n\ncolumn_names = {\n    'Year' : 'year',\n    'School' : 'school',\n    'Seed' : 'seed',\n    'Conference' : 'conference',\n    'Conf. W' : 'conf_wins',\n    'Conf. L' : 'conf_losses',\n    'Conf. %' : 'conf_wins_pct',\n    'Conf. place' : 'conf_place',\n    'Reg. W' : 'reg_wins',\n    'Reg. L' : 'reg_losses',\n    'Reg. %' : 'reg_wins_pct',\n    'How qual' : 'bid',\n    '1st game at home?' : 'first_game_at_home',\n    'Tourney W' : 'tourney_wins',\n    'Tourney L' : 'tourney_losses',\n    'Tourney finish' : 'tourney_finish',\n    'Full W' : 'total_wins',\n    'Full L' : 'total_losses',\n    'Full %' : 'total_wins_pct'\n}\ndata = data.rename(columns = column_names)\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_place\nreg_wins\nreg_losses\nreg_wins_pct\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n79.3\nat-large\nY\n1\n1\nRSF\n24\n7\n77.4\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n85.7\nat-large\nN\n0\n1\n1st\n24\n5\n82.8\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n92.3\nat-large\nY\n4\n1\nN2nd\n28\n3\n90.3\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n64.5\nat-large\nN\n0\n1\n1st\n20\n12\n62.5\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n81.3\nauto\nY\n2\n1\nRF\n28\n7\n80"
  },
  {
    "objectID": "scripts/march_madness_clean.html#column-analysis-and-reformatting",
    "href": "scripts/march_madness_clean.html#column-analysis-and-reformatting",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Column Analysis and Reformatting",
    "text": "Column Analysis and Reformatting\nAnalyzing and replacing the contents of the ‘Conf. place’ : ‘conf_place’ column:\n\ndata['conf_place'].unique()\n\narray(['-', '4th', '1st', '2nd', '3rd', 'T1st W', '3rd E', '2nd E',\n       'T2nd', '1st E', 'T2nd W', 'T1st E', 'T1st', 'T1st N', 'T3rd',\n       '1st W', '2nd W', '1st S', '2nd S', 'T4th', 'T2nd E', 'T6th',\n       '5th', '6th', 'T5th', 'T8th', 'T7th', '7th', '1st-B', '1st-W',\n       '2nd-E', '2nd-6', '1st-E', '1st-R', 'T2nd-W', '1st-6', 'T1st-B',\n       'T1st-W', '1st-P', '1st-M', 'T1st-M', '2nd-A', '1st-A', '1st-N',\n       '2nd-7', 'T3rd-M', 'T2nd-6', '1st-7', 'T2nd-P', '2nd-N', '2nd-W',\n       '8th', 'T1st-A', '2nd-M', '3rd-W', '4th-N', '9th', 'T1st-E',\n       '10th', 'T9th', '1st Div.', '3rd Div', 'T3rd Div.'], dtype=object)\n\n\n\nNumerical Places:\n\n‘1st’, ‘2nd’, ‘3rd’, etc. — clearly ranked within the conference.\n\nTied Places:\n\n‘T1st’, ‘T2nd’, etc. — team tied for that position.\n‘T1st-W’, ‘T2nd-E’, etc. — tied for a position within a division (e.g., West, East).\n\nDivisions within Conferences:\n\n‘1st W’, ‘2nd E’, ‘3rd-W’, etc. — first, second, or third place in a regional division (West, East, etc.).\n\nAmbiguous Codes:\n\n‘1st-6’, ‘T2nd-6’, ‘2nd-7’ — unknown for divisions (e.g., “Group 6” or region 6).\n‘1st-B’, ‘1st-R’, ‘1st-P’, ‘1st-M’, etc. — probably shorthand for colored or named divisions (e.g., Blue, Red, Pacific, Mountain).\n‘1st Div.’, ‘3rd Div’, ‘T3rd Div.’ — older way of denoting division standing.\n\n‘-’ — missing or not applicable (e.g., for Independent schools not in a conference).\n\nFunctions to replace ‘conf_place’ with two columns ‘conf_rank’ and ‘division’\n\ndef extract_conf_rank(conf_place):\n    if pd.isna(conf_place) or conf_place == '-':\n        return np.nan\n    # Match patterns like '1st', 'T2nd', '3rd-W', 'T1st-N', etc.\n    match = re.search(r'(\\d+)(st|nd|rd|th)', conf_place)\n    if match:\n        return int(match.group(1))\n    return np.nan\n\ndef extract_division(conf_place):\n    if pd.isna(conf_place) or conf_place == '-':\n        return np.nan\n    # Look for division info after rank (like 'W', 'E', '6', etc.)\n    match = re.search(r'(?:\\d+(?:st|nd|rd|th)[\\s-]?)([A-Za-z0-9]+)?', conf_place)\n    if match:\n        return match.group(1)\n    return np.nan\n\n\ndata['conf_rank'] = data['conf_place'].apply(extract_conf_rank)\ndata['division'] = data['conf_place'].apply(extract_division)\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_place\nreg_wins\nreg_losses\n...\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\nconf_rank\ndivision\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n...\nat-large\nY\n1\n1\nRSF\n24\n7\n77.4\nNaN\nNaN\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n...\nat-large\nN\n0\n1\n1st\n24\n5\n82.8\nNaN\nNaN\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n...\nat-large\nY\n4\n1\nN2nd\n28\n3\n90.3\nNaN\nNaN\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n...\nat-large\nN\n0\n1\n1st\n20\n12\n62.5\n4.0\nNone\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n...\nauto\nY\n2\n1\nRF\n28\n7\n80\nNaN\nNaN\n\n\n\n\n5 rows × 21 columns\n\n\n\nAnalyzing and replacing the contents of the ‘Tourney finish’ : ‘tourney_finish’ column:\nAccording to the documentation:\nThe round of the final game for each team. OR=opening-round loss (1983 only); 1st=first-round loss; 2nd=second-round loss; RSF=loss in the Sweet 16; RF=loss in the Elite Eight; NSF=loss in the national semifinals; N2nd=national runner-up; Champ=national champions.\nWe’ll recode the content of the column to more interpretable names.\n\ndata['tourney_finish'].unique()\n\narray(['RSF', '1st', 'N2nd', 'RF', 'Champ', 'NSF', 'OR', '2nd'],\n      dtype=object)\n\n\n\nfinish_map = {\n    'OR': 'opening_round_loss',\n    '1st': 'first_round_loss',\n    '2nd': 'second_round_loss',\n    'RSF': 'top_16_loss',\n    'RF': 'top_8_loss',\n    'NSF': 'top_4_loss',\n    'N2nd': 'top_2_loss',\n    'Champ': 'champ'\n}\n\ndata['tourney_finish'] = data['tourney_finish'].replace(finish_map)\n\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_place\nreg_wins\nreg_losses\n...\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\nconf_rank\ndivision\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n...\nat-large\nY\n1\n1\ntop_16_loss\n24\n7\n77.4\nNaN\nNaN\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n...\nat-large\nN\n0\n1\nfirst_round_loss\n24\n5\n82.8\nNaN\nNaN\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n...\nat-large\nY\n4\n1\ntop_2_loss\n28\n3\n90.3\nNaN\nNaN\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n...\nat-large\nN\n0\n1\nfirst_round_loss\n20\n12\n62.5\n4.0\nNone\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n...\nauto\nY\n2\n1\ntop_8_loss\n28\n7\n80\nNaN\nNaN\n\n\n\n\n5 rows × 21 columns\n\n\n\nWe’re going to make this column an ordered categorical.\n\nfinish_order = [\n    'opening_round_loss',\n    'first_round_loss',\n    'second_round_loss',\n    'top_16_loss',\n    'top_8_loss',\n    'top_4_loss',\n    'top_2_loss',\n    'champ'\n]\n\ndata['tourney_finish'] = pd.Categorical(\n    data['tourney_finish'], \n    categories=finish_order, \n    ordered=True\n)\n\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_place\nreg_wins\nreg_losses\n...\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\nconf_rank\ndivision\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\n-\n-\n-\n-\n23\n6\n...\nat-large\nY\n1\n1\ntop_16_loss\n24\n7\n77.4\nNaN\nNaN\n\n\n1\n1982\nAuburn\n7\nSoutheastern\n-\n-\n-\n-\n24\n4\n...\nat-large\nN\n0\n1\nfirst_round_loss\n24\n5\n82.8\nNaN\nNaN\n\n\n2\n1982\nCheyney\n2\nIndependent\n-\n-\n-\n-\n24\n2\n...\nat-large\nY\n4\n1\ntop_2_loss\n28\n3\n90.3\nNaN\nNaN\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6\n3\n66.7\n4th\n20\n11\n...\nat-large\nN\n0\n1\nfirst_round_loss\n20\n12\n62.5\n4.0\nNone\n\n\n4\n1982\nDrake\n4\nMissouri Valley\n-\n-\n-\n-\n26\n6\n...\nauto\nY\n2\n1\ntop_8_loss\n28\n7\n80\nNaN\nNaN\n\n\n\n\n5 rows × 21 columns\n\n\n\nAnalyzing and replacing the contents of the ‘Seed’ : ‘seed’ column:\n\ndata.loc[data['seed'] == '(OR)', 'seed'] = '0'"
  },
  {
    "objectID": "scripts/march_madness_clean.html#changing-datatypes",
    "href": "scripts/march_madness_clean.html#changing-datatypes",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Changing datatypes:",
    "text": "Changing datatypes:\n\ndata.replace(\"-\", np.nan, inplace=True)\n\ndata['seed'] = data['seed'].astype('int')\ndata['conf_wins'] = data['conf_wins'].astype('float')\ndata['conf_losses'] = data['conf_losses'].astype('float')\ndata['conf_wins_pct'] = data['conf_wins_pct'].astype('float')\ndata['total_wins_pct'] = data['total_wins_pct'].str.replace('\\\\', '')\ndata['first_game_at_home'] = data['first_game_at_home'].str.replace('^', '')\ndata['total_wins_pct'] = data['total_wins_pct'].astype('float')\n\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_place\nreg_wins\nreg_losses\n...\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\nconf_rank\ndivision\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\nNaN\nNaN\nNaN\nNaN\n23\n6\n...\nat-large\nY\n1\n1\ntop_16_loss\n24\n7\n77.4\nNaN\nNaN\n\n\n1\n1982\nAuburn\n7\nSoutheastern\nNaN\nNaN\nNaN\nNaN\n24\n4\n...\nat-large\nN\n0\n1\nfirst_round_loss\n24\n5\n82.8\nNaN\nNaN\n\n\n2\n1982\nCheyney\n2\nIndependent\nNaN\nNaN\nNaN\nNaN\n24\n2\n...\nat-large\nY\n4\n1\ntop_2_loss\n28\n3\n90.3\nNaN\nNaN\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6.0\n3.0\n66.7\n4th\n20\n11\n...\nat-large\nN\n0\n1\nfirst_round_loss\n20\n12\n62.5\n4.0\nNone\n\n\n4\n1982\nDrake\n4\nMissouri Valley\nNaN\nNaN\nNaN\nNaN\n26\n6\n...\nauto\nY\n2\n1\ntop_8_loss\n28\n7\n80.0\nNaN\nNaN\n\n\n\n\n5 rows × 21 columns"
  },
  {
    "objectID": "scripts/march_madness_clean.html#nan-standardization",
    "href": "scripts/march_madness_clean.html#nan-standardization",
    "title": "Clean up for womens-march-madness.csv",
    "section": "NaN Standardization",
    "text": "NaN Standardization\n\ndata.replace(to_replace=[pd.NA, \"nan\", \"NaN\", \"None\", None], value=np.nan, inplace=True)"
  },
  {
    "objectID": "scripts/march_madness_clean.html#results-review",
    "href": "scripts/march_madness_clean.html#results-review",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Results Review",
    "text": "Results Review\n\nfor column in data.columns:\n    print(f\"Column: {column}\")\n    print(f\"Data type: {data[column].dtype}\")\n    print(f\"Unique values: {data[column].unique()}\\n\")\n\nColumn: year\nData type: int64\nUnique values: [1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995\n 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009\n 2010 2011 2012 2013 2014 2015 2016 2017 2018]\n\nColumn: school\nData type: object\nUnique values: ['Arizona St.' 'Auburn' 'Cheyney' 'Clemson' 'Drake' 'East Carolina'\n 'Georgia' 'Howard' 'Illinois' 'Jackson St.' 'Kansas St.' 'Kent St.'\n 'Kentucky' 'Long Beach St.' 'Louisiana Tech' 'Maryland' 'Memphis'\n 'Missouri' 'NC State' 'Northwestern' 'Ohio St.' 'Old Dominion' 'Ole Miss'\n 'Oregon' 'Penn St.' \"Saint Peter's\" 'SFA' 'South Carolina'\n 'Southern California' 'Stanford' 'Tennessee' 'Tennessee Tech'\n 'Central Mich.' 'Dartmouth' 'Florida St.' 'Illinois St.' 'Indiana'\n 'La Salle' 'La.-Monroe' 'Louisville' 'Middle Tenn.' 'Monmouth' 'Montana'\n 'North Carolina' 'Oregon St.' 'South Carolina St.' \"St. John's (NY)\"\n 'Texas' 'UCLA' 'Utah' 'Alabama' 'BYU' 'LSU' 'San Diego St.' 'Texas Tech'\n 'UNLV' 'Virginia' 'Holy Cross' 'Idaho' \"Saint Joseph's\" 'Southern Miss.'\n 'Syracuse' 'Washington' 'Western Ky.' 'Western Mich.' 'Arkansas' 'Iowa'\n 'James Madison' 'North Texas' 'Ohio' 'Oklahoma' 'Providence' 'Rutgers'\n 'Southern Ill.' 'Vanderbilt' 'Villanova' 'Bowling Green' 'Duke'\n 'Eastern Wash.' 'Kansas' 'Manhattan' 'New Mexico St.' 'New Orleans'\n 'Northwestern St.' 'South Alabama' 'Colorado' 'Eastern Ill.' 'Fairfield'\n 'Houston' 'Nebraska' 'Wake Forest' 'Cal St. Fullerton' 'Chattanooga'\n 'Cincinnati' 'Hawaii' 'Miami (FL)' 'Oklahoma St.' 'Purdue' 'Temple'\n 'UConn' 'West Virginia' 'Appalachian St.' 'California' 'DePaul'\n 'Michigan' 'Northern Ill.' 'Richmond' 'George Washington' 'Lamar'\n 'Michigan St.' 'Missouri St.' 'Toledo' 'Washington St.' 'Creighton'\n 'Notre Dame' 'Santa Clara' 'UC Santa Barbara' 'Vermont' 'Wisconsin'\n 'Florida' 'Ga. Southern' 'Georgetown' 'Georgia Tech' 'Montana St.'\n 'San Diego' 'Xavier' 'Boise St.' 'Brown' 'FIU' 'Fordham' 'Grambling'\n 'Green Bay' 'Loyola (MD)' 'Marquette' 'Minnesota' \"Mt. St. Mary's\"\n 'N.C. A&T' 'Portland' 'Radford' 'Seton Hall' 'SMU' 'Tennessee St.'\n 'Texas A&M' 'UAB' 'Virginia Tech' 'Florida A&M' 'Furman' 'Maine'\n 'San Francisco' 'Tulane' 'UC Irvine' 'Western Ill.' 'Austin Peay'\n 'Butler' 'Colorado St.' 'Harvard' 'Massachusetts' 'Rhode Island'\n 'St. Francis (PA)' 'UCF' 'Youngstown St.' 'Arizona' 'Detroit Mercy'\n 'Eastern Ky.' 'Iowa St.' 'Lehigh' 'Liberty' 'Marshall' 'Texas St.' 'Troy'\n 'New Mexico' 'Saint Francis (PA)' 'UNC Greensboro' 'Boston College'\n 'CSUN' 'Evansville' 'Mississippi St.' 'Northeastern' 'Oral Roberts'\n \"St. Mary's (CA)\" 'Alcorn St.' 'Campbell' 'Hampton' 'Pepperdine' 'Rice'\n 'Baylor' 'Delaware' 'Denver' 'Georgia St.' 'Idaho St.' 'Long Island'\n 'Milwaukee' 'Penn' 'Siena' 'TCU' 'Bucknell' 'Hartford' 'Norfolk St.'\n 'Oakland' 'Southern' 'Weber St.' 'Alabama St.' 'Boston University'\n 'Charlotte' 'Valparaiso' 'Colgate' 'Eastern Mich.' 'Lipscomb'\n 'Loyola Marymount' 'Marist' 'Canisius' 'Coppin St.' 'Stetson'\n 'UT Arlington' 'Western Carolina' 'Army' 'Fla. Atlantic'\n 'Northern Arizona' 'Sacred Heart' 'South Florida' 'Southeast Mo. St.'\n 'Tulsa' 'UC Riverside' 'Belmont' 'Delaware St.' 'Gonzaga' 'Louisiana'\n 'Pittsburgh' 'Prairie View' 'Robert Morris' 'UMBC' 'Asheville'\n 'Cleveland St.' 'Cornell' 'ETSU' 'Fresno St.' 'Miami (OH)' 'Murray St.'\n 'UTEP' 'UTSA' 'Wyoming' 'Ball St.' 'Drexel' 'NC A&T' 'South Dakota St.'\n 'VCU' 'Dayton' 'Little Rock' 'Portland St.' 'Princeton' 'UNI'\n 'Gardner-Webb' 'McNeese' 'Navy' 'Samford' 'UC Davis' 'UT Martin' 'Albany'\n 'FGCU' 'St. Bonaventure' 'Cal Poly' 'Quinnipiac' 'Wichita St.' 'Akron'\n 'North Dakota' 'South Dakota' 'Winthrop' 'Wright St.' 'American'\n 'Savannah St.' 'St. Francis Brooklyn' 'Army West Point' 'Buffalo'\n 'Central Arkansas' 'Duquesne' 'Iona' 'Jacksonville' 'UNC Asheville'\n 'Elon' 'Texas Southern' 'Mercer' 'Nicholls St.' 'Northern Colo.'\n 'Seattle']\n\nColumn: seed\nData type: int64\nUnique values: [ 4  7  2  5  6  8  1  3  0 10  9 12 11 16 14 15 13]\n\nColumn: conference\nData type: object\nUnique values: ['Western Collegiate' 'Southeastern' 'Independent' 'Atlantic Coast'\n 'Missouri Valley' 'Mid-Eastern' 'Big Ten' 'Southwestern' 'Big Eight'\n 'Mid-American' 'Metro' 'Metro Atlantic' 'Northern California'\n 'Ohio Valley' 'Ivy' 'East Coast' 'Southland' 'Cosmopolitan'\n 'Mountain West Athl.' 'Sun Belt' 'Northern Pacific' 'Atlantic 10'\n 'Big East' 'Southwest' 'High Country' 'Pacific Coast' 'Colonial'\n 'Pacific West' 'Western Athletic' 'Gulf Star' 'Pacific-10' 'Big West'\n 'American South' 'Southern' 'Big Sky' 'North Star' 'Patriot'\n 'Great Midwest' 'Midwestern' 'West Coast' 'North Atlantic'\n 'Mid-Continent' 'Trans America' 'Northeast' 'Big South' 'Conference USA'\n 'Trans-America' 'Big 12' 'America East' 'Horizon' 'Mountain West'\n 'Atlantic Sun' ' Mountain West' 'Summit' 'Pac-12' 'American Atletic'\n 'American Athletic' 'ASUN' 'Colonial Athletic' 'Western Atlantic'\n 'Atlantic-10' 'SWAC' 'Atlantic']\n\nColumn: conf_wins\nData type: float64\nUnique values: [nan  6. 11.  5.  9. 10.  4. 12.  7. 18. 16. 13. 14. 17.  8. 15.  3. 19.\n 20.]\n\nColumn: conf_losses\nData type: float64\nUnique values: [nan  3.  1.  2.  0.  5.  4.  6.  8.  7.  9. 11. 10. 13. 14. 12.]\n\nColumn: conf_wins_pct\nData type: float64\nUnique values: [  nan  66.7  85.7  84.6 100.   75.   83.3  64.3  91.7  50.   76.9  92.3\n  87.5  62.5  90.   88.9  92.9  70.   71.4  94.4  81.3  78.6  80.   77.8\n  44.4  42.9  57.1  55.6  61.1  93.8  68.8  86.7  72.2  60.   63.6  56.3\n  90.9  54.5  81.8  36.4  58.3  72.7  21.4  53.8  46.7  41.7  93.3  41.2\n  43.8  95.   84.2  94.1  38.9  55.   82.4  27.8  37.5  22.2  61.9  85.\n  33.3]\n\nColumn: conf_place\nData type: object\nUnique values: [nan '4th' '1st' '2nd' '3rd' 'T1st W' '3rd E' '2nd E' 'T2nd' '1st E'\n 'T2nd W' 'T1st E' 'T1st' 'T1st N' 'T3rd' '1st W' '2nd W' '1st S' '2nd S'\n 'T4th' 'T2nd E' 'T6th' '5th' '6th' 'T5th' 'T8th' 'T7th' '7th' '1st-B'\n '1st-W' '2nd-E' '2nd-6' '1st-E' '1st-R' 'T2nd-W' '1st-6' 'T1st-B'\n 'T1st-W' '1st-P' '1st-M' 'T1st-M' '2nd-A' '1st-A' '1st-N' '2nd-7'\n 'T3rd-M' 'T2nd-6' '1st-7' 'T2nd-P' '2nd-N' '2nd-W' '8th' 'T1st-A' '2nd-M'\n '3rd-W' '4th-N' '9th' 'T1st-E' '10th' 'T9th' '1st Div.' '3rd Div'\n 'T3rd Div.']\n\nColumn: reg_wins\nData type: int64\nUnique values: [23 24 20 26 19 21 14 28 17 22 30 25 27 15 18 16 29 12 33 31 13 32 34 10]\n\nColumn: reg_losses\nData type: int64\nUnique values: [ 6  4  2 11  7  8 10  5 13  1  3  9 12 14 15  0 16 17 18]\n\nColumn: reg_wins_pct\nData type: float64\nUnique values: [ 79.3  85.7  92.3  64.5  81.3  73.1  72.4  58.3  80.   82.8  56.7  75.9\n  81.5  96.8  78.6  86.2  74.2  82.1  75.   76.   80.8  87.1  83.3  65.2\n  87.   67.9  66.7  76.7  71.4  92.9  72.   69.   64.3  85.2  57.1  96.4\n  50.   89.7  83.9  69.6  92.6  93.3  73.3  93.1  84.6  88.   51.6  89.3\n  63.3  93.8  70.4  77.8  96.6  90.   67.7  60.   70.   96.3  96.7  87.5\n  58.6  76.5  65.5 100.   90.6  62.1  86.7  61.3  74.1  80.6  60.9  71.9\n  60.7  68.8  78.8  71.   77.4  59.4  46.7  88.9  62.5  61.5  59.3  76.9\n  63.   41.4  69.2  88.5  84.4  51.7  93.5  90.9  75.8  53.6  81.8  69.7\n  65.4  93.9  65.6  90.3  53.3  63.6  58.1  68.6  96.9  55.2  54.8  43.3\n  78.1  87.9  43.8  72.7  55.6  46.9  84.8  56.3  97.   53.1  45.5  51.5\n  60.6  88.2  57.6  52.9  82.4  45.2  64.7  91.2  97.1  67.6  79.4  55.9\n  86.4  94.1]\n\nColumn: bid\nData type: object\nUnique values: ['at-large' 'auto']\n\nColumn: first_game_at_home\nData type: object\nUnique values: ['Y' 'N']\n\nColumn: tourney_wins\nData type: int64\nUnique values: [1 0 4 2 5 3 6]\n\nColumn: tourney_losses\nData type: int64\nUnique values: [1 0]\n\nColumn: tourney_finish\nData type: category\nUnique values: ['top_16_loss', 'first_round_loss', 'top_2_loss', 'top_8_loss', 'champ', 'top_4_loss', 'opening_round_loss', 'second_round_loss']\nCategories (8, object): ['opening_round_loss' &lt; 'first_round_loss' &lt; 'second_round_loss' &lt; 'top_16_loss' &lt; 'top_8_loss' &lt; 'top_4_loss' &lt; 'top_2_loss' &lt; 'champ']\n\nColumn: total_wins\nData type: int64\nUnique values: [24 28 20 19 21 14 26 17 23 35 25 22 27 15 18 16 31 29 30 32 34 33 12 39\n 36 37 13 40 38]\n\nColumn: total_losses\nData type: int64\nUnique values: [ 7  5  3 12  8  9 11  6 14  1  4 10 13  2 15 16  0 17 18 53 19]\n\nColumn: total_wins_pct\nData type: float64\nUnique values: [ 77.4  82.8  90.3  62.5  80.   70.4  70.   56.   77.8  81.3  54.8  75.\n  79.3  97.2  78.1  83.9  72.7  72.4  73.1  78.6  84.4  83.3  73.3  84.6\n  68.8  64.5  76.7  69.   90.   69.2  79.4  66.7  63.3  80.6  82.1  55.2\n  93.9  50.   86.7  82.9  78.8  72.   68.   93.8  75.8  90.9  62.1  75.9\n  71.9  85.2  51.5  65.5  61.3  87.9  69.7  91.4  67.9  85.3  93.3  71.\n  65.6  91.2  90.6  84.8  58.1  92.9  87.5  81.8  56.7  89.7  86.1  86.2\n  70.6 100.   88.9  60.   87.1  60.6  91.7  71.4  58.3  82.4  64.3  67.7\n  93.5  94.1  58.6  67.6  74.2  76.5  85.7  88.2  94.6  97.   57.6  56.3\n  45.2  96.7  77.1  61.8  59.3  57.1  96.6  88.6  40.   94.3  60.7  63.6\n  91.9  89.2  73.5  74.3  74.1  51.7  89.5  81.6  94.4  74.4  97.1  63.\n  79.6  48.3  78.9  51.6  97.3  89.3  68.4  65.7  68.6  81.1  81.5  59.4\n  58.8  86.8  97.4  53.1  36.9  41.9  48.4  86.5  42.4  53.6  45.5  83.8\n  48.5  64.7  72.2  55.9  94.7  62.9  78.4  44.1  87.2  69.4  73.   71.1\n  54.5  79.5  51.4  76.3  43.8  92.3  96.9  61.1  70.3  62.2  63.9  84.2\n  54.3  94.9  92.1]\n\nColumn: conf_rank\nData type: float64\nUnique values: [nan  4.  1.  2.  3.  6.  5.  8.  7.  9. 10.]\n\nColumn: division\nData type: object\nUnique values: [nan 'W' 'E' 'N' 'S' 'B' '6' 'R' 'P' 'M' 'A' '7' 'Div']"
  },
  {
    "objectID": "scripts/march_madness_clean.html#final-reorganization-of-columns",
    "href": "scripts/march_madness_clean.html#final-reorganization-of-columns",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Final Reorganization of Columns",
    "text": "Final Reorganization of Columns\n\ndata.columns\n\nIndex(['year', 'school', 'seed', 'conference', 'conf_wins', 'conf_losses',\n       'conf_wins_pct', 'conf_place', 'reg_wins', 'reg_losses', 'reg_wins_pct',\n       'bid', 'first_game_at_home', 'tourney_wins', 'tourney_losses',\n       'tourney_finish', 'total_wins', 'total_losses', 'total_wins_pct',\n       'conf_rank', 'division'],\n      dtype='object')\n\n\n\ndata = data[['year', 'school', 'seed', 'conference', 'conf_wins', 'conf_losses',\n       'conf_wins_pct', 'conf_rank', 'division', 'reg_wins', 'reg_losses', 'reg_wins_pct',\n       'bid', 'first_game_at_home', 'tourney_wins', 'tourney_losses',\n       'tourney_finish', 'total_wins', 'total_losses', 'total_wins_pct'\n       ]]\n\ndata.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_rank\ndivision\nreg_wins\nreg_losses\nreg_wins_pct\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\nNaN\nNaN\nNaN\nNaN\nNaN\n23\n6\n79.3\nat-large\nY\n1\n1\ntop_16_loss\n24\n7\n77.4\n\n\n1\n1982\nAuburn\n7\nSoutheastern\nNaN\nNaN\nNaN\nNaN\nNaN\n24\n4\n85.7\nat-large\nN\n0\n1\nfirst_round_loss\n24\n5\n82.8\n\n\n2\n1982\nCheyney\n2\nIndependent\nNaN\nNaN\nNaN\nNaN\nNaN\n24\n2\n92.3\nat-large\nY\n4\n1\ntop_2_loss\n28\n3\n90.3\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6.0\n3.0\n66.7\n4.0\nNaN\n20\n11\n64.5\nat-large\nN\n0\n1\nfirst_round_loss\n20\n12\n62.5\n\n\n4\n1982\nDrake\n4\nMissouri Valley\nNaN\nNaN\nNaN\nNaN\nNaN\n26\n6\n81.3\nauto\nY\n2\n1\ntop_8_loss\n28\n7\n80.0"
  },
  {
    "objectID": "scripts/march_madness_clean.html#saving-csv",
    "href": "scripts/march_madness_clean.html#saving-csv",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Saving CSV",
    "text": "Saving CSV\n\ndata.to_csv('../data/clean/womensmarchmadness.csv', index=False)"
  },
  {
    "objectID": "scripts/march_madness_clean.html#validating",
    "href": "scripts/march_madness_clean.html#validating",
    "title": "Clean up for womens-march-madness.csv",
    "section": "Validating",
    "text": "Validating\n\nclean = pd.read_csv(\"../data/clean/womensmarchmadness.csv\")\n\nclean.head()\n\n\n\n\n\n\n\n\nyear\nschool\nseed\nconference\nconf_wins\nconf_losses\nconf_wins_pct\nconf_rank\ndivision\nreg_wins\nreg_losses\nreg_wins_pct\nbid\nfirst_game_at_home\ntourney_wins\ntourney_losses\ntourney_finish\ntotal_wins\ntotal_losses\ntotal_wins_pct\n\n\n\n\n0\n1982\nArizona St.\n4\nWestern Collegiate\nNaN\nNaN\nNaN\nNaN\nNaN\n23\n6\n79.3\nat-large\nY\n1\n1\ntop_16_loss\n24\n7\n77.4\n\n\n1\n1982\nAuburn\n7\nSoutheastern\nNaN\nNaN\nNaN\nNaN\nNaN\n24\n4\n85.7\nat-large\nN\n0\n1\nfirst_round_loss\n24\n5\n82.8\n\n\n2\n1982\nCheyney\n2\nIndependent\nNaN\nNaN\nNaN\nNaN\nNaN\n24\n2\n92.3\nat-large\nY\n4\n1\ntop_2_loss\n28\n3\n90.3\n\n\n3\n1982\nClemson\n5\nAtlantic Coast\n6.0\n3.0\n66.7\n4.0\nNaN\n20\n11\n64.5\nat-large\nN\n0\n1\nfirst_round_loss\n20\n12\n62.5\n\n\n4\n1982\nDrake\n4\nMissouri Valley\nNaN\nNaN\nNaN\nNaN\nNaN\n26\n6\n81.3\nauto\nY\n2\n1\ntop_8_loss\n28\n7\n80.0\n\n\n\n\n\n\n\n\nclean.shape\n\n(2092, 20)"
  },
  {
    "objectID": "scripts/HCMST_clean.html",
    "href": "scripts/HCMST_clean.html",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "",
    "text": "Load the necessary libraries for the clean-up, as well as the provided dataset\n\nimport pandas as pd\n\n\ndf = pd.read_csv(\"../data/raw/how-couples-meet-and-stay-together/HCMST_2017-2022.csv\")\ndf.head()\n\n\n\n\n\n\n\n\ncaseid_new\nw3_Weight\nw3_Weight_LGB\nw3_combo_weight\nw3_attrition_adj_weight\nw2_weight_genpop\nw2_weight_LGB\nw2_combo_weight\nw2_attrition_adj_weights\nw1_weight_combo\n...\np20_pppa1634\np20_pppa1902\np20_pppa1903\np20_pppa1904\np20_ppp22001\np20_pppa1905\np20_pppa1648\np20_ppp20072\np20_ppp20071\np20_ppp2date2020\n\n\n\n\n0\n53001\n0.4422\nNaN\n0.495308\n0.400185\n0.3856\nNaN\n0.437670\n0.380351\n0.426861\n...\n2.0\n0.0\n1.0\n0.0\n0.0\n0.0\n13.0\n6.0\nNaN\n20210506.0\n\n\n1\n71609\n0.8284\nNaN\n0.927891\n0.879258\n0.9196\nNaN\n1.043778\n0.953948\n1.295508\n...\n2.0\n0.0\n1.0\n0.0\n0.0\n0.0\n2.0\n5.0\n1.0\n20201118.0\n\n\n2\n106983\n0.8255\nNaN\n0.924643\n0.706467\n0.7748\nNaN\n0.879425\n0.724682\n1.126573\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n4.0\n2.0\n20210429.0\n\n\n3\n121759\nNaN\nNaN\nNaN\nNaN\n0.9177\nNaN\n1.041622\n0.793093\n0.933440\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n11.0\n2.0\n1.0\n20210507.0\n\n\n4\n158083\n0.8810\nNaN\n0.986809\n0.655467\n0.8697\nNaN\n0.987140\n0.735473\n0.931291\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n13.0\n6.0\nNaN\n20210602.0\n\n\n\n\n5 rows × 725 columns\n\n\n\n\ndf.shape\n\n(3510, 725)"
  },
  {
    "objectID": "scripts/HCMST_clean.html#loading-csv",
    "href": "scripts/HCMST_clean.html#loading-csv",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "",
    "text": "Load the necessary libraries for the clean-up, as well as the provided dataset\n\nimport pandas as pd\n\n\ndf = pd.read_csv(\"../data/raw/how-couples-meet-and-stay-together/HCMST_2017-2022.csv\")\ndf.head()\n\n\n\n\n\n\n\n\ncaseid_new\nw3_Weight\nw3_Weight_LGB\nw3_combo_weight\nw3_attrition_adj_weight\nw2_weight_genpop\nw2_weight_LGB\nw2_combo_weight\nw2_attrition_adj_weights\nw1_weight_combo\n...\np20_pppa1634\np20_pppa1902\np20_pppa1903\np20_pppa1904\np20_ppp22001\np20_pppa1905\np20_pppa1648\np20_ppp20072\np20_ppp20071\np20_ppp2date2020\n\n\n\n\n0\n53001\n0.4422\nNaN\n0.495308\n0.400185\n0.3856\nNaN\n0.437670\n0.380351\n0.426861\n...\n2.0\n0.0\n1.0\n0.0\n0.0\n0.0\n13.0\n6.0\nNaN\n20210506.0\n\n\n1\n71609\n0.8284\nNaN\n0.927891\n0.879258\n0.9196\nNaN\n1.043778\n0.953948\n1.295508\n...\n2.0\n0.0\n1.0\n0.0\n0.0\n0.0\n2.0\n5.0\n1.0\n20201118.0\n\n\n2\n106983\n0.8255\nNaN\n0.924643\n0.706467\n0.7748\nNaN\n0.879425\n0.724682\n1.126573\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n4.0\n2.0\n20210429.0\n\n\n3\n121759\nNaN\nNaN\nNaN\nNaN\n0.9177\nNaN\n1.041622\n0.793093\n0.933440\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n11.0\n2.0\n1.0\n20210507.0\n\n\n4\n158083\n0.8810\nNaN\n0.986809\n0.655467\n0.8697\nNaN\n0.987140\n0.735473\n0.931291\n...\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n13.0\n6.0\nNaN\n20210602.0\n\n\n\n\n5 rows × 725 columns\n\n\n\n\ndf.shape\n\n(3510, 725)"
  },
  {
    "objectID": "scripts/HCMST_clean.html#full-list-of-variables",
    "href": "scripts/HCMST_clean.html#full-list-of-variables",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Full List of Variables",
    "text": "Full List of Variables\nThe next cell displays the full list of variables in the original data set. We are not going to use everything…\nWe’ll focus on variables of interest for specific inquiries.\nIn the following links, we can find the encoding of each variable.\nData source: https://data.stanford.edu/hcmst2017\nVariable List per year (Note w1 = 2017, w2 = 2020, w3 = 2022): https://stacks.stanford.edu/file/druid:tq903pj6286/HCMST%202017-%202022%20user%27s%20guide%20v2.3.pdf\nDetailed Info on variables: https://stacks.stanford.edu/file/druid:hg921sg6829/HCMST%202017%20to%202022%20v2.2%20codebook.pdf\n\n#df.columns.tolist()"
  },
  {
    "objectID": "scripts/HCMST_clean.html#variables-of-interest",
    "href": "scripts/HCMST_clean.html#variables-of-interest",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Variables of Interest",
    "text": "Variables of Interest\nThe following lists are not actually used in the rest of the notebook for data cleaning purposes.\nStill, they display the selected variables of interest (and how their names vary from year to year), so, we are leaving them in the notebook for documentation.\n\n# ppage = Age\n# ppeduc = Education (Highest Degree Received)\n# ppgender = Gender\n# ppethm =  Race / Ethnicity \n# ppincimp = Household Income\n# ppwork = Current Employment Status \n\nsubject_demographics_2017 = [\n    'w1_ppage', 'w1_ppeduc', 'w1_ppgender', 'w1_ppethm', 'w1_ppincimp', 'w1_ppwork'\n]\nsubject_demographics_2020 = [\n    'w2_ppage', 'w2_ppeduc', 'w2_ppgender', 'w2_ppethm', 'w2_ppincimp', 'w2_ppwork'\n]\nsubject_demographics_2022 = [\n    'w3_ppage', 'w3_ppeduc', 'w3_ppgender', 'w3_ppethm', 'w3_ppincimp', 'w3_ppwork'\n]\n\n\n# q4 = Partner Gender\n# q9 = Partner Age\n# q6b = Partner's Race\n# q10 = Partner's Education (Highest Degree Received)\n\npartner_demographics_2017 = [\n    'w1_q4', 'w1_q9', 'w1_q6b', 'w1_q10'\n]\npartner_demographics_2020 = [\n    'w2_Q4', 'w2_Q9', 'w2_Q6B', 'w2_Q10'\n]\npartner_demographics_2022 = [\n    'w3_Q4', 'w3_Q9', 'w3_Q6B', 'w3_Q10'\n]\n\n\n# same_sex_couple = same-sex couple\n# married = Married\n# q34/rel_qual_combo/rel_qual = Relationship quality 1 (Excellent) to 5 (Very Poor) - Potential Target\n\nrelationship_status_2017 = [\n    'w1_same_sex_couple', 'w1_married', 'w1_q34'\n]\nrelationship_status_2020 = [\n    'w2_same_sex_couple', 'w2_married', 'w2_rel_qual_combo'\n]\nrelationship_status_2022 = [\n    'w3_same_sex_couple', 'w3_married', 'w3_rel_qual'\n]\n\n\n# q21b - Year current relationship started\n# q21d - Year of marriage\n# q21e - Year relationship ended\n# relate/relationship duration = Duration of relationship in years\n\nrelationship_time_2017 = [\n    'w1_q21b_year', 'w1_q21d_year', 'w1_q21e_year', 'w1_relate_duration_in2017_years'\n]\nrelationship_time_2020 = [\n    'w2_q21b_year', 'w2_q21d_year', 'w2_q21e_year', 'w2_relationship_duration'\n]\nrelationship_time_2022 = [\n    'w3_Q21B_year', 'w3_Q21D_year', 'w3_Q21E_year', 'w3_relationship_duration_yrs'\n]\n\n\n# PPT01 = # of children in the household ages 0-1\n# PPT25 = # of children in the household ages 2-5\n# PPT612 = # of children in the household ages 6-12\n# PPT1317 = # of children in the household ages 13-17\n# PPT18OV = # of children in the household ages 18-Over\n\nchildren_info_2017 = [\n    'w1_PPT01', 'w1_PPT25', 'w1_PPT612', 'w1_PPT1317', 'w1_PPT18OV'\n]\nchildren_info_2020 = [\n    'w2_PPT01', 'w2_PPT25', 'w2_PPT612', 'w2_PPT1317', 'w2_PPT18OV'\n]\nchildren_info_2022 = [\n    'w3_PPT01', 'w3_PPT25', 'w3_PPT612', 'w3_PPT1317', 'w3_PPT18OV'\n]\n\n\n# Only available in 2022 in full (Post-COVID)\n\n# coronavirus_effect_combo = Is relationship better or worse during pandemic\n# pandemic_income = has income gone up or down during pandemic\n# subject/partner_had_COVID = has been sick with COVID\n# corona/partner_vaccine = has been vaccinated\n# COVID_agreement = subject and partner agree on approach to pandemic\n\ncovid_vars_2022 = [\n    'w3_coronavirus_effect_combo', 'w3_pandemic_income', 'w3_subject_had_COVID', 'w3_partner_had_COVID', 'w3_corona_vaccine',\n    'w3_partner_corona_vaccine', 'w3_COVID_agreement'\n]\n\n\n# Only some variables available per year\n\n# sex_frequency = Frequency of sex\n# flirt = how often flirt\n# fight = how often fight\n# monogamy = subject's commitment to monogamy\n# p_monogamy = expected commitment to monogamy from partner\n\nrelationship_quality_2017 = [\n    'w1_sex_frequency'\n]\nrelationship_quality_2020 = [\n    'w2_sex_frequency', 'w2_flirt', 'w2_fight'\n]\nrelationship_quality_2022 = [\n    'w3_sex_frequency', 'w3_flirt', 'w3_fight'\n]"
  },
  {
    "objectID": "scripts/HCMST_clean.html#rename-columns",
    "href": "scripts/HCMST_clean.html#rename-columns",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Rename Columns",
    "text": "Rename Columns\nSome variables contain the same information but vary in name year to year. So, we’ll need 3 renaming dictionaries (1 per year)\nFirst, the 3 renaming maps (one per year):\n\ncolumn_renames_2017 = {\n    #subject_demographics\n    'w1_ppage': 'subject_age',\n    'w1_ppeduc': 'subject_education',\n    'w1_ppgender': 'subject_sex',\n    'w1_ppethm': 'subject_ethnicity',\n    'w1_ppincimp': 'subject_income_category',\n    'w1_ppwork': 'subject_employment_status',\n    #partner_demographics\n    'w1_q4': 'partner_sex',\n    'w1_q9': 'partner_age',\n    'w1_q6b': 'partner_ethnicity',\n    'w1_q10': 'partner_education',\n    #relationship_status\n    'w1_same_sex_couple': 'same_sex_couple',\n    'w1_married': 'married',\n    'w1_q34': 'relationship_quality',\n    #relationship_time\n    'w1_q21b_year': 'relationship_start_year',\n    'w1_q21d_year': 'marriage_year',\n    'w1_q21e_year': 'break_up_year',\n    'w1_relate_duration_in2017_years': 'relationship_duration',\n    #children_info\n    'w1_PPT01': 'kids_0_1',\n    'w1_PPT25': 'kids_2_5',\n    'w1_PPT612': 'kids_6_12',\n    'w1_PPT1317': 'kids_13_17',\n    'w1_PPT18OV': 'kids_18_plus',\n    #covidvars\n    #'w1_coronavirus_effect_combo': 'rel_change_during_pandemic',\n    #'w1_pandemic_income': 'inc_change_during_pandemic',\n    #'w1_subject_had_COVID': 'subject_had_covid', \n    #'w1_partner_had_COVID': 'partner_had_covid', \n    #'w1_corona_vaccine': 'subject_vaccinated',\n    #'w1_partner_corona_vaccine': 'partner_vaccinated', \n    #'w1_COVID_agreement': 'agree_covid_approach',\n    #relationship_quality\n    'w1_sex_frequency': 'sex_frequency',\n    #'w3_flirt': 'flirts_with_partner',\n    #'w3_fight': 'fights_with_partner',\n}\n\n\ncolumn_renames_2020 = {\n    #subject_demographics\n    'w2_ppage': 'subject_age',\n    'w2_ppeduc': 'subject_education',\n    'w2_ppgender': 'subject_sex',\n    'w2_ppethm': 'subject_ethnicity',\n    'w2_ppincimp': 'subject_income_category',\n    'w2_ppwork': 'subject_employment_status',\n    #partner_demographics\n    'w2_Q4': 'partner_sex',\n    'w2_Q9': 'partner_age',\n    'w2_Q6B': 'partner_ethnicity',\n    'w2_Q10': 'partner_education',\n    #relationship_status\n    'w2_same_sex_couple': 'same_sex_couple',\n    'w2_married': 'married',\n    'w2_rel_qual_combo': 'relationship_quality',\n    #relationship_time\n    'w2_q21b_year': 'relationship_start_year',\n    'w2_q21d_year': 'marriage_year',\n    'w2_q21e_year': 'break_up_year',\n    'w2_relationship_duration': 'relationship_duration',\n    #children_info\n    'w2_PPT01': 'kids_0_1',\n    'w2_PPT25': 'kids_2_5',\n    'w2_PPT612': 'kids_6_12',\n    'w2_PPT1317': 'kids_13_17',\n    'w2_PPT18OV': 'kids_18_plus',\n    #covidvars\n    #'w2_coronavirus_effect_combo': 'rel_change_during_pandemic',\n    #'w2_pandemic_income': 'inc_change_during_pandemic',\n    #'w2_subject_had_COVID': 'subject_had_covid', \n    #'w2_partner_had_COVID': 'partner_had_covid', \n    #'w2_corona_vaccine': 'subject_vaccinated',\n    #'w2_partner_corona_vaccine': 'partner_vaccinated', \n    #'w2_COVID_agreement': 'agree_covid_approach',\n    #relationship_quality\n    'w2_sex_frequency': 'sex_frequency',\n    'w2_flirt': 'flirts_with_partner',\n    'w2_fight': 'fights_with_partner',\n}\n\n\ncolumn_renames_2022 = {\n    #subject_demographics\n    'w3_ppage': 'subject_age',\n    'w3_ppeduc': 'subject_education',\n    'w3_ppgender': 'subject_sex',\n    'w3_ppethm': 'subject_ethnicity',\n    'w3_ppincimp': 'subject_income_category',\n    'w3_ppwork': 'subject_employment_status',\n    #partner_demographics\n    'w3_Q4': 'partner_sex',\n    'w3_Q9': 'partner_age',\n    'w3_Q6B': 'partner_ethnicity',\n    'w3_Q10': 'partner_education',\n    #relationship_status\n    'w3_same_sex_couple': 'same_sex_couple',\n    'w3_married': 'married',\n    'w3_rel_qual': 'relationship_quality',\n    #relationship_time\n    'w3_Q21B_year': 'relationship_start_year',\n    'w3_Q21D_year': 'marriage_year',\n    'w3_Q21E_year': 'break_up_year',\n    'w3_relationship_duration_yrs': 'relationship_duration',\n    #children_info\n    'w3_PPT01': 'kids_0_1',\n    'w3_PPT25': 'kids_2_5',\n    'w3_PPT612': 'kids_6_12',\n    'w3_PPT1317': 'kids_13_17',\n    'w3_PPT18OV': 'kids_18_plus',\n    #covidvars\n    'w3_coronavirus_effect_combo': 'rel_change_during_pandemic',\n    'w3_pandemic_income': 'inc_change_during_pandemic',\n    'w3_subject_had_COVID': 'subject_had_covid', \n    'w3_partner_had_COVID': 'partner_had_covid', \n    'w3_corona_vaccine': 'subject_vaccinated',\n    'w3_partner_corona_vaccine': 'partner_vaccinated', \n    'w3_COVID_agreement': 'agree_covid_approach',\n    #relationship_quality\n    'w3_sex_frequency': 'sex_frequency',\n    'w3_flirt': 'flirts_with_partner',\n    'w3_fight': 'fights_with_partner',\n}\n\n\nDataframe per year\nWe need to create dataframes per year while renaming variables in each dictionary.\nWe will also create a column named “Wave” that contains the year of the survey.\nFirst, 2017:\n\ndf_2017 = df[['caseid_new'] + list(column_renames_2017.keys())].rename(columns=column_renames_2017)\ndf_2017['wave'] = '2017'\ndf_2017.head()\n\n\n\n\n\n\n\n\ncaseid_new\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\n...\nmarriage_year\nbreak_up_year\nrelationship_duration\nkids_0_1\nkids_2_5\nkids_6_12\nkids_13_17\nkids_18_plus\nsex_frequency\nwave\n\n\n\n\n0\n53001\n48\n9\n2\n5\n13\n1\n1.0\n46.0\n1.0\n...\n2014.0\nNaN\n3.583333\n0\n0\n0\n0\n1\n3.0\n2017\n\n\n1\n71609\n68\n10\n2\n1\n12\n1\n1.0\n71.0\n1.0\n...\n1969.0\nNaN\n52.750000\n0\n0\n0\n0\n2\n5.0\n2017\n\n\n2\n106983\n39\n11\n1\n1\n15\n1\n2.0\n49.0\n1.0\n...\n2002.0\nNaN\n17.583334\n0\n0\n2\n0\n3\n3.0\n2017\n\n\n3\n121759\n54\n9\n1\n1\n16\n1\n2.0\n59.0\n4.0\n...\n1991.0\nNaN\n27.416666\n0\n0\n0\n0\n4\n4.0\n2017\n\n\n4\n158083\n48\n10\n1\n1\n14\n1\n2.0\n34.0\n1.0\n...\n2013.0\n2014.0\nNaN\n0\n0\n0\n0\n1\nNaN\n2017\n\n\n\n\n5 rows × 25 columns\n\n\n\n\ndf_2017.shape\n\n(3510, 25)\n\n\nThen, 2020:\n\ndf_2020 = df[['caseid_new'] + list(column_renames_2020.keys())].rename(columns=column_renames_2020)\ndf_2020['wave'] = '2020'\ndf_2020.head()\n\n\n\n\n\n\n\n\ncaseid_new\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\n...\nrelationship_duration\nkids_0_1\nkids_2_5\nkids_6_12\nkids_13_17\nkids_18_plus\nsex_frequency\nflirts_with_partner\nfights_with_partner\nwave\n\n\n\n\n0\n53001\n51.0\n9.0\n2.0\n1.0\n10.0\n1.0\n1.0\n51.0\n1.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n2.0\n5.0\n6.0\n1.0\n2020\n\n\n1\n71609\n71.0\n10.0\n2.0\n1.0\n13.0\n1.0\nNaN\nNaN\nNaN\n...\n56.0\n0.0\n0.0\n0.0\n0.0\n1.0\n5.0\n6.0\n4.0\n2020\n\n\n2\n106983\n42.0\n11.0\n1.0\n1.0\n15.0\n1.0\nNaN\nNaN\nNaN\n...\n21.0\n0.0\n0.0\n1.0\n1.0\n3.0\n3.0\n2.0\n3.0\n2020\n\n\n3\n121759\n57.0\n9.0\n1.0\n1.0\n16.0\n1.0\nNaN\nNaN\nNaN\n...\n31.0\n0.0\n0.0\n0.0\n0.0\n2.0\n4.0\n6.0\n1.0\n2020\n\n\n4\n158083\n52.0\n10.0\n1.0\n1.0\n18.0\n1.0\nNaN\nNaN\nNaN\n...\nNaN\n0.0\n0.0\n0.0\n0.0\n3.0\nNaN\nNaN\nNaN\n2020\n\n\n\n\n5 rows × 27 columns\n\n\n\n\ndf_2020.shape\n\n(3510, 27)\n\n\nThen, 2022:\n\ndf_2022 = df[['caseid_new'] + list(column_renames_2022.keys())].rename(columns=column_renames_2022)\ndf_2022['wave'] = '2022'\ndf_2022.head()\n\n\n\n\n\n\n\n\ncaseid_new\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\n...\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nsex_frequency\nflirts_with_partner\nfights_with_partner\nwave\n\n\n\n\n0\n53001\n53.0\n9.0\n2.0\n1.0\n10.0\n1.0\nNaN\nNaN\nNaN\n...\n3.0\n0.0\n1.0\n4.0\n4.0\n1.0\n3.0\n2.0\n1.0\n2022\n\n\n1\n71609\n72.0\n10.0\n2.0\n1.0\n14.0\n1.0\nNaN\nNaN\nNaN\n...\n2.0\n0.0\n0.0\n1.0\n1.0\n2.0\n5.0\n6.0\n8.0\n2022\n\n\n2\n106983\n43.0\n11.0\n1.0\n1.0\n14.0\n1.0\nNaN\nNaN\nNaN\n...\n2.0\n0.0\n0.0\n1.0\n1.0\n1.0\n3.0\n2.0\n3.0\n2022\n\n\n3\n121759\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\n\n\n4\n158083\n53.0\n10.0\n1.0\n1.0\n18.0\n1.0\nNaN\nNaN\nNaN\n...\n3.0\n0.0\nNaN\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\n\n\n\n\n5 rows × 34 columns\n\n\n\n\ndf_2022.shape\n\n(3510, 34)"
  },
  {
    "objectID": "scripts/HCMST_clean.html#a-single-dataframe",
    "href": "scripts/HCMST_clean.html#a-single-dataframe",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "A single Dataframe",
    "text": "A single Dataframe\nNow, we can concatenate the 3 dataframes since they have the same variables. We’ll have the “wave” column to differentiate by year.\n\ndf_cleaned = pd.concat([df_2017, df_2020, df_2022], ignore_index=True)\n\n\ndf_cleaned.shape\n\n(10530, 34)\n\n\n\ndf_cleaned.head()\n\n\n\n\n\n\n\n\ncaseid_new\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\n...\nwave\nflirts_with_partner\nfights_with_partner\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\n\n\n\n\n0\n53001\n48.0\n9.0\n2.0\n5.0\n13.0\n1.0\n1.0\n46.0\n1.0\n...\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n71609\n68.0\n10.0\n2.0\n1.0\n12.0\n1.0\n1.0\n71.0\n1.0\n...\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n106983\n39.0\n11.0\n1.0\n1.0\n15.0\n1.0\n2.0\n49.0\n1.0\n...\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n121759\n54.0\n9.0\n1.0\n1.0\n16.0\n1.0\n2.0\n59.0\n4.0\n...\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n158083\n48.0\n10.0\n1.0\n1.0\n14.0\n1.0\n2.0\n34.0\n1.0\n...\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 34 columns\n\n\n\nWe are just going to rename the ‘caseid_new’ to something more simple:\n\ndf_cleaned = df_cleaned.rename(columns={'caseid_new': 'id'})\n\n\nSelected variables\n\ndf_cleaned.columns.tolist()\n\n['id',\n 'subject_age',\n 'subject_education',\n 'subject_sex',\n 'subject_ethnicity',\n 'subject_income_category',\n 'subject_employment_status',\n 'partner_sex',\n 'partner_age',\n 'partner_ethnicity',\n 'partner_education',\n 'same_sex_couple',\n 'married',\n 'relationship_quality',\n 'relationship_start_year',\n 'marriage_year',\n 'break_up_year',\n 'relationship_duration',\n 'kids_0_1',\n 'kids_2_5',\n 'kids_6_12',\n 'kids_13_17',\n 'kids_18_plus',\n 'sex_frequency',\n 'wave',\n 'flirts_with_partner',\n 'fights_with_partner',\n 'rel_change_during_pandemic',\n 'inc_change_during_pandemic',\n 'subject_had_covid',\n 'partner_had_covid',\n 'subject_vaccinated',\n 'partner_vaccinated',\n 'agree_covid_approach']\n\n\nMerging kids of all ages to a single feature:\n\ndf_cleaned['children'] = df_cleaned['kids_0_1'] + df_cleaned['kids_2_5'] + df_cleaned['kids_6_12'] + df_cleaned['kids_13_17'] + df_cleaned['kids_18_plus']\n\ndf_cleaned.drop(columns=['kids_0_1', 'kids_2_5', 'kids_6_12', 'kids_13_17', 'kids_18_plus'], inplace=True)\n\n\ndf_cleaned.head()\n\n\n\n\n\n\n\n\nid\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\n...\nflirts_with_partner\nfights_with_partner\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nchildren\n\n\n\n\n0\n53001\n48.0\n9.0\n2.0\n5.0\n13.0\n1.0\n1.0\n46.0\n1.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n1\n71609\n68.0\n10.0\n2.0\n1.0\n12.0\n1.0\n1.0\n71.0\n1.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n2\n106983\n39.0\n11.0\n1.0\n1.0\n15.0\n1.0\n2.0\n49.0\n1.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n5.0\n\n\n3\n121759\n54.0\n9.0\n1.0\n1.0\n16.0\n1.0\n2.0\n59.0\n4.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n4\n158083\n48.0\n10.0\n1.0\n1.0\n14.0\n1.0\n2.0\n34.0\n1.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n\n\n5 rows × 30 columns"
  },
  {
    "objectID": "scripts/HCMST_clean.html#data-type-exploration",
    "href": "scripts/HCMST_clean.html#data-type-exploration",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Data Type Exploration",
    "text": "Data Type Exploration\nWe can see what data type each column has. We can note that all columns are encoded with numerical values.\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nprint(df_cleaned.dtypes)\n\nid                              int64\nsubject_age                   float64\nsubject_education             float64\nsubject_sex                   float64\nsubject_ethnicity             float64\nsubject_income_category       float64\nsubject_employment_status     float64\npartner_sex                   float64\npartner_age                   float64\npartner_ethnicity             float64\npartner_education             float64\nsame_sex_couple               float64\nmarried                       float64\nrelationship_quality          float64\nrelationship_start_year       float64\nmarriage_year                 float64\nbreak_up_year                 float64\nrelationship_duration         float64\nsex_frequency                 float64\nwave                           object\nflirts_with_partner           float64\nfights_with_partner           float64\nrel_change_during_pandemic    float64\ninc_change_during_pandemic    float64\nsubject_had_covid             float64\npartner_had_covid             float64\nsubject_vaccinated            float64\npartner_vaccinated            float64\nagree_covid_approach          float64\nchildren                      float64\ndtype: object"
  },
  {
    "objectID": "scripts/HCMST_clean.html#decoding-variables",
    "href": "scripts/HCMST_clean.html#decoding-variables",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Decoding Variables",
    "text": "Decoding Variables\nWe’ll need to re-map column content to something more interpretable.\nGoing column by column…\nFirst, education level:\n\nedu_mapping = {\n    1: 'no_education',\n    2: '1st_4th_grade',\n    3: '5th_6th_grade',\n    4: '7th_8th_grade',\n    5: '9th',\n    6: '10th',\n    7: '11th',\n    8: '12th_nodiploma',\n    9: 'high_school_grad',\n    10: 'some_college',\n    11: 'associate_degree',\n    12: 'bach_degree',\n    13: 'masters_degree',\n    14: 'prof_doct_degree'\n}\n\ndf_cleaned['subject_education'] = df_cleaned['subject_education'].map(edu_mapping)\ndf_cleaned['partner_education'] = df_cleaned['partner_education'].map(edu_mapping)\n\nordered_levels = [\n    'no_education',\n    '1st_4th_grade',\n    '5th_6th_grade',\n    '7th_8th_grade',\n    '9th',\n    '10th',\n    '11th',\n    '12th_nodiploma',\n    'high_school_grad',\n    'some_college',\n    'associate_degree',\n    'bach_degree',\n    'masters_degree',\n    'prof_doct_degree'\n]\n\n# Convert to ordered categorical\ndf_cleaned['subject_education'] = pd.Categorical(\n    df_cleaned['subject_education'],\n    categories=ordered_levels,\n    ordered=True\n)\n\ndf_cleaned['partner_education'] = pd.Categorical(\n    df_cleaned['partner_education'],\n    categories=ordered_levels,\n    ordered=True\n)\n\nThen gender:\n\ngender_mapping = {\n    1: 'male',\n    2: 'female',\n    3: 'other'\n}\n\ndf_cleaned['subject_sex'] = df_cleaned['subject_sex'].map(gender_mapping)\ndf_cleaned['partner_sex'] = df_cleaned['partner_sex'].map(gender_mapping)\n\nThen, ethniticy/race:\n\neth_sub_mapping = {\n    1: 'white',\n    2: 'black',\n    3: 'other',\n    4: 'hispanic',\n    5: '2_plus_eth'\n}\n\ndf_cleaned['subject_ethnicity'] = df_cleaned['subject_ethnicity'].map(eth_sub_mapping)\n\neth_part_mapping = {\n    1: 'white',\n    2: 'black',\n    3: 'american_indian',\n    4: 'asian',\n    5: 'other'\n}\n\ndf_cleaned['partner_ethnicity'] = df_cleaned['partner_ethnicity'].map(eth_part_mapping)\n\nThen, income level:\n\nincome_mapping = {\n    1: 'under_5k',\n    2: '5k_7k',\n    3: '7k_10k',\n    4: '10k_12k',\n    5: '12k_15k',\n    6: '15k_20k',\n    7: '20k_25k',\n    8: '25k_30k',\n    9: '30k_35k',\n    10: '35k_40k',\n    11: '40k_50k',\n    12: '50k_60k',\n    13: '60k_75k',\n    14: '75k_85k',\n    15: '85k_100k',\n    16: '100k_125k',\n    17: '125k_150k',\n    18: '150k_175k',\n    19: '175k_200k',\n    20: '200k_250k',\n    21: 'over_250k'\n}\n\ndf_cleaned['subject_income_category'] = df_cleaned['subject_income_category'].map(income_mapping)\n\nordered_income_levels = [\n    'under_5k', '5k_7k', '7k_10k', '10k_12k', '12k_15k', '15k_20k',\n    '20k_25k', '25k_30k', '30k_35k', '35k_40k', '40k_50k', '50k_60k',\n    '60k_75k', '75k_85k', '85k_100k', '100k_125k', '125k_150k',\n    '150k_175k', '175k_200k', '200k_250k', 'over_250k'\n]\n\ndf_cleaned['subject_income_category'] = pd.Categorical(\n    df_cleaned['subject_income_category'],\n    categories=ordered_income_levels,\n    ordered=True\n)\n\nThen, employment status:\n\nemployment_mapping = {\n    1: 'working_paid_employee',\n    2: 'working_self_employed',\n    3: 'not_working_temp_layoff',\n    4: 'not_working_looking',\n    5: 'not_working_retired',\n    6: 'not_working_disabled',\n    7: 'not_working_other'\n}\n\ndf_cleaned['subject_employment_status'] = df_cleaned['subject_employment_status'].map(employment_mapping)\n\nThen, same-sex couple encoding:\n\nsame_sex_couple_map = {\n    0: 'no',\n    1: 'yes'\n}\n\ndf_cleaned['same_sex_couple'] = df_cleaned['same_sex_couple'].map(same_sex_couple_map)\n\nThen, marital status:\n\nmarried_mapping = {\n    0: 'not_married',\n    1: 'married'\n}\n\ndf_cleaned['married'] = df_cleaned['married'].map(married_mapping)\n\nThen, relationship quality (THIS COULD BE A TARGET VARIABLE FOR MANY STUDIES):\n\nrel_qual_mapping = {\n    1: 'excellent',\n    2: 'good',\n    3: 'fair',\n    4: 'poor',\n    5: 'very_poor'\n}\n\ndf_cleaned['relationship_quality'] = df_cleaned['relationship_quality'].map(rel_qual_mapping)\n\nThen, the effect of COVID on the relationship. Note that all COVID variables only appear in the 2022 survey.\n\ncovid_effect_mapping = {\n    1: 'better_than_before',\n    2: 'no_change',\n    3: 'worse_than_before'\n}\n\ndf_cleaned['rel_change_during_pandemic'] = df_cleaned['rel_change_during_pandemic'].map(covid_effect_mapping)\n\nThen, the effect of COVID on income level.\n\ncovid_income_mapping = {\n    1: 'much_worse',\n    2: 'worse',\n    3: 'no_change',\n    4: 'better',\n    5: 'much_better'\n}\n\ndf_cleaned['inc_change_during_pandemic'] = df_cleaned['inc_change_during_pandemic'].map(covid_income_mapping)\n\nThen, if subject or partner had COVID\n\nhad_covid_mapping = {\n    0: 'no',\n    1: 'yes'\n}\n\ndf_cleaned['subject_had_covid'] = df_cleaned['subject_had_covid'].map(had_covid_mapping)\ndf_cleaned['partner_had_covid'] = df_cleaned['partner_had_covid'].map(had_covid_mapping)\n\nThen, status of COVID vaccination:\n\ncorona_vaccine_mapping = {\n    1: 'fully_vaccinated_and_booster',\n    2: 'fully_vaccinated_no_booster',\n    3: 'partially_vaccinated',\n    4: 'not_vaccinated'\n}\n\ndf_cleaned['subject_vaccinated'] = df_cleaned['subject_vaccinated'].map(corona_vaccine_mapping)\ndf_cleaned['partner_vaccinated'] = df_cleaned['partner_vaccinated'].map(corona_vaccine_mapping)\n\nThen, if the couple agrees on COVID approach:\n\ncovid_agreement_mapping = {\n    1: 'completely_agree',\n    2: 'mostly_agree',\n    3: 'mostly_disagree',\n    4: 'completely_disagree'\n}\n\ndf_cleaned['agree_covid_approach'] = df_cleaned['agree_covid_approach'].map(covid_agreement_mapping)\n\nThen, sex frequency:\n\nsex_frequency_mapping = {\n    1: 'once_or_more_a_day',\n    2: '3_to_6_times_a_week',\n    3: 'once_or_twice_a_week',\n    4: '2_to_3_times_a_month',\n    5: 'once_a_month_or_less'\n}\n\ndf_cleaned['sex_frequency'] = df_cleaned['sex_frequency'].map(sex_frequency_mapping)\n\nThen, how often the subject flirts with partner:\n\nflirt_mapping = {\n    1: 'every_day',\n    2: 'a_few_times_a_week',\n    3: 'once_a_week',\n    4: '1_to_3_times_a_month',\n    5: 'less_than_once_a_month',\n    6: 'never'\n}\n\ndf_cleaned['flirts_with_partner'] = df_cleaned['flirts_with_partner'].map(flirt_mapping)\n\nordered_flirt_frequency_levels = [\n    'every_day',\n    'a_few_times_a_week',\n    'once_a_week',\n    '1_to_3_times_a_month',\n    'less_than_once_a_month',\n    'never'\n]\n\ndf_cleaned['flirts_with_partner'] = pd.Categorical(\n    df_cleaned['flirts_with_partner'],\n    categories=ordered_flirt_frequency_levels,\n    ordered=True\n)\n\nThen, how often the subject fights with partner:\n\nfight_mapping = {\n    1: '0_times',\n    2: '1_time',\n    3: '2_times',\n    4: '3_times',\n    5: '4_times',\n    6: '5_times',\n    7: '6_times',\n    8: '7_or_more_times'\n}\n\ndf_cleaned['fights_with_partner'] = df_cleaned['fights_with_partner'].map(fight_mapping)\n\nordered_fight_frequency_levels = [\n    '0_times',\n    '1_time',\n    '2_times',\n    '3_times',\n    '4_times',\n    '5_times',\n    '6_times',\n    '7_or_more_times'\n]\n\ndf_cleaned['fights_with_partner'] = pd.Categorical(\n    df_cleaned['fights_with_partner'],\n    categories=ordered_fight_frequency_levels,\n    ordered=True\n)\n\nNow, we can see the updated data types for each variable.\nWe can also see a sample of how the data looks after the recoding process.\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nprint(df_cleaned.dtypes)\n\nid                               int64\nsubject_age                    float64\nsubject_education             category\nsubject_sex                     object\nsubject_ethnicity               object\nsubject_income_category       category\nsubject_employment_status       object\npartner_sex                     object\npartner_age                    float64\npartner_ethnicity               object\npartner_education             category\nsame_sex_couple                 object\nmarried                         object\nrelationship_quality            object\nrelationship_start_year        float64\nmarriage_year                  float64\nbreak_up_year                  float64\nrelationship_duration          float64\nsex_frequency                   object\nwave                            object\nflirts_with_partner           category\nfights_with_partner           category\nrel_change_during_pandemic      object\ninc_change_during_pandemic      object\nsubject_had_covid               object\npartner_had_covid               object\nsubject_vaccinated              object\npartner_vaccinated              object\nagree_covid_approach            object\nchildren                       float64\ndtype: object\n\n\n\ndf_cleaned.sample(20)\n\n\n\n\n\n\n\n\nid\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\npartner_education\nsame_sex_couple\nmarried\nrelationship_quality\nrelationship_start_year\nmarriage_year\nbreak_up_year\nrelationship_duration\nsex_frequency\nwave\nflirts_with_partner\nfights_with_partner\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nchildren\n\n\n\n\n1835\n2317447\n43.0\nbach_degree\nmale\nwhite\n75k_85k\nworking_paid_employee\nfemale\n44.0\nwhite\nassociate_degree\nno\nmarried\nexcellent\n2012.0\n2013.0\nNaN\n5.500000\nonce_or_twice_a_week\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n1203\n1974471\n70.0\nmasters_degree\nfemale\nwhite\n30k_35k\nnot_working_retired\nmale\n74.0\nwhite\nhigh_school_grad\nno\nnot_married\nNaN\n1986.0\nNaN\nNaN\nNaN\nNaN\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n3656\n813467\n63.0\nbach_degree\nfemale\nwhite\n60k_75k\nnot_working_retired\nNaN\nNaN\nNaN\nNaN\nno\nmarried\nexcellent\nNaN\nNaN\nNaN\n41.000000\nonce_a_month_or_less\n2020\n1_to_3_times_a_month\n2_times\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n1657\n2228497\n27.0\nhigh_school_grad\nmale\nwhite\n30k_35k\nnot_working_disabled\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n4525\n1902763\n62.0\nassociate_degree\nmale\nwhite\n20k_25k\nworking_paid_employee\nNaN\nNaN\nNaN\nNaN\nNaN\nnot_married\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2020\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n1888\n2338241\n38.0\n12th_nodiploma\nmale\nwhite\n35k_40k\nworking_paid_employee\nfemale\n37.0\nwhite\nhigh_school_grad\nno\nmarried\nexcellent\n1996.0\n2000.0\nNaN\n20.916666\nonce_or_twice_a_week\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n6896\n2948877\n62.0\nhigh_school_grad\nmale\nwhite\n25k_30k\nnot_working_retired\nNaN\nNaN\nNaN\nNaN\nno\nmarried\ngood\nNaN\nNaN\nNaN\n46.000000\nonce_a_month_or_less\n2020\nnever\n1_time\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n2260\n2565397\n69.0\nbach_degree\nmale\nwhite\n75k_85k\nnot_working_retired\nfemale\n65.0\nasian\nsome_college\nno\nmarried\ngood\n1971.0\n1973.0\nNaN\n45.583332\nonce_a_month_or_less\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.0\n\n\n6693\n2913341\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2020\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n7264\n1018305\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n6925\n2954057\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2020\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n10239\n2920753\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n9129\n2463691\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n10255\n2922621\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2022\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n773\n1760115\n64.0\nhigh_school_grad\nfemale\nwhite\n15k_20k\nnot_working_retired\nmale\n55.0\nwhite\nhigh_school_grad\nno\nnot_married\nexcellent\n2011.0\nNaN\nNaN\n6.333333\nonce_or_twice_a_week\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n2141\n2482081\n38.0\nbach_degree\nmale\nhispanic\n150k_175k\nworking_paid_employee\nfemale\n38.0\nwhite\nmasters_degree\nno\nmarried\nexcellent\n1999.0\n2003.0\nNaN\n17.833334\nonce_or_twice_a_week\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n341\n1181693\n68.0\nhigh_school_grad\nmale\nwhite\n100k_125k\nworking_paid_employee\nfemale\n67.0\nwhite\nsome_college\nno\nmarried\nexcellent\n1973.0\n1974.0\nNaN\n43.916668\nonce_or_twice_a_week\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.0\n\n\n6629\n2899207\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2020\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n9325\n2591515\n70.0\nsome_college\nmale\nwhite\n75k_85k\nworking_paid_employee\nNaN\nNaN\nNaN\nNaN\nno\nmarried\ngood\nNaN\nNaN\nNaN\n38.416668\nonce_or_twice_a_week\n2022\nnever\n2_times\nno_change\nworse\nno\nno\nfully_vaccinated_and_booster\nfully_vaccinated_and_booster\ncompletely_agree\n2.0\n\n\n2138\n2480385\n55.0\nassociate_degree\nmale\nhispanic\n30k_35k\nworking_paid_employee\nmale\n57.0\nwhite\nassociate_degree\nyes\nnot_married\ngood\n1990.0\nNaN\nNaN\n27.083334\nonce_a_month_or_less\n2017\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0"
  },
  {
    "objectID": "scripts/HCMST_clean.html#nan-percentage",
    "href": "scripts/HCMST_clean.html#nan-percentage",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "NaN Percentage",
    "text": "NaN Percentage\nBelow we can note the % of NaN values in each column.\nWe can note that most columns still has a major % of NaN values.\nThese high percentages are mostly dependent on the year of the survey.\nFor example:\n\n2017 is missing primarily COVID related info.\n2020 is missing primarily partner info, chronological info and COVID related info.\n2022 is missing primarily partner info and chronological info.\n\nThis makes sense as the documentation notes that:\n\nVariables in survey changed from year to year slightly.\n“Response rate was 3510/6753=52% in 2017, 2107/2431= 87% in 2020, and 1722/2073=83% in 2022. The Denominators in 2020 and 2022 include only subjects who remained in the KnowledgePanel, as they were the only subjects eligible to be contacted.”\n\n\ndf_cleaned.shape\n\n(10530, 30)\n\n\n\nnan_percentage_per_column = df_cleaned.isna().mean() * 100\nprint(nan_percentage_per_column)\n\nid                             0.000000\nsubject_age                   30.303894\nsubject_education             30.303894\nsubject_sex                   30.303894\nsubject_ethnicity             30.303894\nsubject_income_category       30.303894\nsubject_employment_status     30.303894\npartner_sex                   65.536562\npartner_age                   65.707502\npartner_ethnicity             65.660019\npartner_education             65.622032\nsame_sex_couple               39.563153\nmarried                       31.405508\nrelationship_quality          44.586895\nrelationship_start_year       66.666667\nmarriage_year                 79.116809\nbreak_up_year                 96.077873\nrelationship_duration         46.087369\nsex_frequency                 47.853751\nwave                           0.000000\nflirts_with_partner           70.940171\nfights_with_partner           71.975309\nrel_change_during_pandemic    87.388414\ninc_change_during_pandemic    83.741690\nsubject_had_covid             83.732194\npartner_had_covid             86.904084\nsubject_vaccinated            83.817664\npartner_vaccinated            87.245964\nagree_covid_approach          87.435897\nchildren                      30.303894\ndtype: float64\n\n\n\nnan_percentage_per_column_by_wave = (\n    df_cleaned\n    .groupby('wave')\n    .apply(lambda g: g.isna().mean() * 100)\n    .transpose()\n)\n\nprint(nan_percentage_per_column_by_wave)\n\nwave                              2017        2020       2022\nid                            0.000000    0.000000   0.000000\nsubject_age                   0.000000   39.971510  50.940171\nsubject_education             0.000000   39.971510  50.940171\nsubject_sex                   0.000000   39.971510  50.940171\nsubject_ethnicity             0.000000   39.971510  50.940171\nsubject_income_category       0.000000   39.971510  50.940171\nsubject_employment_status     0.000000   39.971510  50.940171\npartner_sex                   3.390313   95.868946  97.350427\npartner_age                   3.874644   95.868946  97.378917\npartner_ethnicity             3.732194   95.897436  97.350427\npartner_education             3.618234   95.897436  97.350427\nsame_sex_couple               3.304843   53.475783  61.908832\nmarried                       3.304843   39.971510  50.940171\nrelationship_quality         18.888889   52.962963  61.908832\nrelationship_start_year       6.666667   95.925926  97.407407\nmarriage_year                38.205128   99.658120  99.487179\nbreak_up_year                88.319088   99.943020  99.971510\nrelationship_duration        21.225071   54.045584  62.991453\nsex_frequency                23.475783   55.897436  64.188034\nwave                          0.000000    0.000000   0.000000\nflirts_with_partner         100.000000   51.225071  61.595442\nfights_with_partner         100.000000   53.589744  62.336182\nrel_change_during_pandemic  100.000000  100.000000  62.165242\ninc_change_during_pandemic  100.000000  100.000000  51.225071\nsubject_had_covid           100.000000  100.000000  51.196581\npartner_had_covid           100.000000  100.000000  60.712251\nsubject_vaccinated          100.000000  100.000000  51.452991\npartner_vaccinated          100.000000  100.000000  61.737892\nagree_covid_approach        100.000000  100.000000  62.307692\nchildren                      0.000000   39.971510  50.940171\n\n\nC:\\Users\\Paco\\AppData\\Local\\Temp\\ipykernel_56416\\437808906.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  .apply(lambda g: g.isna().mean() * 100)\n\n\nWe can remove some of the rows that are fully empty (even if they have values in “id” and “wave”)\n\ncols_to_check = df_cleaned.columns.difference(['id', 'wave'])\ndf_cleaned = df_cleaned.dropna(subset=cols_to_check, how='all')\n\n\ndf_cleaned.shape\n\n(7339, 30)\n\n\n\nnan_percentage_per_column_by_wave = (\n    df_cleaned\n    .groupby('wave')\n    .apply(lambda g: g.isna().mean() * 100)\n    .transpose()\n)\n\nprint(nan_percentage_per_column_by_wave)\n\nwave                              2017        2020       2022\nid                            0.000000    0.000000   0.000000\nsubject_age                   0.000000    0.000000   0.000000\nsubject_education             0.000000    0.000000   0.000000\nsubject_sex                   0.000000    0.000000   0.000000\nsubject_ethnicity             0.000000    0.000000   0.000000\nsubject_income_category       0.000000    0.000000   0.000000\nsubject_employment_status     0.000000    0.000000   0.000000\npartner_sex                   3.390313   93.118178  94.599303\npartner_age                   3.874644   93.118178  94.657375\npartner_ethnicity             3.732194   93.165638  94.599303\npartner_education             3.618234   93.165638  94.599303\nsame_sex_couple               3.304843   22.496440  22.357724\nmarried                       3.304843    0.000000   0.000000\nrelationship_quality         18.888889   21.642145  22.357724\nrelationship_start_year       6.666667   93.213099  94.715447\nmarriage_year                38.205128   99.430470  98.954704\nbreak_up_year                88.319088   99.905078  99.941928\nrelationship_duration        21.225071   23.445657  24.564460\nsex_frequency                23.475783   26.530612  27.003484\nwave                          0.000000    0.000000   0.000000\nflirts_with_partner         100.000000   18.747034  21.718931\nfights_with_partner         100.000000   22.686284  23.228804\nrel_change_during_pandemic  100.000000  100.000000  22.880372\ninc_change_during_pandemic  100.000000  100.000000   0.580720\nsubject_had_covid           100.000000  100.000000   0.522648\npartner_had_covid           100.000000  100.000000  19.918699\nsubject_vaccinated          100.000000  100.000000   1.045296\npartner_vaccinated          100.000000  100.000000  22.009292\nagree_covid_approach        100.000000  100.000000  23.170732\nchildren                      0.000000    0.000000   0.000000\n\n\nC:\\Users\\Paco\\AppData\\Local\\Temp\\ipykernel_56416\\437808906.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  .apply(lambda g: g.isna().mean() * 100)"
  },
  {
    "objectID": "scripts/HCMST_clean.html#final-reorganization-of-columns",
    "href": "scripts/HCMST_clean.html#final-reorganization-of-columns",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Final Reorganization of Columns",
    "text": "Final Reorganization of Columns\nGiving amount of missing data, “Partner variables” and “Chronological variables” that have significant %NaN rates in 2020 and 2022 could be removed for specific inquiries. However, I would propose to keep them in the overall dataset.\nTherefore, the final data set would be:\n\ndf_cleaned.columns\n\nIndex(['id', 'subject_age', 'subject_education', 'subject_sex',\n       'subject_ethnicity', 'subject_income_category',\n       'subject_employment_status', 'partner_sex', 'partner_age',\n       'partner_ethnicity', 'partner_education', 'same_sex_couple', 'married',\n       'relationship_quality', 'relationship_start_year', 'marriage_year',\n       'break_up_year', 'relationship_duration', 'sex_frequency', 'wave',\n       'flirts_with_partner', 'fights_with_partner',\n       'rel_change_during_pandemic', 'inc_change_during_pandemic',\n       'subject_had_covid', 'partner_had_covid', 'subject_vaccinated',\n       'partner_vaccinated', 'agree_covid_approach', 'children'],\n      dtype='object')\n\n\n\ndata = df_cleaned[['id', 'wave',  #Identifiers\n                   \n                   'subject_age', 'subject_education', 'subject_sex',  #Subject variables\n                   'subject_ethnicity', 'subject_income_category', 'subject_employment_status',\n                   \n                   'partner_sex', 'partner_age', 'partner_ethnicity', 'partner_education',  #Partner variables\n                   \n                   'same_sex_couple', 'married', 'sex_frequency', 'flirts_with_partner', 'fights_with_partner', #Couple Habits\n                   \n                   'relationship_start_year', 'marriage_year', 'break_up_year', #Chronology\n                   'relationship_duration', \n                   \n                   'children',  #Kids Info\n                   \n                   'rel_change_during_pandemic', 'inc_change_during_pandemic', #Pandemic Vars\n                   'subject_had_covid', 'partner_had_covid', 'subject_vaccinated',\n                   'partner_vaccinated', 'agree_covid_approach', \n                   \n                   'relationship_quality' #Outcome\n       ]]\n\ndata.head()\n\n\n\n\n\n\n\n\nid\nwave\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\npartner_education\nsame_sex_couple\nmarried\nsex_frequency\nflirts_with_partner\nfights_with_partner\nrelationship_start_year\nmarriage_year\nbreak_up_year\nrelationship_duration\nchildren\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nrelationship_quality\n\n\n\n\n0\n53001\n2017\n48.0\nhigh_school_grad\nfemale\n2_plus_eth\n60k_75k\nworking_paid_employee\nmale\n46.0\nwhite\nassociate_degree\nno\nmarried\nonce_or_twice_a_week\nNaN\nNaN\n2013.0\n2014.0\nNaN\n3.583333\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n1\n71609\n2017\n68.0\nsome_college\nfemale\nwhite\n50k_60k\nworking_paid_employee\nmale\n71.0\nwhite\nsome_college\nno\nmarried\nonce_a_month_or_less\nNaN\nNaN\n1964.0\n1969.0\nNaN\n52.750000\n2.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n2\n106983\n2017\n39.0\nassociate_degree\nmale\nwhite\n85k_100k\nworking_paid_employee\nfemale\n49.0\nwhite\nsome_college\nno\nmarried\nonce_or_twice_a_week\nNaN\nNaN\n1999.0\n2002.0\nNaN\n17.583334\n5.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n3\n121759\n2017\n54.0\nhigh_school_grad\nmale\nwhite\n100k_125k\nworking_paid_employee\nfemale\n59.0\nasian\nmasters_degree\nno\nmarried\n2_to_3_times_a_month\nNaN\nNaN\n1990.0\n1991.0\nNaN\n27.416666\n4.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n4\n158083\n2017\n48.0\nsome_college\nmale\nwhite\n75k_85k\nworking_paid_employee\nfemale\n34.0\nwhite\nassociate_degree\nno\nnot_married\nNaN\nNaN\nNaN\n2011.0\n2013.0\n2014.0\nNaN\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN"
  },
  {
    "objectID": "scripts/HCMST_clean.html#final-data-review",
    "href": "scripts/HCMST_clean.html#final-data-review",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Final Data Review",
    "text": "Final Data Review\n\nfor column in df_cleaned.columns:\n    print(f\"Column: {column}\")\n    print(f\"Data type: {df_cleaned[column].dtype}\")\n    print(f\"Unique values: {df_cleaned[column].unique()}\\n\")\n\nColumn: id\nData type: int64\nUnique values: [  53001   71609  106983 ... 2968971 2969933 2972135]\n\nColumn: subject_age\nData type: float64\nUnique values: [48. 68. 39. 54. 59. 72. 55. 73. 46. 43. 57. 50. 61. 79. 58. 64. 81. 70.\n 80. 53. 51. 74. 56. 40. 36. 22. 47. 78. 67. 25. 65. 38. 24. 66. 35. 26.\n 60. 71. 27. 29. 34. 76. 21. 41. 28. 19. 49. 86. 20. 23. 44. 84. 62. 63.\n 45. 52. 77. 75. 42. 82. 69. 92. 85. 32. 37. 33. 30. 31. 90. 83. 18. 87.\n 93. 89. 91. 88. 95. 97. 98.]\n\nColumn: subject_education\nData type: category\nUnique values: ['high_school_grad', 'some_college', 'associate_degree', 'bach_degree', 'masters_degree', ..., '11th', '7th_8th_grade', '1st_4th_grade', 'no_education', '5th_6th_grade']\nLength: 14\nCategories (14, object): ['no_education' &lt; '1st_4th_grade' &lt; '5th_6th_grade' &lt; '7th_8th_grade' ... 'associate_degree' &lt; 'bach_degree' &lt; 'masters_degree' &lt; 'prof_doct_degree']\n\nColumn: subject_sex\nData type: object\nUnique values: ['female' 'male']\n\nColumn: subject_ethnicity\nData type: object\nUnique values: ['2_plus_eth' 'white' 'black' 'other' 'hispanic']\n\nColumn: subject_income_category\nData type: category\nUnique values: ['60k_75k', '50k_60k', '85k_100k', '100k_125k', '75k_85k', ..., '15k_20k', '20k_25k', 'under_5k', '7k_10k', '5k_7k']\nLength: 21\nCategories (21, object): ['under_5k' &lt; '5k_7k' &lt; '7k_10k' &lt; '10k_12k' ... '150k_175k' &lt; '175k_200k' &lt; '200k_250k' &lt; 'over_250k']\n\nColumn: subject_employment_status\nData type: object\nUnique values: ['working_paid_employee' 'not_working_disabled' 'not_working_retired'\n 'not_working_looking' 'working_self_employed' 'not_working_other'\n 'not_working_temp_layoff']\n\nColumn: partner_sex\nData type: object\nUnique values: ['male' 'female' nan 'other']\n\nColumn: partner_age\nData type: float64\nUnique values: [46. 71. 49. 59. 34. 52. 75. 55. 79. 37. 63. 51. 61. 62. 74. 50. 65. 58.\n 83. 47. 70. 77. 42. 69. 24. 53. 56. 54. 57. 32. 44. 72. 28. 64. 30. nan\n 33. 60. 43. 25. 27. 31. 80. 21. 78. 67. 29. 40. 39. 76. 23. 41. 45. 82.\n 26. 66. 68. 86. 36. 84. 18. 20. 38. 73. 19. 81. 22. 91. 85. 48. -1. 87.\n 89. 35. 10. 90. 94. 95. 17. 14. 16. 11.]\n\nColumn: partner_ethnicity\nData type: object\nUnique values: ['white' 'asian' 'black' 'american_indian' 'other' nan]\n\nColumn: partner_education\nData type: category\nUnique values: ['associate_degree', 'some_college', 'masters_degree', 'bach_degree', 'high_school_grad', ..., '7th_8th_grade', '10th', 'no_education', '5th_6th_grade', '1st_4th_grade']\nLength: 15\nCategories (14, object): ['no_education' &lt; '1st_4th_grade' &lt; '5th_6th_grade' &lt; '7th_8th_grade' ... 'associate_degree' &lt; 'bach_degree' &lt; 'masters_degree' &lt; 'prof_doct_degree']\n\nColumn: same_sex_couple\nData type: object\nUnique values: ['no' nan 'yes']\n\nColumn: married\nData type: object\nUnique values: ['married' 'not_married' nan]\n\nColumn: relationship_quality\nData type: object\nUnique values: ['excellent' nan 'good' 'fair' 'very_poor' 'poor']\n\nColumn: relationship_start_year\nData type: float64\nUnique values: [2013. 1964. 1999. 1990. 2011. 1993. 1981. 1983. 1996. 2001. 2014. 1984.\n 1987. 1988. 1962. 1989. 1954. 1970. 2007.   nan 1960. 2015. 1978. 2006.\n 2016. 1991. 1986. 1997. 2010. 2017. 1968. 1998. 1980. 2004. 1982. 1972.\n 2002. 1977. 2008. 1974. 1985. 1994. 1979. 2009. 1959. 1965. 2012. 1971.\n 1976. 1961. 1958. 1995. 1969. 1953. 1973. 2003. 1992. 2000. 1967. 1966.\n 1963. 2005. 1975. 1955. 1952. 1947. 1957. 1951. 1950. 1956. 1948. 1949.\n 1942. 2020. 2019. 2018. 1920. 2021. 2022.]\n\nColumn: marriage_year\nData type: float64\nUnique values: [2014. 1969. 2002. 1991. 2013. 1997.   nan 1983. 2017. 2001. 1990. 2007.\n 1964. 1985. 1984. 1956. 1995. 1972. 2008. 1960. 1986. 2000. 2009. 1987.\n 1965. 1978. 1970. 2011. 1973. 2006. 1975. 1981. 1977. 1963. 1988. 1980.\n 1976. 1999. 1992. 1996. 1961. 1974. 1994. 1955. 2016. 2003. 1982. 1998.\n 1971. 1989. 1979. 1966. 2005. 1962. 1967. 1968. 2010. 2015. 2004. 1993.\n 1959. 2012. 1951. 1952. 1957. 1958. 1950. 1944. 1948. 1953. 2019. 2018.\n 2020. 2022. 2021.]\n\nColumn: break_up_year\nData type: float64\nUnique values: [  nan 2014. 1989. 1985. 1984. 2016. 2017. 2012. 2013. 2015. 2007. 2006.\n 2003. 2009. 1996. 2000. 1999. 2010. 1987. 1990. 1976. 2001. 1994. 1997.\n 1978. 2004. 1992. 1975. 2011. 2002. 2008. 1986. 1993. 1980. 1995. 1988.\n 1998. 1977. 2005. 1983. 1991. 2018. 2020. 2022.]\n\nColumn: relationship_duration\nData type: float64\nUnique values: [ 3.58333325e+00  5.27500000e+01  1.75833340e+01  2.74166660e+01\n             nan  2.35833340e+01  3.42500000e+01  2.36666660e+01\n  2.10000000e+01  1.64166660e+01  3.41666675e+00  3.34166679e+01\n  2.98333340e+01  2.89166660e+01  2.67500000e+01  2.80000000e+01\n  3.59166679e+01  6.29166679e+01  2.45000000e+01  2.44166660e+01\n  4.70833321e+01  1.03333330e+01  1.77500000e+01  1.66666663e+00\n  3.89166679e+01  1.80833340e+01  1.09166670e+01  3.58333321e+01\n  2.40833340e+01  2.88333340e+01  2.80833340e+01  2.65000000e+01\n  3.43333321e+01  3.11666660e+01  2.75000000e+00  5.83333349e+00\n  5.66666651e+00  1.95833340e+01  5.26666679e+01  3.95000000e+01\n  4.90833321e+01  6.41666651e+00  1.91666660e+01  3.65833321e+01\n  1.33333330e+01  3.47500000e+01  4.53333321e+01  1.46666670e+01\n  3.99166679e+01  9.16666698e+00  4.25833321e+01  3.18333340e+01\n  2.30000000e+01  3.81666679e+01  4.02500000e+01  1.15000000e+01\n  3.90833321e+01  4.93333321e+01  8.16666698e+00  3.02500000e+01\n  5.78333321e+01  5.15833321e+01  5.16666651e+00  3.10833340e+01\n  3.67500000e+01  3.88333321e+01  4.56666679e+01  3.30000000e+01\n  3.32500000e+01  4.61666679e+01  2.78333340e+01  1.33333337e+00\n  1.97500000e+01  3.80833321e+01  3.16666660e+01  3.97500000e+01\n  2.02500000e+01  5.95000000e+01  2.24166660e+01  3.40833321e+01\n  4.10000000e+01  6.66666687e-01  4.13333321e+01  4.12500000e+01\n  1.00000000e+01  2.08333325e+00  7.83333349e+00  3.22500000e+01\n  2.03333340e+01  9.41666698e+00  5.65833321e+01  3.75000000e+00\n  1.00833330e+01  2.58333325e+00  4.31666679e+01  4.87500000e+01\n  3.66666675e+00  2.77500000e+01  4.79166679e+01  2.69166660e+01\n  6.37500000e+01  2.16666675e+00  4.58333349e+00  3.51666679e+01\n  4.40000000e+01  1.26666670e+01  1.50000000e+01  2.20833340e+01\n  1.41666670e+01  3.52500000e+01  5.48333321e+01  2.30833340e+01\n  4.50833321e+01  3.72500000e+01  3.24166679e+01  5.28333321e+01\n  6.50000000e+00  2.96666660e+01  2.71666660e+01  5.90833321e+01\n  4.05000000e+01  1.93333340e+01  2.49166660e+01  1.65833340e+01\n  2.91666675e+00  5.19166679e+01  1.66666672e-01  1.40000000e+01\n  2.63333340e+01  4.98333321e+01  5.07500000e+01  2.90833340e+01\n  2.50000000e-01  2.56666660e+01  2.68333340e+01  4.26666679e+01\n  4.41666651e+00  1.04166670e+01  5.37500000e+01  0.00000000e+00\n  3.55833321e+01  4.91666651e+00  3.04166660e+01  1.78333340e+01\n  3.00833340e+01  5.46666679e+01  9.58333302e+00  2.12500000e+01\n  4.94166679e+01  3.57500000e+01  1.91666663e+00  2.94166660e+01\n  1.89166660e+01  1.54166670e+01  1.05833330e+01  1.94166660e+01\n  3.30833321e+01  1.25000000e+01  1.61666660e+01  4.24166679e+01\n  1.68333340e+01  4.60833321e+01  8.50000000e+00  3.91666675e+00\n  4.71666679e+01  5.00000000e-01  4.28333321e+01  4.15000000e+01\n  2.29166660e+01  3.84166679e+01  2.19166660e+01  1.57500000e+01\n  6.83333349e+00  3.96666679e+01  1.55000000e+01  6.16666679e+01\n  2.70833340e+01  4.16666679e+01  5.21666679e+01  2.00833340e+01\n  3.50000000e+00  2.82500000e+01  1.36666670e+01  6.50833359e+01\n  2.87500000e+01  2.52500000e+01  5.13333321e+01  5.25000000e+01\n  2.51666660e+01  3.68333321e+01  2.91666660e+01  3.54166679e+01\n  4.75833321e+01  2.06666660e+01  5.72500000e+01  3.41666679e+01\n  1.10000000e+01  4.92500000e+01  5.10833321e+01  3.20000000e+01\n  2.79166660e+01  2.33333340e+01  2.64166660e+01  2.76666660e+01\n  4.46666679e+01  5.66666679e+01  3.20833321e+01  5.55833321e+01\n  5.79166679e+01  2.48333340e+01  5.30000000e+01  5.55000000e+01\n  1.58333337e+00  1.08333337e+00  3.39166679e+01  1.24166670e+01\n  7.91666651e+00  9.00000000e+00  4.00000000e+01  5.08333321e+01\n  2.00000000e+01  3.35000000e+01  5.36666679e+01  4.33333349e+00\n  3.37500000e+01  1.58333330e+01  4.39166679e+01  4.83333321e+01\n  4.60000000e+01  8.33333358e-02  5.00000000e+01  4.10833321e+01\n  2.04166660e+01  2.99166660e+01  2.50000000e+00  4.50000000e+01\n  5.00000000e+00  1.20000000e+01  1.90833340e+01  1.88333340e+01\n  7.50000000e+00  2.38333340e+01  1.62500000e+01  8.91666698e+00\n  8.41666698e+00  7.00000000e+01  2.33333325e+00  2.14166660e+01\n  4.85000000e+01  1.80000000e+01  5.25833321e+01  4.89166679e+01\n  2.55000000e+01  2.09166660e+01  6.00000000e+00  2.34166660e+01\n  2.83333340e+01  4.01666679e+01  5.99166679e+01  5.60000000e+01\n  3.77500000e+01  2.57500000e+01  3.25000000e+00  9.25000000e+00\n  3.63333321e+01  1.59166670e+01  1.32500000e+01  1.25833330e+01\n  1.85833340e+01  7.50000000e-01  4.38333321e+01  3.86666679e+01\n  3.66666679e+01  5.83333313e-01  2.92500000e+01  2.16666660e+01\n  6.60000000e+01  5.50833321e+01  1.16666663e+00  5.20000000e+01\n  5.44166679e+01  3.65000000e+01  3.23333321e+01  8.83333302e+00\n  4.04166679e+01  4.69166679e+01  2.17500000e+01  3.21666679e+01\n  5.03333321e+01  1.39166670e+01  4.57500000e+01  1.75000000e+01\n  7.75000000e+00  2.73333340e+01  5.58333321e+01  2.46666660e+01\n  2.62500000e+01  1.30000000e+01  9.91666698e+00  2.28333340e+01\n  1.83333337e+00  2.58333340e+01  2.15833340e+01  2.95833340e+01\n  2.26666660e+01  3.76666679e+01  4.45833321e+01  9.75000000e+00\n  3.25833321e+01  5.11666679e+01  3.17500000e+01  2.01666660e+01\n  2.75833340e+01  5.47500000e+01  1.87500000e+01  4.80833321e+01\n  4.97500000e+01  4.90000000e+01  3.45000000e+01  5.91666651e+00\n  3.13333340e+01  3.64166679e+01  3.70000000e+01  5.09166679e+01\n  4.81666679e+01  6.50000000e+01  4.03333321e+01  3.93333321e+01\n  4.76666679e+01  4.08333349e+00  4.48333321e+01  1.35000000e+01\n  4.07500000e+01  4.16666651e+00  3.75833321e+01  4.23333321e+01\n  5.50000000e+00  4.64166679e+01  1.11666670e+01  1.41666663e+00\n  2.50833340e+01  1.44166670e+01  2.11666660e+01  5.49166679e+01\n  4.20833321e+01  2.60000000e+01  4.30833321e+01  1.83333340e+01\n  3.28333321e+01  1.69166660e+01  1.82500000e+01  3.90000000e+01\n  3.50000000e+01  1.63333340e+01  1.74166660e+01  1.23333330e+01\n  1.37500000e+01  5.41666651e+00  2.23333340e+01  5.70833321e+01\n  8.33333302e+00  3.55000000e+01  4.59166679e+01  2.95000000e+01\n  3.53333321e+01  3.74166679e+01  5.39166679e+01  6.30000000e+01\n  6.91666651e+00  1.19166670e+01  8.66666698e+00  4.34166679e+01\n  2.41666675e+00  6.58333349e+00  4.83333349e+00  5.69166679e+01\n  8.00000000e+00  1.47500000e+01  2.22500000e+01  3.61666679e+01\n  4.00833321e+01  1.52500000e+01  3.19166660e+01  3.06666660e+01\n  5.24166679e+01  5.77500000e+01  3.08333340e+01  5.42500000e+01\n  4.30000000e+01  5.60833321e+01  1.72500000e+01  3.08333325e+00\n  2.47500000e+01  4.88333321e+01  4.18333321e+01  2.90000000e+01\n  3.91666679e+01  3.25000000e+01  1.13333330e+01  3.38333321e+01\n  2.42500000e+01  4.17500000e+01  2.05000000e+01  4.49166679e+01\n  4.73333321e+01  3.83333325e+00  3.83333321e+01  1.45000000e+01\n  6.75000000e+00  4.55833321e+01  4.95833321e+01  2.75000000e+01\n  2.70000000e+01  1.05000000e+01  8.33333313e-01  2.05833340e+01\n  3.00000000e+00  9.66666698e+00  1.76666660e+01  4.84166679e+01\n  2.53333340e+01  1.67500000e+01  6.33333349e+00  3.50833321e+01\n  2.81666660e+01  1.18333330e+01  2.25000000e+01  5.02500000e+01\n  4.35833321e+01  5.06666679e+01  3.33333343e-01  1.60833340e+01\n  4.70000000e+01  6.25000000e+00  1.21666670e+01  4.82500000e+01\n  1.16666670e+01  9.83333302e+00  3.85000000e+01  5.63333321e+01\n  1.50000000e+00  4.75000000e+01  3.95833321e+01  6.58333359e+01\n -3.33333343e-01  2.41666660e+01  1.50833330e+01  8.58333302e+00\n  6.67500000e+01  4.50000000e+00  5.58333349e+00  1.84166660e+01\n  2.08333340e+01  4.06666679e+01  5.53333321e+01  7.41666651e+00\n  4.75000000e+00  2.86666660e+01  2.15000000e+01  1.45833330e+01\n  5.17500000e+01  2.59166660e+01  1.55833330e+01  4.36666679e+01\n  1.25000000e+00  1.06666670e+01  4.19166679e+01  1.73333340e+01\n  1.10833330e+01  5.91666679e+01  1.70833340e+01  3.40000000e+01\n  1.66666660e+01  2.43333340e+01  4.20000000e+01  1.70000000e+01\n  7.16666651e+00  5.57500000e+01  2.40000000e+01  6.08333349e+00\n  1.92500000e+01  4.08333321e+01  1.01666670e+01  2.93333340e+01\n  2.66666660e+01  5.75000000e+00  6.26666679e+01  4.22500000e+01\n  1.95000000e+01  1.90000000e+01  3.60000000e+01  4.68333321e+01\n  1.29166670e+01  1.75000000e+00  1.27500000e+01  9.16666687e-01\n  6.21666679e+01  4.54166679e+01  9.08333302e+00  8.08333302e+00\n  5.40833321e+01  4.78333321e+01  7.08333349e+00  4.11666679e+01\n  3.15000000e+01  7.25000000e+00  4.14166679e+01  1.99166660e+01\n  6.08333321e+01  2.25000000e+00  1.30833330e+01  1.56666670e+01\n  1.15833330e+01  8.25000000e+00  7.00000000e+00  4.00000000e+00\n  3.33333325e+00  4.65833321e+01  6.16666651e+00  1.02500000e+01\n  6.00000000e+01  4.33333321e+01  4.65000000e+01  2.60833340e+01\n  1.31666670e+01  1.17500000e+01  2.55833340e+01  4.42500000e+01\n  1.51666670e+01  3.09166660e+01  2.65833340e+01  1.48333330e+01\n  5.38333321e+01  9.33333302e+00  2.66666675e+00  2.25833340e+01\n  6.28333321e+01  4.72500000e+01  2.50000000e+01  1.42500000e+01\n  1.38333330e+01  4.16666657e-01  2.13333340e+01  2.37500000e+01\n  3.98333321e+01  5.22500000e+01  1.53333330e+01  3.85833321e+01\n  3.00000000e+01  7.58333349e+00  4.25000000e+00  3.78333321e+01\n  3.87500000e+01  5.50000000e+01  4.85833321e+01  2.21666660e+01\n  6.47500000e+01  8.75000000e+00  3.16666675e+00  1.20833330e+01\n  6.66666651e+00  3.75000000e+01  1.43333330e+01  3.56666679e+01\n  1.40833330e+01  3.82500000e+01  4.58333321e+01  1.35833330e+01\n  5.33333349e+00  4.66666651e+00  1.22500000e+01  5.20833321e+01\n  1.08333330e+01  3.71666679e+01  2.83333325e+00  4.41666679e+01\n  6.90833359e+01  3.92500000e+01  3.80000000e+01  4.21666679e+01\n  3.46666679e+01  5.76666679e+01  1.07500000e+01  5.25000000e+00\n  6.07500000e+01  4.51666679e+01  5.10000000e+01  2.00000000e+00\n  1.28333330e+01  1.34166670e+01  6.40833359e+01  5.68333321e+01\n  2.07500000e+01  3.49166679e+01  4.09166679e+01  5.45000000e+01\n  5.35833321e+01  1.60000000e+01  3.60833321e+01  6.80000000e+01\n  2.61666660e+01  5.54166679e+01  4.77500000e+01  1.00000000e+00\n  3.33333321e+01  1.12500000e+01  6.00833321e+01  1.86666660e+01\n  1.79166660e+01  3.03333340e+01  3.73333321e+01  5.43333321e+01\n  5.15000000e+01  3.05833340e+01  4.55000000e+01  1.49166670e+01\n  4.15833321e+01  3.10000000e+01  3.05000000e+01  6.06666679e+01\n  3.48333321e+01  3.94166679e+01  4.47500000e+01  2.72500000e+01\n  3.15833340e+01  3.44166679e+01  2.84166660e+01  4.67500000e+01\n  2.35000000e+01  3.14166660e+01  4.37500000e+01  3.69166679e+01\n  2.45833340e+01  5.01666679e+01  6.12500000e+01  1.14166670e+01\n  2.20000000e+01  7.51666641e+01  6.45833359e+01  7.33333349e+00\n  6.69166641e+01  3.29166679e+01  5.12500000e+01  1.71666660e+01\n  5.45833321e+01  2.27500000e+01  5.62500000e+01  5.90000000e+01\n  5.08333349e+00  4.63333321e+01  2.32500000e+01  6.11666679e+01\n  4.74166679e+01  2.10833340e+01  9.50000000e+00  5.30833321e+01\n  1.81666660e+01  2.85833340e+01  3.36666679e+01  4.25000000e+01\n  4.66666679e+01  3.70833321e+01  6.73333359e+01  4.05833321e+01\n  5.65000000e+01  1.96666660e+01  2.18333340e+01  2.85000000e+01\n  4.44166679e+01  3.12500000e+01  4.45000000e+01  6.23333321e+01\n  4.40833321e+01  5.00833321e+01  6.10833321e+01  1.98333340e+01\n  4.99166679e+01  5.34166679e+01  2.97500000e+01  5.35000000e+01\n  5.88333321e+01  6.19166679e+01  4.29166679e+01  5.95833321e+01\n  5.40000000e+01  5.05000000e+01  1.65000000e+01  2.54166660e+01\n  5.86666679e+01  3.79166679e+01  3.45833321e+01  7.66666651e+00\n  2.31666660e+01  6.10000000e+01  6.70000000e+01  5.80000000e+01\n  5.70000000e+01  4.80000000e+01  7.40000000e+01  6.90000000e+01\n  7.10000000e+01  6.20000000e+01  6.40000000e+01  7.20000000e+01\n  5.74166679e+01  3.35833321e+01  6.75833359e+01  5.73333321e+01\n  6.25000000e+01  4.35000000e+01  4.27500000e+01  6.41666641e+01\n  5.18333321e+01  6.97500000e+01  5.71666679e+01  6.02500000e+01\n  5.83333321e+01  7.46666641e+01  5.31666679e+01  3.01666660e+01\n  5.97500000e+01  6.05000000e+01  5.23333321e+01  5.05833321e+01\n  3.26666679e+01  5.89166679e+01  5.16666679e+01  5.29166679e+01\n  7.14166641e+01  3.27500000e+01  5.64166679e+01  3.07500000e+01\n  5.85000000e+01  4.32500000e+01  2.39166660e+01  5.32500000e+01\n  6.04166679e+01  4.62500000e+01  6.54166641e+01  5.56666679e+01\n  5.04166679e+01  6.15000000e+01  5.82500000e+01  7.26666641e+01\n  5.85833321e+01  5.61666679e+01  6.55000000e+01  5.67500000e+01\n  6.53333359e+01  3.62500000e+01  5.14166679e+01  5.87500000e+01\n  1.85000000e+01  7.15833359e+01  6.09166679e+01  6.13333321e+01\n  3.31666679e+01  4.52500000e+01  4.96666679e+01  5.94166679e+01\n  1.01750000e+02]\n\nColumn: sex_frequency\nData type: object\nUnique values: ['once_or_twice_a_week' 'once_a_month_or_less' '2_to_3_times_a_month' nan\n '3_to_6_times_a_week' 'once_or_more_a_day']\n\nColumn: wave\nData type: object\nUnique values: ['2017' '2020' '2022']\n\nColumn: flirts_with_partner\nData type: category\nUnique values: [NaN, 'never', 'a_few_times_a_week', 'less_than_once_a_month', '1_to_3_times_a_month', 'every_day', 'once_a_week']\nCategories (6, object): ['every_day' &lt; 'a_few_times_a_week' &lt; 'once_a_week' &lt; '1_to_3_times_a_month' &lt; 'less_than_once_a_month' &lt; 'never']\n\nColumn: fights_with_partner\nData type: category\nUnique values: [NaN, '0_times', '3_times', '2_times', '1_time', '7_or_more_times', '4_times', '5_times', '6_times']\nCategories (8, object): ['0_times' &lt; '1_time' &lt; '2_times' &lt; '3_times' &lt; '4_times' &lt; '5_times' &lt; '6_times' &lt; '7_or_more_times']\n\nColumn: rel_change_during_pandemic\nData type: object\nUnique values: [nan 'better_than_before' 'no_change' 'worse_than_before']\n\nColumn: inc_change_during_pandemic\nData type: object\nUnique values: [nan 'no_change' 'worse' 'much_worse' 'better' 'much_better']\n\nColumn: subject_had_covid\nData type: object\nUnique values: [nan 'no' 'yes']\n\nColumn: partner_had_covid\nData type: object\nUnique values: [nan 'yes' 'no']\n\nColumn: subject_vaccinated\nData type: object\nUnique values: [nan 'not_vaccinated' 'fully_vaccinated_and_booster'\n 'fully_vaccinated_no_booster' 'partially_vaccinated']\n\nColumn: partner_vaccinated\nData type: object\nUnique values: [nan 'not_vaccinated' 'fully_vaccinated_and_booster'\n 'partially_vaccinated' 'fully_vaccinated_no_booster']\n\nColumn: agree_covid_approach\nData type: object\nUnique values: [nan 'completely_agree' 'mostly_agree' 'completely_disagree'\n 'mostly_disagree']\n\nColumn: children\nData type: float64\nUnique values: [ 1.  2.  5.  4.  6.  3.  8. 10.  7.  9. 12.]"
  },
  {
    "objectID": "scripts/HCMST_clean.html#saving-csv",
    "href": "scripts/HCMST_clean.html#saving-csv",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Saving CSV",
    "text": "Saving CSV\n\ndata.to_csv(\"../data/clean/hcmst.csv\", index=False)"
  },
  {
    "objectID": "scripts/HCMST_clean.html#testing-a-2022-data-set",
    "href": "scripts/HCMST_clean.html#testing-a-2022-data-set",
    "title": "Clean up for HCMST_2017-2022.csv",
    "section": "Testing a 2022 data set:",
    "text": "Testing a 2022 data set:\nDuring the client meeting on May 21st, 2025. It was decided to only keep 2022 data, while removing mostly sparse columns, id and wave values.\n\nclean = pd.read_csv(\"../data/clean/hcmst.csv\")\n\nclean.head()\n\n\n\n\n\n\n\n\nid\nwave\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\npartner_sex\npartner_age\npartner_ethnicity\npartner_education\nsame_sex_couple\nmarried\nsex_frequency\nflirts_with_partner\nfights_with_partner\nrelationship_start_year\nmarriage_year\nbreak_up_year\nrelationship_duration\nchildren\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nrelationship_quality\n\n\n\n\n0\n53001\n2017\n48.0\nhigh_school_grad\nfemale\n2_plus_eth\n60k_75k\nworking_paid_employee\nmale\n46.0\nwhite\nassociate_degree\nno\nmarried\nonce_or_twice_a_week\nNaN\nNaN\n2013.0\n2014.0\nNaN\n3.583333\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n1\n71609\n2017\n68.0\nsome_college\nfemale\nwhite\n50k_60k\nworking_paid_employee\nmale\n71.0\nwhite\nsome_college\nno\nmarried\nonce_a_month_or_less\nNaN\nNaN\n1964.0\n1969.0\nNaN\n52.750000\n2.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n2\n106983\n2017\n39.0\nassociate_degree\nmale\nwhite\n85k_100k\nworking_paid_employee\nfemale\n49.0\nwhite\nsome_college\nno\nmarried\nonce_or_twice_a_week\nNaN\nNaN\n1999.0\n2002.0\nNaN\n17.583334\n5.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n3\n121759\n2017\n54.0\nhigh_school_grad\nmale\nwhite\n100k_125k\nworking_paid_employee\nfemale\n59.0\nasian\nmasters_degree\nno\nmarried\n2_to_3_times_a_month\nNaN\nNaN\n1990.0\n1991.0\nNaN\n27.416666\n4.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nexcellent\n\n\n4\n158083\n2017\n48.0\nsome_college\nmale\nwhite\n75k_85k\nworking_paid_employee\nfemale\n34.0\nwhite\nassociate_degree\nno\nnot_married\nNaN\nNaN\nNaN\n2011.0\n2013.0\n2014.0\nNaN\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\ndata_2022 = clean[clean['wave'] == 2022].dropna(subset=['rel_change_during_pandemic', 'relationship_quality'])\n\n\ndata_2022.columns.tolist()\n\n['id',\n 'wave',\n 'subject_age',\n 'subject_education',\n 'subject_sex',\n 'subject_ethnicity',\n 'subject_income_category',\n 'subject_employment_status',\n 'partner_sex',\n 'partner_age',\n 'partner_ethnicity',\n 'partner_education',\n 'same_sex_couple',\n 'married',\n 'sex_frequency',\n 'flirts_with_partner',\n 'fights_with_partner',\n 'relationship_start_year',\n 'marriage_year',\n 'break_up_year',\n 'relationship_duration',\n 'children',\n 'rel_change_during_pandemic',\n 'inc_change_during_pandemic',\n 'subject_had_covid',\n 'partner_had_covid',\n 'subject_vaccinated',\n 'partner_vaccinated',\n 'agree_covid_approach',\n 'relationship_quality']\n\n\n\ndata_2022 = data_2022[[\n 'subject_age',\n 'subject_education',\n 'subject_sex',\n 'subject_ethnicity',\n 'subject_income_category',\n 'subject_employment_status',\n 'same_sex_couple',\n 'married',\n 'sex_frequency',\n 'flirts_with_partner',\n 'fights_with_partner',\n 'relationship_duration',\n 'children',\n 'rel_change_during_pandemic',\n 'inc_change_during_pandemic',\n 'subject_had_covid',\n 'partner_had_covid',\n 'subject_vaccinated',\n 'partner_vaccinated',\n 'agree_covid_approach',\n 'relationship_quality']]\n\n\ndata_2022.head()\n\n\n\n\n\n\n\n\nsubject_age\nsubject_education\nsubject_sex\nsubject_ethnicity\nsubject_income_category\nsubject_employment_status\nsame_sex_couple\nmarried\nsex_frequency\nflirts_with_partner\nfights_with_partner\nrelationship_duration\nchildren\nrel_change_during_pandemic\ninc_change_during_pandemic\nsubject_had_covid\npartner_had_covid\nsubject_vaccinated\npartner_vaccinated\nagree_covid_approach\nrelationship_quality\n\n\n\n\n5617\n53.0\nhigh_school_grad\nfemale\nwhite\n35k_40k\nworking_paid_employee\nno\nnot_married\nonce_or_twice_a_week\na_few_times_a_week\n0_times\n1.500000\n2.0\nbetter_than_before\nno_change\nno\nyes\nnot_vaccinated\nnot_vaccinated\ncompletely_agree\nexcellent\n\n\n5618\n72.0\nsome_college\nfemale\nwhite\n75k_85k\nworking_paid_employee\nno\nmarried\nonce_a_month_or_less\nnever\n7_or_more_times\n57.416668\n1.0\nno_change\nworse\nno\nno\nfully_vaccinated_and_booster\nfully_vaccinated_and_booster\nmostly_agree\ngood\n\n\n5619\n43.0\nassociate_degree\nmale\nwhite\n75k_85k\nworking_paid_employee\nno\nmarried\nonce_or_twice_a_week\na_few_times_a_week\n2_times\n22.333334\n5.0\nno_change\nworse\nno\nno\nfully_vaccinated_and_booster\nfully_vaccinated_and_booster\ncompletely_agree\nexcellent\n\n\n5621\n64.0\nsome_college\nmale\nwhite\n75k_85k\nworking_paid_employee\nno\nmarried\nonce_or_twice_a_week\n1_to_3_times_a_month\n0_times\n28.250000\n2.0\nno_change\nno_change\nno\nno\nfully_vaccinated_and_booster\nfully_vaccinated_and_booster\ncompletely_agree\ngood\n\n\n5623\n60.0\nhigh_school_grad\nfemale\nblack\n75k_85k\nworking_paid_employee\nno\nmarried\nonce_or_twice_a_week\na_few_times_a_week\n0_times\n38.916668\n3.0\nbetter_than_before\nno_change\nno\nno\nnot_vaccinated\npartially_vaccinated\ncompletely_agree\nexcellent\n\n\n\n\n\n\n\n\ndata_2022.shape\n\n(1328, 21)\n\n\n\ndata_2022.to_csv(\"../data/clean/hcmst.csv\", index=False)"
  },
  {
    "objectID": "scripts/bcindegeniouslistings_clean.html",
    "href": "scripts/bcindegeniouslistings_clean.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport re\n\nLoad the raw data\n\n# Load the data\ndf = pd.read_csv(\"../bcindigenousbusinesslistings3.csv\")\n\nInspecting the data\n\n# Inspect the data\nprint(df.info())\nprint(df.head())\nprint(f\"Initial number of rows: {len(df)}\") \n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1259 entries, 0 to 1258\nData columns (total 12 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Business Name        1259 non-null   object \n 1   Description          1135 non-null   object \n 2   Web Site             699 non-null    object \n 3   City                 1258 non-null   object \n 4   Latitude             1258 non-null   float64\n 5   Longitude            1258 non-null   float64\n 6   Keywords             1257 non-null   object \n 7   Region               1259 non-null   object \n 8   Type                 1123 non-null   object \n 9   Industry Sector      1222 non-null   object \n 10  Year Formed          648 non-null    float64\n 11  Number of Employees  572 non-null    object \ndtypes: float64(3), object(9)\nmemory usage: 118.2+ KB\nNone\n                                       Business Name  \\\n0                                Ellipsis Energy Inc   \n1  Indigenous Community Development & Prosperity ...   \n2                         Formline Construction Ltd.   \n3                          Quilakwa Investments Ltd.   \n4                                      Quilakwa Esso   \n\n                                         Description  \\\n0  Ellipsis Energy Inc is an Aboriginal owned com...   \n1  ICDPRO works together with Indigenous communit...   \n2  With over combined 30 years of experience in t...   \n3  Quilakwa Investments Ltd. oversees several Ind...   \n4  Quilakwa Esso is owned by the Splatsin Indian ...   \n\n                                      Web Site           City   Latitude  \\\n0                 http://www.ellipsisenergy.ca  Moberly Lake   55.819370   \n1  https://indigenouscommunitydevelopment.com/        Enderby  50.551498   \n2                        https://www.flcon.ca/        Burnaby  49.266050   \n3                    http://www.splatsindc.com        Enderby  50.537507   \n4                                          NaN        Enderby  50.537507   \n\n    Longitude                                           Keywords  \\\n0 -121.834602  Ellipsis Energy Inc 21 – Mining, quarrying, an...   \n1 -119.133546  Indigenous Community Development & Prosperity ...   \n2  123.005840       Formline Construction Ltd. 23 – Construction   \n3 -119.141955                          Quilakwa Investments Ltd.   \n4 -119.141955                 Quilakwa Esso 44-45 - Retail trade   \n\n                       Region                     Type  \\\n0                   Northeast          Private Company   \n1         Thompson / Okanagan          Private Company   \n2  Lower Mainland / Southwest          Private Company   \n3         Thompson / Okanagan  Community Owned Company   \n4         Thompson / Okanagan  Community Owned Company   \n\n                                     Industry Sector  Year Formed  \\\n0  21 – Mining, quarrying, and oil and gas extrac...       2012.0   \n1  81 – Other services (except public administrat...       2020.0   \n2                                  23 – Construction       2021.0   \n3               72 – Accommodation and food services       1984.0   \n4                               44-45 - Retail trade       1984.0   \n\n  Number of Employees  \n0              5 to 9  \n1              1 to 4  \n2              1 to 4  \n3            20 to 49  \n4            10 to 19  \nInitial number of rows: 1259\n\n\nColumn Name Standardization\n\n#  Clean column names (convert to lowercase and replace spaces with underscores)\ndf.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n\nRemove Unnecessary Columns\n\n# Remove unnecessary columns\ncolumns_to_drop = ['description', 'web_site', 'keywords']\ndf = df.drop(columns=columns_to_drop, errors='ignore')\n\nRemoval of Duplicates\n\n# Remove duplicate rows\ndf = df.drop_duplicates()\n\n\n# check no of rows after removing duplicates\nprint(f\"No of rows after removing duplicates: {len(df)}\") \n\nNo of rows after removing duplicates: 1259\n\n\nCritical Data Validation\n\n# Remove rows missing critical information\n#business_name is a mandatory field here\nif 'business_name' in df.columns:\n    df = df[df['business_name'].notna() & (df['business_name'] != '')]\n\n\n# check no of rows after removing rows missing critical information\nprint(f\"No of rows: {len(df)}\") \n\nNo of rows: 1259\n\n\nEnsure Year is an integer\n\n# Ensure year_formed is a nullable integer\ndf['year_formed'] = pd.to_numeric(df['year_formed'], errors='coerce').astype('Int64')\n\nCleanup industry_sector\n\n# custom function to standardize industry_sector data\ndef clean_industry_sector(sector):\n    if pd.isna(sector):\n        return np.nan\n    \n    # Convert to string\n    sector = str(sector).strip()\n    \n    # Handle cases starting with colon\n    if sector.startswith(':'):\n        sector = sector[1:].strip()\n    \n    # Remove ALL number patterns including:\n    # \"23 - \", \"44-45 - \", \"1.5 - \", \"54 – \" (with en dash)\n    sector = re.sub(r'^[\\d\\.]+\\s*[-–—]?\\s*[\\d\\.]*\\s*[-–—]\\s*', '', sector).strip()\n    \n    # Return np.nan if empty, otherwise capitalize first letter\n    return np.nan if not sector else sector[0].upper() + sector[1:]\n\n\nprint(\"test cleaning:\")\ntest_case = \":54 – Professional, scientific and technical services\"\nprint(f\"'{test_case}' → '{clean_industry_sector(test_case)}'\")\n\n\ndf['industry_sector'] = df['industry_sector'].apply(clean_industry_sector)\n\ntest cleaning:\n':54 – Professional, scientific and technical services' → 'Professional, scientific and technical services'\n\n\nData Formatting\n\n# Trim whitespace in string fields\ntext_cols = ['business_name', 'city', 'industry_sector','region','type']\ndf[text_cols] = df[text_cols].apply(lambda x: x.str.strip())\n\nSave the Cleaned data\n\n# Save cleaned data\ndf.to_csv(\"cleaned_indigenous_businesses.csv\", index=False)\n\nValidation of Cleaned Data\n\n# Validate cleaned data\nclean_data= pd.read_csv(\"cleaned_indigenous_businesses.csv\")\nprint(f\"Final cleaned dataset rows: {len(clean_data)}\")  # Final row count\nclean_data.head()\n\nFinal cleaned dataset rows: 1259\n\n\n\n\n\n\n\n\n\nbusiness_name\ncity\nlatitude\nlongitude\nregion\ntype\nindustry_sector\nyear_formed\nnumber_of_employees\n\n\n\n\n0\nEllipsis Energy Inc\nMoberly Lake\n55.819370\n-121.834602\nNortheast\nPrivate Company\nMining, quarrying, and oil and gas extraction\n2012.0\n5 to 9\n\n\n1\nIndigenous Community Development & Prosperity ...\nEnderby\n50.551498\n-119.133546\nThompson / Okanagan\nPrivate Company\nOther services (except public administration)\n2020.0\n1 to 4\n\n\n2\nFormline Construction Ltd.\nBurnaby\n49.266050\n123.005840\nLower Mainland / Southwest\nPrivate Company\nConstruction\n2021.0\n1 to 4\n\n\n3\nQuilakwa Investments Ltd.\nEnderby\n50.537507\n-119.141955\nThompson / Okanagan\nCommunity Owned Company\nAccommodation and food services\n1984.0\n20 to 49\n\n\n4\nQuilakwa Esso\nEnderby\n50.537507\n-119.141955\nThompson / Okanagan\nCommunity Owned Company\nRetail trade\n1984.0\n10 to 19"
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html",
    "href": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html",
    "title": "Gender marker change - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Gender marker change” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nDescribes the legislation status of the right to change legal gender. This is the legal recognition of sex reassignment by permitting a change of legal gender on an individual’s birth certificate. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Gender marker change” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#csv-structure",
    "title": "Gender marker change - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#metadata.json-structure",
    "title": "Gender marker change - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#about-the-data",
    "title": "Gender marker change - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#gender-marker-change",
    "href": "data/raw/LGBTIQ-rights/right-to-change-legal-gender/readme.html#gender-marker-change",
    "title": "Gender marker change - Data package",
    "section": "",
    "text": "Describes the legislation status of the right to change legal gender. This is the legal recognition of sex reassignment by permitting a change of legal gender on an individual’s birth certificate. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Gender marker change” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html",
    "href": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html",
    "title": "Public spending on education as a share of GDP - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Public spending on education as a share of GDP” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nTotal general government expenditure on education (all levels of government and all levels of education), given as a share of GDP. Last updated: November 4, 2024\nNext update: November 2025\nDate range: 1870–2023\nUnit: %\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nWorld Bank (2024); Tanzi & Schuknecht (2000) – processed by Our World in Data\n\n\n\nWorld Bank (2024); Tanzi & Schuknecht (2000) – processed by Our World in Data. “Public spending on education as a share of GDP” [dataset]. World Bank, “World Bank Education Statistics (EdStats)”; Tanzi & Schuknecht, “Public Expenditure on Education OECD” [original data]. Source: World Bank (2024), Tanzi & Schuknecht (2000) – processed by Our World In Data\n\n\n\n\n\n\n\n\n\nRetrieved on: 2024-11-04\nRetrieved from: https://datacatalog.worldbank.org/search/dataset/0038480/education-statistics\n\n\n\nRetrieved on: 2017-09-30\nRetrieved from: https://link.springer.com/article/10.1023%2FA%3A1017578302202?LI=true\n\n\n\nHistorical expenditure data:\nHistorical data in this dataset is based on a wide array of sources, reflecting a comprehensive approach to data collection across different time periods and regions. However, the diverse nature of these sources leads to inconsistencies, as methodologies and data quality vary between sources. For instance, older sources like the League of Nations Statistical Yearbook or Mitchell’s 1962 data may use different metrics or collection methods compared to more modern sources like the OECD Education reports or UN surveys. This variance in source material and methodology means that direct comparisons across different years or countries might be challenging, necessitating careful interpretation and cross-reference for accuracy. The dataset serves as a rich historical repository but also underscores the complexities and challenges inherent in compiling and harmonizing historical data from multiple, diverse sources.\nRecent estimates:\nGeneral government expenditure on education (current, capital, and transfers) is expressed as a percentage of GDP. It includes expenditure funded by transfers from international sources to government. General government usually refers to local, regional and central governments.\nWorld Bank variable id: SE.XPD.TOTL.GD.ZS\nOriginal source: UNESCO Institute for Statistics (UIS). UIS.Stat Bulk Data Download Service. Accessed October 24, 2022."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#csv-structure",
    "title": "Public spending on education as a share of GDP - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#metadata.json-structure",
    "title": "Public spending on education as a share of GDP - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#about-the-data",
    "title": "Public spending on education as a share of GDP - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#public-spending-on-education-as-a-share-of-gdp",
    "href": "data/raw/LGBTIQ-rights/government-expenditure-on-education/readme.html#public-spending-on-education-as-a-share-of-gdp",
    "title": "Public spending on education as a share of GDP - Data package",
    "section": "",
    "text": "Total general government expenditure on education (all levels of government and all levels of education), given as a share of GDP. Last updated: November 4, 2024\nNext update: November 2025\nDate range: 1870–2023\nUnit: %\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nWorld Bank (2024); Tanzi & Schuknecht (2000) – processed by Our World in Data\n\n\n\nWorld Bank (2024); Tanzi & Schuknecht (2000) – processed by Our World in Data. “Public spending on education as a share of GDP” [dataset]. World Bank, “World Bank Education Statistics (EdStats)”; Tanzi & Schuknecht, “Public Expenditure on Education OECD” [original data]. Source: World Bank (2024), Tanzi & Schuknecht (2000) – processed by Our World In Data\n\n\n\n\n\n\n\n\n\nRetrieved on: 2024-11-04\nRetrieved from: https://datacatalog.worldbank.org/search/dataset/0038480/education-statistics\n\n\n\nRetrieved on: 2017-09-30\nRetrieved from: https://link.springer.com/article/10.1023%2FA%3A1017578302202?LI=true\n\n\n\nHistorical expenditure data:\nHistorical data in this dataset is based on a wide array of sources, reflecting a comprehensive approach to data collection across different time periods and regions. However, the diverse nature of these sources leads to inconsistencies, as methodologies and data quality vary between sources. For instance, older sources like the League of Nations Statistical Yearbook or Mitchell’s 1962 data may use different metrics or collection methods compared to more modern sources like the OECD Education reports or UN surveys. This variance in source material and methodology means that direct comparisons across different years or countries might be challenging, necessitating careful interpretation and cross-reference for accuracy. The dataset serves as a rich historical repository but also underscores the complexities and challenges inherent in compiling and harmonizing historical data from multiple, diverse sources.\nRecent estimates:\nGeneral government expenditure on education (current, capital, and transfers) is expressed as a percentage of GDP. It includes expenditure funded by transfers from international sources to government. General government usually refers to local, regional and central governments.\nWorld Bank variable id: SE.XPD.TOTL.GD.ZS\nOriginal source: UNESCO Institute for Statistics (UIS). UIS.Stat Bulk Data Download Service. Accessed October 24, 2022."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html",
    "href": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html",
    "title": "GDP per capita - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “GDP per capita” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nAverage economic output per person in a country or region per year. This data is adjusted for inflation and for differences in living costs between countries. Last updated: January 24, 2025\nNext update: January 2026\nDate range: 1990–2023\nUnit: international-$ in 2021 prices\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nData compiled from multiple sources by World Bank (2025) – with minor processing by Our World in Data\n\n\n\nData compiled from multiple sources by World Bank (2025) – with minor processing by Our World in Data. “GDP per capita – World Bank – In constant international-$” [dataset]. Data compiled from multiple sources by World Bank, “World Development Indicators” [original data]. Source: Data compiled from multiple sources by World Bank (2025) – with minor processing by Our World In Data\n\n\n\n\n\nGross domestic product (GDP) is a measure of the total value added from the production of goods and services in a country or region each year. GDP per capita is GDP divided by population.\nThis GDP per capita indicator provides information on economic growth and income levels from 1990.\nThis data is adjusted for inflation and for differences in living costs between countries.\nThis data is expressed in international-$ at 2021 prices.\nFor GDP per capita estimates in the long run, explore the Maddison Project Database’s indicator.\n\n\n\n\nGDP per capita based on purchasing power parity (PPP). PPP GDP is gross domestic product converted to international dollars using purchasing power parity rates. An international dollar has the same purchasing power over GDP as the U.S. dollar has in the United States. GDP at purchaser’s prices is the sum of gross value added by all resident producers in the country plus any product taxes and minus any subsidies not included in the value of the products. It is calculated without making deductions for depreciation of fabricated assets or for depletion and degradation of natural resources. Data are in constant 2021 international dollars.\nStatistical concept and methodology: For the concept and methodology of PPP, please refer to the International Comparison Program (ICP)’s website (https://www.worldbank.org/en/programs/icp).\n\n\n\n\n\nRetrieved on: 2025-01-24\nRetrieved from: https://datacatalog.worldbank.org/search/dataset/0037712/World-Development-Indicators"
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#csv-structure",
    "title": "GDP per capita - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#metadata.json-structure",
    "title": "GDP per capita - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#about-the-data",
    "title": "GDP per capita - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#gdp-per-capita-in-constant-international--world-bank",
    "href": "data/raw/LGBTIQ-rights/gdp-per-capita/readme.html#gdp-per-capita-in-constant-international--world-bank",
    "title": "GDP per capita - Data package",
    "section": "",
    "text": "Average economic output per person in a country or region per year. This data is adjusted for inflation and for differences in living costs between countries. Last updated: January 24, 2025\nNext update: January 2026\nDate range: 1990–2023\nUnit: international-$ in 2021 prices\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nData compiled from multiple sources by World Bank (2025) – with minor processing by Our World in Data\n\n\n\nData compiled from multiple sources by World Bank (2025) – with minor processing by Our World in Data. “GDP per capita – World Bank – In constant international-$” [dataset]. Data compiled from multiple sources by World Bank, “World Development Indicators” [original data]. Source: Data compiled from multiple sources by World Bank (2025) – with minor processing by Our World In Data\n\n\n\n\n\nGross domestic product (GDP) is a measure of the total value added from the production of goods and services in a country or region each year. GDP per capita is GDP divided by population.\nThis GDP per capita indicator provides information on economic growth and income levels from 1990.\nThis data is adjusted for inflation and for differences in living costs between countries.\nThis data is expressed in international-$ at 2021 prices.\nFor GDP per capita estimates in the long run, explore the Maddison Project Database’s indicator.\n\n\n\n\nGDP per capita based on purchasing power parity (PPP). PPP GDP is gross domestic product converted to international dollars using purchasing power parity rates. An international dollar has the same purchasing power over GDP as the U.S. dollar has in the United States. GDP at purchaser’s prices is the sum of gross value added by all resident producers in the country plus any product taxes and minus any subsidies not included in the value of the products. It is calculated without making deductions for depreciation of fabricated assets or for depletion and degradation of natural resources. Data are in constant 2021 international dollars.\nStatistical concept and methodology: For the concept and methodology of PPP, please refer to the International Comparison Program (ICP)’s website (https://www.worldbank.org/en/programs/icp).\n\n\n\n\n\nRetrieved on: 2025-01-24\nRetrieved from: https://datacatalog.worldbank.org/search/dataset/0037712/World-Development-Indicators"
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html",
    "href": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html",
    "title": "Income inequality: Gini coefficient - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Income inequality: Gini coefficient” on the Our World in Data website.\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe remaining columns are the data columns, each of which is a time series. If the CSV data is downloaded using the “full data” option, then each column corresponds to one time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data columns are transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\nAll data and visualizations on Our World in Data rely on data sourced from one or several original data providers. Preparing this original data involves several processing steps. Depending on the data, this can include standardizing country names and world region definitions, converting units, calculating derived indicators such as per capita measures, as well as adding or adapting metadata such as the name or the description given to an indicator. Read about our data pipeline\n\n\n\n\n\n\n\nThe Gini coefficient measures inequality on a scale from 0 to 1. Higher values indicate higher inequality. Last updated: October 7, 2024\nNext update: May 2025\nDate range: 1963–2023\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nWorld Bank Poverty and Inequality Platform (2024) – with major processing by Our World in Data\n\n\n\nWorld Bank Poverty and Inequality Platform (2024) – with major processing by Our World in Data. “Gini Coefficient – World Bank” [dataset]. World Bank Poverty and Inequality Platform, “World Bank Poverty and Inequality Platform (PIP) 20240627_2017, 20240627_2011” [original data]. Source: World Bank Poverty and Inequality Platform (2024) – with major processing by Our World In Data\n\n\n\n\n\nDepending on the country and year, the data relates to income measured after taxes and benefits, or to consumption, per capita. ‘Per capita’ means that the income of each household is attributed equally to each member of the household (including children).\nNon-market sources of income, including food grown by subsistence farmers for their own consumption, are taken into account.\n\n\n\n\n\n\nRetrieved on: 2024-10-07\nRetrieved from: https://pip.worldbank.org\n\n\n\nFor most countries in the PIP dataset, estimates relate to either disposable income or consumption, for all available years. A number of countries, however, have a mix of income and consumption data points, with both data types sometimes available for particular years.\nIn most of our charts, we present the data with some data points dropped in order to present single series for each country. This allows us to make readable visualizations that combine multiple countries and metrics. In choosing which data points to drop, we try to strike a balance between maintaining comparability over time and showing as long a time series as possible. As such, the exact approach varies somewhat across countries.\nIf you would like to see the original data with all available income and consumption data points shown separately, you can do so in our Poverty Data Explorer. You can also download this data in our complete dataset of the World Bank PIP data."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#csv-structure",
    "title": "Income inequality: Gini coefficient - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe remaining columns are the data columns, each of which is a time series. If the CSV data is downloaded using the “full data” option, then each column corresponds to one time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data columns are transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#metadata.json-structure",
    "title": "Income inequality: Gini coefficient - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#about-the-data",
    "title": "Income inequality: Gini coefficient - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\nAll data and visualizations on Our World in Data rely on data sourced from one or several original data providers. Preparing this original data involves several processing steps. Depending on the data, this can include standardizing country names and world region definitions, converting units, calculating derived indicators such as per capita measures, as well as adding or adapting metadata such as the name or the description given to an indicator. Read about our data pipeline"
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#gini-coefficient-world-bank",
    "href": "data/raw/LGBTIQ-rights/economic-inequality-gini-index/readme.html#gini-coefficient-world-bank",
    "title": "Income inequality: Gini coefficient - Data package",
    "section": "",
    "text": "The Gini coefficient measures inequality on a scale from 0 to 1. Higher values indicate higher inequality. Last updated: October 7, 2024\nNext update: May 2025\nDate range: 1963–2023\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nWorld Bank Poverty and Inequality Platform (2024) – with major processing by Our World in Data\n\n\n\nWorld Bank Poverty and Inequality Platform (2024) – with major processing by Our World in Data. “Gini Coefficient – World Bank” [dataset]. World Bank Poverty and Inequality Platform, “World Bank Poverty and Inequality Platform (PIP) 20240627_2017, 20240627_2011” [original data]. Source: World Bank Poverty and Inequality Platform (2024) – with major processing by Our World In Data\n\n\n\n\n\nDepending on the country and year, the data relates to income measured after taxes and benefits, or to consumption, per capita. ‘Per capita’ means that the income of each household is attributed equally to each member of the household (including children).\nNon-market sources of income, including food grown by subsistence farmers for their own consumption, are taken into account.\n\n\n\n\n\n\nRetrieved on: 2024-10-07\nRetrieved from: https://pip.worldbank.org\n\n\n\nFor most countries in the PIP dataset, estimates relate to either disposable income or consumption, for all available years. A number of countries, however, have a mix of income and consumption data points, with both data types sometimes available for particular years.\nIn most of our charts, we present the data with some data points dropped in order to present single series for each country. This allows us to make readable visualizations that combine multiple countries and metrics. In choosing which data points to drop, we try to strike a balance between maintaining comparability over time and showing as long a time series as possible. As such, the exact approach varies somewhat across countries.\nIf you would like to see the original data with all available income and consumption data points shown separately, you can do so in our Poverty Data Explorer. You can also download this data in our complete dataset of the World Bank PIP data."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html",
    "href": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html",
    "title": "Censorship of LGBT issues - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Censorship of LGBT issues” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nDescribes censorship or prohibition of discussing, promoting, or teaching LGBT+ topics in media, schools, and in the general public. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Censorship of LGBT+ issues” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#csv-structure",
    "title": "Censorship of LGBT issues - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#metadata.json-structure",
    "title": "Censorship of LGBT issues - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#about-the-data",
    "title": "Censorship of LGBT issues - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#censorship-of-lgbt-issues",
    "href": "data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/readme.html#censorship-of-lgbt-issues",
    "title": "Censorship of LGBT issues - Data package",
    "section": "",
    "text": "Describes censorship or prohibition of discussing, promoting, or teaching LGBT+ topics in media, schools, and in the general public. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Censorship of LGBT+ issues” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html",
    "href": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html",
    "title": "Employment discrimination based on sexual orientation or gender identity - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Employment discrimination based on sexual orientation or gender identity” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nDescribes the prohibition of discrimination based on sexual orientation and/or gender identity in employment, including hiring, promotion, termination, harassment, etc. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1981–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Employment discrimination based on sexual orientation or gender identity prohibited” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#csv-structure",
    "title": "Employment discrimination based on sexual orientation or gender identity - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#metadata.json-structure",
    "title": "Employment discrimination based on sexual orientation or gender identity - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#about-the-data",
    "title": "Employment discrimination based on sexual orientation or gender identity - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#employment-discrimination-based-on-sexual-orientation-or-gender-identity-prohibited",
    "href": "data/raw/LGBTIQ-rights/employment-discrimination/readme.html#employment-discrimination-based-on-sexual-orientation-or-gender-identity-prohibited",
    "title": "Employment discrimination based on sexual orientation or gender identity - Data package",
    "section": "",
    "text": "Describes the prohibition of discrimination based on sexual orientation and/or gender identity in employment, including hiring, promotion, termination, harassment, etc. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1981–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Employment discrimination based on sexual orientation or gender identity prohibited” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html",
    "href": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html",
    "title": "Gender-affirming care - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Gender-affirming care” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nInterventions to help transgender and non-binary people align their bodies with their gender identity. This can include hormone replacement therapy, surgeries, or psychological support. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Gender-affirming care” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#csv-structure",
    "title": "Gender-affirming care - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#metadata.json-structure",
    "title": "Gender-affirming care - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#about-the-data",
    "title": "Gender-affirming care - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#gender-affirming-care",
    "href": "data/raw/LGBTIQ-rights/gender-affirming-care/readme.html#gender-affirming-care",
    "title": "Gender-affirming care - Data package",
    "section": "",
    "text": "Interventions to help transgender and non-binary people align their bodies with their gender identity. This can include hormone replacement therapy, surgeries, or psychological support. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Gender-affirming care” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html",
    "href": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html",
    "title": "Marriage for same-sex partners - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Marriage for same-sex partners” on the Our World in Data website. It was downloaded on April 16, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nDescribes the legislation status of same-sex marriage. This is marriage and marriage recognition between two people of the same biological sex and/or gender identity. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Marriage for same-sex partners” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#csv-structure",
    "href": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#csv-structure",
    "title": "Marriage for same-sex partners - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#metadata.json-structure",
    "href": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#metadata.json-structure",
    "title": "Marriage for same-sex partners - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#about-the-data",
    "href": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#about-the-data",
    "title": "Marriage for same-sex partners - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#marriage-for-same-sex-partners",
    "href": "data/raw/LGBTIQ-rights/marriage-same-sex-partners/readme.html#marriage-for-same-sex-partners",
    "title": "Marriage for same-sex partners - Data package",
    "section": "",
    "text": "Describes the legislation status of same-sex marriage. This is marriage and marriage recognition between two people of the same biological sex and/or gender identity. Last updated: April 7, 2025\nNext update: April 2026\nDate range: 1950–2025\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nEqualdex (2025) – with major processing by Our World in Data\n\n\n\nEqualdex (2025) – with major processing by Our World in Data. “Marriage for same-sex partners” [dataset]. Equaldex, “Equaldex” [original data]. Source: Equaldex (2025) – with major processing by Our World In Data\n\n\n\n\n\n\nRetrieved on: 2025-04-07\nRetrieved from: https://www.equaldex.com/\n\n\n\n\nWe have extracted the data from the official Equaldex JSON API.\nWe combine the historical and current data extracted from the API to create a time series.\nWhenever policy implementation dates for a status are not provided in the data, and this status is the only available for the country, we consider that this status has not changed during the entire period of the dataset.\nWe group some of the categories the source has defined for each issue, for further clarity in our visualizations.\nWe present this data only for sovereign states, defined by Butcher and Griffiths (2020). We use the definitions of the latest year available."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Diverse Data Hub is an open educational resource offering curated datasets focused on equity, diversity, inclusion, and other socially relevant topics. It is designed to support students, educators, and researchers in accessing and working with meaningful data in their teaching, learning, and analysis.\nDatasets are available through the diversedata R package, allowing for straightforward integration into data science workflows. Each dataset includes detailed documentation and contextual background to support informed exploration and connection to real-world topics. Example case studies are also included to illustrate practical applications.\nGet Started →"
  },
  {
    "objectID": "index.html#featured-datasets",
    "href": "index.html#featured-datasets",
    "title": "Diverse Data Hub",
    "section": "Featured Datasets",
    "text": "Featured Datasets\n\n\n\n\n\n\nWomen’s March Madness\n\n\nDescription: This data set tracks every NCAA Division I Women’s Basketball Tournament appearance since 1982 up until 2018. It includes team seeds, results, bid types, season and conference records, and regional placements. Useful for analyzing team success, seeding impact, conference strength, and historical trends in women’s college basketball over four decades.\n\nMore Details\n\n\n\n\nWildfire\n\n\nDescription: This data set on Canadian wildfires includes data on fire size, cause, location, detection method, response, and weather. Collected from official sources, it supports wildfire risk assessment and response. It also highlights social and geographic disparities, emphasizing impacts on remote and underserved communities facing climate-related and infrastructure challenges.\n\nMore Details\n\n\n\n\n\nHow Couples Meet and Stay Together\n\n\nDescription: This data set contains information from a 2022 survey of people across the U.S. to understand how couples meet and stay together. It focuses on how relationships were influenced by the COVID-19 pandemic and offers insight at modern relationships, including changes in dating habits and how couples adapted during a challenging time.\n\nMore Details\n\n\n\n\nIndigenous Businesses\n\n\nDescription: XXX\n\nMore Details\n\n\n\n\nGender Assessment\n\n\nDescription: XXX\n\nMore Details\n\n\n\n\nGlobal Rights\n\n\nDescription: XXX\n\nMore Details"
  },
  {
    "objectID": "scripts/gender_assessment_clean.html",
    "href": "scripts/gender_assessment_clean.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Gender Assessment data cleaning\n\nimport pandas as pd\n\n\n# Load the dataset\ndf = pd.read_csv(\"../data/raw/gender-assessment/gender_assessment.csv\")\n\n\n# Inspect the data\nprint(df.info())\nprint(f\"Initial number of rows: {len(df)}\") \n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2000 entries, 0 to 1999\nData columns (total 79 columns):\n #   Column                                                                                                                                                                                                                                                                                                                                                               Non-Null Count  Dtype  \n---  ------                                                                                                                                                                                                                                                                                                                                                               --------------  -----  \n 0   WBA ID                                                                                                                                                                                                                                                                                                                                                               2000 non-null   object \n 1   Company Name                                                                                                                                                                                                                                                                                                                                                         2000 non-null   object \n 2   HQ Country                                                                                                                                                                                                                                                                                                                                                           2000 non-null   object \n 3   HQ Region                                                                                                                                                                                                                                                                                                                                                            2000 non-null   object \n 4   ISIN                                                                                                                                                                                                                                                                                                                                                                 1475 non-null   object \n 5   WBA Industry                                                                                                                                                                                                                                                                                                                                                         1995 non-null   object \n 6   Ownership                                                                                                                                                                                                                                                                                                                                                            1996 non-null   object \n 7   Year assessed                                                                                                                                                                                                                                                                                                                                                        2000 non-null   int64  \n 8   Overall Gender Assessment Score                                                                                                                                                                                                                                                                                                                                      2000 non-null   float64\n 9   Percentage of Total Possible Score \n(out of 52.3)                                                                                                                                                                                                                                                                                                                    2000 non-null   int64  \n 10  A01. Strategic action                                                                                                                                                                                                                                                                                                                                                2000 non-null   int64  \n 11  A01.EA The company made a public commitment to gender equality and women’s empowerment (e.g. signatory to the UN Women’s Empowerment Principles, or having made another public commitment at CEO level).                                                                                                                                                             2000 non-null   object \n 12  A02. Gender targets                                                                                                                                                                                                                                                                                                                                                  2000 non-null   int64  \n 13  A02.EA The company discloses one or more time-bound targets on gender equality and women’s empowerment with regard to its workplace.                                                                                                                                                                                                                                 2000 non-null   object \n 14  A02.EC The company discloses one or more time-bound targets on gender equality and women’s empowerment with regard  to its supply chain.                                                                                                                                                                                                                             2000 non-null   object \n 15  A04. Gender-responsive human rights due diligence process                                                                                                                                                                                                                                                                                                            2000 non-null   int64  \n 16  A04.EA The company discloses what gender-related human rights impacts it has assessed and prioritised as being salient (i.e. most severe and potentially irremediable if not addressed).                                                                                                                                                                             2000 non-null   object \n 17  A04.EB The company consults with women or women's groups as part of the risk identification and assessment process.                                                                                                                                                                                                                                                  2000 non-null   object \n 18  A05. Grievance mechanisms                                                                                                                                                                                                                                                                                                                                            2000 non-null   float64\n 19  A05.EA The company has a gender-responsive mechanism through which employees can report grievances.                                                                                                                                                                                                                                                                  2000 non-null   object \n 20  A05.EB The company has one or more channel(s)/mechanism(s), or participates in a shared mechanism, accessible to all external individuals and communities who may be adversely impacted by the company (or individuals or organisations acting on their behalf or who are otherwise in a position to be aware of adverse impacts), to raise complaints or concerns.  2000 non-null   object \n 21  A05.EC The company collects, analyses and monitors sex-disaggregated grievance data (e.g. number of grievances reported, number of grievances remediated).                                                                                                                                                                                                           2000 non-null   object \n 22  A06. Stakeholder engagement                                                                                                                                                                                                                                                                                                                                          2000 non-null   int64  \n 23  A06.EA The company does employee surveys or other engagement mechanisms that specifically address gender equality & women’s empowerment issues.                                                                                                                                                                                                                      2000 non-null   object \n 24  A07. Corrective action process                                                                                                                                                                                                                                                                                                                                       2000 non-null   float64\n 25  A07.EA The company screens for gender-related issues among its suppliers as part of its audit process. Can score Partially Met for .5.                                                                                                                                                                                                                               2000 non-null   object \n 26  A07.EB The company identifies any gender-related issues as requiring corrective action to be taken by a supplier within a set period of time in order to remediate the issue.                                                                                                                                                                                        2000 non-null   object \n 27  B01. Gender equality in leadership                                                                                                                                                                                                                                                                                                                                   2000 non-null   int64  \n 28  B01.EA The company maintains a gender balance (between 40-60%) at the highest governance body.                                                                                                                                                                                                                                                                       2000 non-null   object \n 29  B01.EB The company maintains a gender balance (between 40-60%) at the senior executive level.                                                                                                                                                                                                                                                                        2000 non-null   object \n 30  B01.EC The company maintains a gender balance (between 40-60%) at the senior management level.                                                                                                                                                                                                                                                                       2000 non-null   object \n 31  B01.ED The company maintains a gender balance (between 40-60%) at the middle/other management level.                                                                                                                                                                                                                                                                 2000 non-null   object \n 32  B02. Professional development and recruitment                                                                                                                                                                                                                                                                                                                        2000 non-null   int64  \n 33  B02.EA The company offers professional development programmes (e.g. mentoring programme(s), leadership coaching, access to internal and/or external professional networks, educational programs, and formal sponsorship programmes.                                                                                                                                  2000 non-null   object \n 34  B02.EB The company tracks the number of women who are participating in these programmes.                                                                                                                                                                                                                                                                             2000 non-null   object \n 35  B03. Sex-disaggregated employee data                                                                                                                                                                                                                                                                                                                                 2000 non-null   int64  \n 36  B03.EA The company collects sex-disaggregated data on the gender balance of its employees by occupational function.                                                                                                                                                                                                                                                  2000 non-null   object \n 37  B03.EB The company collects sex-disaggregated data on the percentage of employees promoted.                                                                                                                                                                                                                                                                          2000 non-null   object \n 38  B03.EC The company collects sex-disaggregated data on the annual turnover of employees.                                                                                                                                                                                                                                                                              2000 non-null   object \n 39  B03.ED The company collect sex-disaggregated data on the annual absenteeism levels of employees.                                                                                                                                                                                                                                                                     2000 non-null   object \n 40  B04. Gender equality leadership in the supply chain                                                                                                                                                                                                                                                                                                                  2000 non-null   int64  \n 41  B04.EA The company collects or requires its suppliers to collect sex-disaggregated data by leadership level across the supply chain.                                                                                                                                                                                                                                 2000 non-null   object \n 42  B06. Enabling environment for freedom of association and collective bargaining                                                                                                                                                                                                                                                                                       2000 non-null   int64  \n 43  B06.EB The company describes how it supports the practices of its business relationships in relation to freedom of association and collective bargaining.                                                                                                                                                                                                            2000 non-null   object \n 44  B07. Gender-responsive procurement                                                                                                                                                                                                                                                                                                                                   2000 non-null   int64  \n 45  B07.EA The company made a public commitment to gender-responsive procurement.                                                                                                                                                                                                                                                                                        2000 non-null   object \n 46  B07.EB The company procures from women-owned businesses.                                                                                                                                                                                                                                                                                                             2000 non-null   object \n 47  C01. Gender pay gap                                                                                                                                                                                                                                                                                                                                                  2000 non-null   int64  \n 48  C01.EA The company collects sex-disaggregated pay data.                                                                                                                                                                                                                                                                                                              2000 non-null   object \n 49  C01.EB The company collects sex-disaggregated pay data by different pay bands, occupational functions, or other financial benefits.                                                                                                                                                                                                                                  2000 non-null   object \n 50  C01.EC The company uses a third party to undertake/verify its pay gap analysis.                                                                                                                                                                                                                                                                                      2000 non-null   object \n 51  C02. Paid primary and secondary carer leave                                                                                                                                                                                                                                                                                                                          2000 non-null   float64\n 52  C02.EA The company has a global policy of providing at least 14 weeks of paid primary carer leave offered to full-time employees.                                                                                                                                                                                                                                    2000 non-null   object \n 53  C02.EB The company monitors the return-to-work rate of employees after primary carer leave and their retention a year after primary carer leave.                                                                                                                                                                                                                     2000 non-null   object \n 54  C02.EC The company has a global policy of providing at least two weeks of paid secondary carer leave offered to full-time employees.                                                                                                                                                                                                                                 2000 non-null   object \n 55  C02.ED The company tracks the number of workers who take secondary carer leave.                                                                                                                                                                                                                                                                                      2000 non-null   object \n 56  C03. Childcare and other family support                                                                                                                                                                                                                                                                                                                              2000 non-null   int64  \n 57  C03.EA The company offers childcare support to employees.                                                                                                                                                                                                                                                                                                            2000 non-null   object \n 58  C03.EB The company offers other family support to its employees.                                                                                                                                                                                                                                                                                                     2000 non-null   object \n 59  C04. Flexible work                                                                                                                                                                                                                                                                                                                                                   2000 non-null   int64  \n 60  C04.EA The company offers flexible working hours to its employees (the ability to alter the start and end of the day).                                                                                                                                                                                                                                               2000 non-null   object \n 61  C04.EB The company collects sex-disaggregated data on the number of employees who have flexible working hour arrangements.                                                                                                                                                                                                                                           2000 non-null   object \n 62  C04.EC The company offers flexible work locations to its employees (the ability to work from home/telecommuting).                                                                                                                                                                                                                                                    2000 non-null   object \n 63  C04.ED The company collects sex-disaggregated data on the number of employees who have flexible work location arrangements.                                                                                                                                                                                                                                          2000 non-null   object \n 64  C06. Living wage in the supply chain                                                                                                                                                                                                                                                                                                                                 2000 non-null   int64  \n 65  C06.EA The company requires its suppliers to pay their workers a living wage.                                                                                                                                                                                                                                                                                        2000 non-null   object \n 66  C06.EB The company takes specific actions to help ensure its suppliers pay their workers a living wage.                                                                                                                                                                                                                                                              2000 non-null   object \n 67  D01. Health, safety and well-being in the workplace                                                                                                                                                                                                                                                                                                                  2000 non-null   float64\n 68  D01.EA The company has a publicly available policy statement committing it to respect the health and safety of its employees.                                                                                                                                                                                                                                        2000 non-null   object \n 69  D01.EB The company discloses sex-disaggregated information on health and safety for its employees.                                                                                                                                                                                                                                                                   2000 non-null   object \n 70  D01.EC The company provides coverage of the costs associated with any of the following health information and services: maternal health, sexual and reproductive health, and mental health. It has to provide more than two different services for a full score. Partially met if only one service is provided.                                                      2000 non-null   object \n 71  D02. Safe and healthy work in the supply chain                                                                                                                                                                                                                                                                                                                       2000 non-null   int64  \n 72  D02.EA The company has a publicly available statement of policy that expects its business relationships to commit to respecting the health and safety of their workers.                                                                                                                                                                                              2000 non-null   object \n 73  D02.EC The company discloses how it monitors the health and safety performance of its business relationships.                                                                                                                                                                                                                                                        2000 non-null   object \n 74  E01. Violence and harassment prevention                                                                                                                                                                                                                                                                                                                              2000 non-null   float64\n 75  E01.EA The company has publicly available policies in place regarding violence and harassment in the workplace (e.g., zero tolerance policy, safe transport policy, etc.). Can score Partially Met for .5.                                                                                                                                                           2000 non-null   object \n 76  E02. Violence and harassment remediation                                                                                                                                                                                                                                                                                                                             2000 non-null   float64\n 77  E02.EA The company has a remediation process for addressing violence and harassment grievances in the workplace. Can score Partially Met for .5.                                                                                                                                                                                                                     2000 non-null   object \n 78  E02.EB The company collects, analyses and monitors sex-disaggregated data on the remediation of violence and harassment grievances.                                                                                                                                                                                                                                  2000 non-null   object \ndtypes: float64(7), int64(17), object(55)\nmemory usage: 1.2+ MB\nNone\nInitial number of rows: 2000\n\n\n\n# Choosing only indicator scores and removing element scores\n#Drop columns with values only in ['Met', 'Unmet', 'Partially Met']\ncolumns_to_drop = []\nfor col in df.columns:\n    unique_vals = df[col].dropna().unique()\n    if all(val in ['Met', 'Unmet', 'Partially Met'] for val in unique_vals):\n        columns_to_drop.append(col)\n\n#WBA ID and ISIN are not required in the analysis so removing\ncolumns_to_drop.extend(['WBA ID', 'ISIN'])\n                       \ndf = df.drop(columns=columns_to_drop)\n\n\n# Drop rows with missing values in critical columns\ndf = df.dropna(subset=[\"Company Name \", \"HQ Country\", \"Overall Gender Assessment Score\"])\n\n\n#  Clean column names (convert to lowercase and replace spaces with underscores)\ndf.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n\n\n# Rename long column names to shorter ones\nrename_map = {\n    'company_name': 'company',\n    'hq_country': 'country',\n    'hq_region': 'region',\n    'wba_industry': 'industry',\n    'year_assessed': 'year',\n    'overall_gender_assessment_score': 'score',\n    'percentage_of_total_possible_score_\\n(out_of_52.3)': 'percent_score',\n    \"a01._strategic_action\": \"strategic_action\",\n    \"a02._gender_targets\": \"gender_targets\",\n    \"a04._gender-responsive_human_rights_due_diligence_process\": \"gender_due_diligence\",\n    \"a05._grievance_mechanisms\": \"grievance_mechanisms\",\n    \"a06._stakeholder_engagement\": \"stakeholder_engagement\",\n    \"a07._corrective_action_process\": \"corrective_action\",\n    \"b01._gender_equality_in_leadership\": \"gender_leadership\",\n    \"b02._professional_development_and_recruitment\": \"development_recruitment\",\n    \"b03._sex-disaggregated_employee_data\": \"employee_data_by_sex\",\n    \"b04._gender_equality_leadership_in_the_supply_chain\": \"supply_chain_gender_leadership\",\n    \"b06._enabling_environment_for_freedom_of_association_and_collective_bargaining\": \"enabling_environment_union_rights\",\n    \"b07._gender-responsive_procurement\": \"gender_procurement\",\n    \"c01._gender_pay_gap\": \"gender_pay_gap\",\n    \"c02._paid_primary_and_secondary_carer_leave\": \"carer_leave_paid\",\n    'c03._childcare_and_other_family_support': 'childcare_support',\n    'c04._flexible_work': 'flex_work',\n    'c06._living_wage_in_the_supply_chain': 'living_wage_supply_chain',\n    'd01._health,_safety_and_well-being_in_the_workplace': 'health_safety',\n    'd02._safe_and_healthy_work_in_the_supply_chain': 'health_safety_supply_chain',\n    'e01._violence_and_harassment_prevention': 'violence_prevention',\n    'e02._violence_and_harassment_remediation': 'violence_remediation'\n}\n\n# Apply renaming\ndf = df.rename(columns=rename_map)\n\n\n# Ensure 'score' and 'percent_score' are numeric\ndf['score'] = pd.to_numeric(df['score'], errors='coerce')\ndf['percent_score'] = pd.to_numeric(df['percent_score'], errors='coerce')\n\n\n# Remove duplicates\ndf = df.drop_duplicates()\n\n\n# Save cleaned file\ndf.to_csv(\"../data/clean/gender_assessment_clean.csv\", index=False)\n\n\n# Validate cleaned data\nclean_data= pd.read_csv(\"../data/clean/gender_assessment_clean.csv\")\nprint(f\"Final cleaned dataset rows: {len(clean_data)}\")  # Final row count\nclean_data.head()\n\nFinal cleaned dataset rows: 2000\n\n\n\n\n\n\n\n\n\ncompany\ncountry\nregion\nindustry\nownership\nyear\nscore\npercent_score\nstrategic_action\ngender_targets\n...\ngender_procurement\ngender_pay_gap\ncarer_leave_paid\nchildcare_support\nflex_work\nliving_wage_supply_chain\nhealth_safety\nhealth_safety_supply_chain\nviolence_prevention\nviolence_remediation\n\n\n\n\n0\n3M\nUnited States\nNorth America\nChemicals\nPublic\n2023\n11.3\n22\n1\n0\n...\n1\n0\n0.0\n0\n2\n0\n1.0\n2\n1.0\n0.0\n\n\n1\nAsos\nUnited Kingdom\nEurope & Central Asia\nApparel & Footwear\nPublic\n2023\n16.9\n32\n1\n0\n...\n0\n0\n0.0\n1\n1\n2\n0.5\n2\n0.5\n0.0\n\n\n2\nA.P. Moller - Maersk\nDenmark\nEurope & Central Asia\nFreight & logistics\nPublic\n2024\n10.9\n21\n1\n1\n...\n0\n0\n0.0\n0\n0\n0\n1.0\n2\n1.0\n0.0\n\n\n3\nABB\nSwitzerland\nEurope & Central Asia\nCapital Goods\nPublic\n2023\n12.8\n25\n1\n1\n...\n0\n0\n1.0\n0\n0\n0\n1.0\n2\n1.0\n0.0\n\n\n4\nAbbVie\nUnited States\nNorth America\nPharmaceuticals & Biotechnology\nPublic\n2023\n15.4\n30\n1\n0\n...\n1\n0\n0.0\n2\n1\n0\n1.0\n2\n1.0\n0.0\n\n\n\n\n5 rows × 29 columns"
  },
  {
    "objectID": "scripts/LGBTIQ-rights_clean.html",
    "href": "scripts/LGBTIQ-rights_clean.html",
    "title": "LGBTIQ-rights Dataset Cleaning Steps",
    "section": "",
    "text": "First, we will examine how many unique years and countries are included across the different datasets."
  },
  {
    "objectID": "scripts/LGBTIQ-rights_clean.html#lgbtiq-specific-datasets",
    "href": "scripts/LGBTIQ-rights_clean.html#lgbtiq-specific-datasets",
    "title": "LGBTIQ-rights Dataset Cleaning Steps",
    "section": "",
    "text": "First, we will examine how many unique years and countries are included across the different datasets."
  },
  {
    "objectID": "scripts/LGBTIQ-rights_clean.html#python-code-to-analyze-each-dataset",
    "href": "scripts/LGBTIQ-rights_clean.html#python-code-to-analyze-each-dataset",
    "title": "LGBTIQ-rights Dataset Cleaning Steps",
    "section": "Python Code to Analyze Each Dataset",
    "text": "Python Code to Analyze Each Dataset\n\nimport pandas as pd\n\n# Function to summarize unique years and countries\ndef summarize_years_and_countries(df, dataset_name):\n    return pd.DataFrame({\n        \"Dataset\": [dataset_name],\n        \"Unique Years\": [df[\"Year\"].nunique()],\n        \"Unique Countries\": [df[\"Entity\"].nunique()]\n    })\n\n\n\n# Censorship of LGBTIQ Issues\ndf_censorship = pd.read_csv(\"../data/raw/LGBTIQ-rights/censorship-of-lgbtiq-issues/censorship-of-lgbtiq-issues.csv\")\ncensorship_summary = summarize_years_and_countries(df_censorship, \"Censorship of LGBTIQ Issues\")\n\n# Employment Discrimination\ndf_employment_discrimination = pd.read_csv(\"../data/raw/LGBTIQ-rights/employment-discrimination/employment-discrimination-lgbt-equaldex.csv\")\nemployment_discrimination_summary = summarize_years_and_countries(df_employment_discrimination, \"Employment Discrimination\")\n\n# Economic Inequality (Gini Index)\ndf_gini = pd.read_csv(\"../data/raw/LGBTIQ-rights/economic-inequality-gini-index/economic-inequality-gini-index.csv\")\n\ngini_summary = summarize_years_and_countries(df_gini, \"Economic Inequality (Gini Index)\")\n\n# GDP per Capita\ndf_gdp = pd.read_csv(\"../data/raw/LGBTIQ-rights/gdp-per-capita/gdp-per-capita-worldbank.csv\")\ngdp_summary = summarize_years_and_countries(df_gdp, \"GDP per Capita\")\n\n# Government Expenditure on Education\ndf_education = pd.read_csv(\"../data/raw/LGBTIQ-rights/government-expenditure-on-education/total-government-expenditure-on-education-gdp.csv\")\neducation_summary = summarize_years_and_countries(df_education, \"Government Education Expenditure\")\n\n# Gender-Affirming Care\ndf_gender_care = pd.read_csv(\"../data/raw/LGBTIQ-rights/gender-affirming-care/gender-affirming-care.csv\")\ngender_care_summary = summarize_years_and_countries(df_gender_care, \"Gender-Affirming Care\")\n\n# Same-Sex Marriage Rights\ndf_marriage = pd.read_csv(\"../data/raw/LGBTIQ-rights/marriage-same-sex-partners/marriage-same-sex-partners-equaldex.csv\")\nmarriage_summary = summarize_years_and_countries(df_marriage, \"Same-Sex Marriage\")\n\n# Legal Gender Change Rights\ndf_legal_gender = pd.read_csv(\"../data/raw/LGBTIQ-rights/right-to-change-legal-gender/right-to-change-legal-gender-equaldex.csv\")\nlegal_gender_summary = summarize_years_and_countries(df_legal_gender, \"Legal Gender Change\")\n\ndef summarize_countries_per_year(df, dataset_name):\n    return (\n        df.groupby(\"Year\")[\"Entity\"]\n        .nunique()\n        .reset_index(name=\"num_countries\")\n        .assign(Dataset=dataset_name)\n    )\n\n\n\ncensorship_summary = summarize_countries_per_year(df_censorship, \"Censorship of LGBTIQ Issues\")\nemployment_summary = summarize_countries_per_year(df_employment_discrimination, \"Employment Discrimination\")\ngini_summary = summarize_countries_per_year(df_gini, \"Economic Inequality (Gini Index)\")\ngdp_summary = summarize_countries_per_year(df_gdp, \"GDP per Capita\")\neducation_summary = summarize_countries_per_year(df_education, \"Government Education Expenditure\")\ngender_care_summary = summarize_countries_per_year(df_gender_care, \"Gender-Affirming Care\")\nmarriage_summary = summarize_countries_per_year(df_marriage, \"Same-Sex Marriage\")\nlegal_gender_summary = summarize_countries_per_year(df_legal_gender, \"Legal Gender Change\")\n\n# Combine\nsummary_all = pd.concat([\n    censorship_summary,\n    employment_summary,\n    gini_summary,\n    gdp_summary,\n    education_summary,\n    gender_care_summary,\n    marriage_summary,\n    legal_gender_summary\n], ignore_index=True)\n\n# Pivot\nsummary_pivot = summary_all.pivot_table(\n    index=\"Dataset\",\n    columns=\"Year\",\n    values=\"num_countries\",\n    fill_value=0\n).reset_index()\n\nsummary_pivot\n\n\n\n\n\n\n\nYear\nDataset\n1870\n1913\n1937\n1950\n1951\n1952\n1953\n1954\n1955\n...\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n2024\n2025\n\n\n\n\n0\nCensorship of LGBTIQ Issues\n0.0\n0.0\n0.0\n4.0\n4.0\n4.0\n4.0\n4.0\n4.0\n...\n34.0\n37.0\n37.0\n40.0\n41.0\n43.0\n46.0\n48.0\n50.0\n194.0\n\n\n1\nEconomic Inequality (Gini Index)\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n87.0\n83.0\n96.0\n82.0\n70.0\n75.0\n28.0\n4.0\n0.0\n0.0\n\n\n2\nEmployment Discrimination\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n63.0\n66.0\n73.0\n78.0\n81.0\n84.0\n86.0\n87.0\n88.0\n183.0\n\n\n3\nGDP per Capita\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n213.0\n213.0\n213.0\n213.0\n213.0\n213.0\n212.0\n206.0\n0.0\n0.0\n\n\n4\nGender-Affirming Care\n0.0\n0.0\n0.0\n9.0\n9.0\n9.0\n9.0\n9.0\n9.0\n...\n66.0\n67.0\n70.0\n71.0\n75.0\n76.0\n79.0\n81.0\n83.0\n164.0\n\n\n5\nGovernment Education Expenditure\n5.0\n8.0\n11.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n184.0\n187.0\n182.0\n184.0\n181.0\n180.0\n149.0\n66.0\n0.0\n0.0\n\n\n6\nLegal Gender Change\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n...\n87.0\n91.0\n95.0\n98.0\n98.0\n98.0\n102.0\n103.0\n103.0\n194.0\n\n\n7\nSame-Sex Marriage\n0.0\n0.0\n0.0\n12.0\n13.0\n13.0\n14.0\n14.0\n14.0\n...\n126.0\n128.0\n131.0\n134.0\n135.0\n135.0\n135.0\n138.0\n138.0\n194.0\n\n\n\n\n8 rows × 80 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = summary_all.copy()\nprint(df)\n\n     Year  num_countries                      Dataset\n0    1950              4  Censorship of LGBTIQ Issues\n1    1951              4  Censorship of LGBTIQ Issues\n2    1952              4  Censorship of LGBTIQ Issues\n3    1953              4  Censorship of LGBTIQ Issues\n4    1954              4  Censorship of LGBTIQ Issues\n..    ...            ...                          ...\n497  2021             98          Legal Gender Change\n498  2022            102          Legal Gender Change\n499  2023            103          Legal Gender Change\n500  2024            103          Legal Gender Change\n501  2025            194          Legal Gender Change\n\n[502 rows x 3 columns]\n\n\n\nimport matplotlib.pyplot as plt\n\nfor dataset in df[\"Dataset\"].unique():\n    subset = df[df[\"Dataset\"] == dataset]\n\n    if subset[\"num_countries\"].notna().sum() == 0:\n        print(f\"Skipping {dataset} – all values are null\")\n        continue\n\n    plt.figure(figsize=(8, 4))\n    plt.plot(subset[\"Year\"], subset[\"num_countries\"], marker='o', linestyle='-')\n    plt.title(f\"Non-Null Value Count per Year – {dataset}\")\n    plt.xlabel(\"Year\")\n    plt.ylabel(\"Count of countries that has data\")\n    plt.xticks(rotation=45)\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## So based on the result, I think after 2000, we have an acceptable number of countries that have data ( all of them at least have 50 coountires after this year with the valid data)\n## So I filter the dataset for after 2000, please let me know if you want to change this\n## This frame would be our base table for our left join \n## summary_all\n\n\n## I've noticed that for some csv files. we do not have code, so I just want to left join on Year and Country\n\ncolumns_to_check = [\"Year\", \"Entity\", \"Code\"]\n\ndataframes = {\n    \"df_censorship\": df_censorship,\n    \"df_employment_discrimination\": df_employment_discrimination,\n    \"df_gini\": df_gini,\n    \"df_gdp\": df_gdp,\n    \"df_education\": df_education,\n    \"df_gender_care\": df_gender_care,\n    \"df_marriage\": df_marriage,\n    \"df_legal_gender\": df_legal_gender,\n}\n\nfor name, df in dataframes.items():\n    print(f\"\\n{name} - Nulls in Key Columns:\")\n    for col in columns_to_check:\n        if col in df.columns:\n            null_count = df[col].isnull().sum()\n            print(f\"  {col}: {null_count} null(s)\")\n        else:\n            print(f\"  {col}: Column not found\")\n\n\ndf_censorship - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 0 null(s)\n\ndf_employment_discrimination - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 0 null(s)\n\ndf_gini - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 133 null(s)\n\ndf_gdp - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 458 null(s)\n\ndf_education - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 428 null(s)\n\ndf_gender_care - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 0 null(s)\n\ndf_marriage - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 0 null(s)\n\ndf_legal_gender - Nulls in Key Columns:\n  Year: 0 null(s)\n  Entity: 0 null(s)\n  Code: 0 null(s)\n\n\n\n# First, I combined all datasets into one long DataFrame \n## Please notice that stacking all the rows from these datasets on top of each other\nall_data = pd.concat([\n    df_censorship[[\"Entity\", \"Code\", \"Year\"]],\n    df_employment_discrimination[[\"Entity\",\"Code\", \"Year\"]],\n    df_gini[[\"Entity\",\"Code\", \"Year\"]],\n    df_gdp[[\"Entity\",\"Code\", \"Year\"]],\n    df_education[[\"Entity\",\"Code\", \"Year\"]],\n    df_gender_care[[\"Entity\",\"Code\", \"Year\"]],\n    df_marriage[[\"Entity\",\"Code\", \"Year\"]],\n    df_legal_gender[[\"Entity\",\"Code\", \"Year\"]],\n], ignore_index=True)\n\n##\n## Show rows where 'Code' is null\nnull_code_rows = all_data[all_data[\"Code\"].isna()]\nprint(null_code_rows)\n\n                                Entity Code  Year\n3108                 Argentina (urban)  NaN  1980\n3109                 Argentina (urban)  NaN  1986\n3110                 Argentina (urban)  NaN  1987\n3111                 Argentina (urban)  NaN  1991\n3112                 Argentina (urban)  NaN  1992\n...                                ...  ...   ...\n18012  Western and Central Africa (WB)  NaN  2018\n18013  Western and Central Africa (WB)  NaN  2019\n18014  Western and Central Africa (WB)  NaN  2020\n18015  Western and Central Africa (WB)  NaN  2021\n18016  Western and Central Africa (WB)  NaN  2022\n\n[1019 rows x 3 columns]\n\n\n\nimport pandas as pd\n\n## Create a mapping from Entity → Code using non-null values\nentity_to_code_map = (\n    all_data[all_data[\"Code\"].notna()]\n    .drop_duplicates(subset=\"Entity\")\n    .set_index(\"Entity\")[\"Code\"]\n    .to_dict()\n)\n\n## Create lists to store matched and unmatched entity names\nmatched_entities = []\nunmatched_entities = []\n\n## Fill missing codes and track matches\ndef fill_code_and_track(row):\n    if pd.isna(row[\"Code\"]):\n        matched_code = entity_to_code_map.get(row[\"Entity\"])\n        if matched_code is not None:\n            matched_entities.append(row[\"Entity\"])\n            return matched_code\n        else:\n            unmatched_entities.append(row[\"Entity\"])\n            return None\n    return row[\"Code\"]\n\nall_data[\"Code\"] = all_data.apply(fill_code_and_track, axis=1)\n\n## Remove duplicates from tracking lists\nmatched_entities = sorted(set(matched_entities))\nunmatched_entities = sorted(set(unmatched_entities))\n\nprint(\"✅ Finished filling missing Code values.\")\nprint(f\"✅ {len(matched_entities)} entities were successfully matched:\")\nfor entity in matched_entities:\n    print(\"  ✓\", entity)\n\nprint(\"\\n❗ Entities with no Code found:\")\nfor entity in unmatched_entities:\n    print(\"  ✗\", entity)\n\nprint(f\"\\n🧮 Remaining rows with missing Code: {all_data['Code'].isna().sum()}\")\n## As we can see for these countries, we do not have code, please let mw know, what should we do for them \n\n✅ Finished filling missing Code values.\n✅ 0 entities were successfully matched:\n\n❗ Entities with no Code found:\n  ✗ Arab World (WB)\n  ✗ Argentina (urban)\n  ✗ Bolivia (urban)\n  ✗ Central Europe and the Baltics (WB)\n  ✗ China (rural)\n  ✗ China (urban)\n  ✗ Colombia (urban)\n  ✗ EU (27)\n  ✗ East Asia and Pacific (WB)\n  ✗ East Asia and the Pacific (WB)\n  ✗ Ecuador (urban)\n  ✗ Ethiopia (rural)\n  ✗ Europe and Central Asia (WB)\n  ✗ European Union (27)\n  ✗ Faeroe Islands\n  ✗ High-income countries\n  ✗ Honduras (urban)\n  ✗ India (rural)\n  ✗ India (urban)\n  ✗ Latin America and Caribbean (WB)\n  ✗ Low-income countries\n  ✗ Lower-middle-income countries\n  ✗ Micronesia (country) (urban)\n  ✗ Middle East and North Africa (WB)\n  ✗ Middle-income countries\n  ✗ North America (WB)\n  ✗ Rwanda (rural)\n  ✗ South Asia (WB)\n  ✗ Southern and Eastern Africa (WB)\n  ✗ Sub-Saharan Africa (WB)\n  ✗ Suriname (urban)\n  ✗ Upper-middle-income countries\n  ✗ Uruguay (urban)\n  ✗ Western and Central Africa (WB)\n\n🧮 Remaining rows with missing Code: 1019\n\n\n\n## So I just created my base table based on Year and Country and filtered it out for Year &gt; 2000  and &lt;= 2023\nfiltered_data = all_data[(all_data[\"Year\"] &gt; 2000) & (all_data[\"Year\"] &lt;= 2023)]\nbase_table = filtered_data[[\"Year\", \"Entity\", \"Code\"]].drop_duplicates()\nbase_table = base_table.sort_values(by=[\"Year\", \"Entity\"]).reset_index(drop=True)\nbase_table\n\n\n\n\n\n\n\n\nYear\nEntity\nCode\n\n\n\n\n0\n2001\nAfghanistan\nAFG\n\n\n1\n2001\nAlbania\nALB\n\n\n2\n2001\nAlgeria\nDZA\n\n\n3\n2001\nAndorra\nAND\n\n\n4\n2001\nAngola\nAGO\n\n\n...\n...\n...\n...\n\n\n5265\n2023\nVietnam\nVNM\n\n\n5266\n2023\nWorld\nOWID_WRL\n\n\n5267\n2023\nYemen\nYEM\n\n\n5268\n2023\nZambia\nZMB\n\n\n5269\n2023\nZimbabwe\nZWE\n\n\n\n\n5270 rows × 3 columns\n\n\n\n\nmerged_wide_df = base_table.copy()\ndatasets = {\n    \"censorship\": df_censorship,\n    \"employment\": df_employment_discrimination,\n    \"gini\": df_gini,\n    \"gdp\": df_gdp,\n    \"education\": df_education,\n    \"gendercare\": df_gender_care,\n    \"marriage\": df_marriage,\n    \"legalgender\": df_legal_gender,\n}\n\n\nfor name, df in datasets.items():\n\n    value_cols = [col for col in df.columns if col not in [\"Entity\", \"Year\"]]\n    df_renamed = df.rename(columns={col: f\"{col}_{name}\" for col in value_cols})\n    merged_wide_df = merged_wide_df.merge(\n        df_renamed,\n        on=[\"Entity\", \"Year\"],\n        how=\"left\"\n    )\n\nprint(\"Final shape:\", merged_wide_df.shape)\n\nFinal shape: (5270, 20)\n\n\n\nmerged_wide_df.head()\n\n\n\n\n\n\n\n\nYear\nEntity\nCode\nCode_censorship\nCensorship of LGBT+ issues (historical)_censorship\nCode_employment\nLGBT+ employment discrimination (historical)_employment\nCode_gini\nGini coefficient_gini\n990179-annotations_gini\nCode_gdp\nGDP per capita, PPP (constant 2021 international $)_gdp\nCode_education\nPublic spending on education as a share of GDP_education\nCode_gendercare\nGender-affirming care (historical)_gendercare\nCode_marriage\nSame-sex marriage (historical)_marriage\nCode_legalgender\nRight to change legal gender (historical)_legalgender\n\n\n\n\n0\n2001\nAfghanistan\nAFG\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAFG\n1454.1108\nNaN\nNaN\nNaN\nNaN\nAFG\nBanned\nNaN\nNaN\n\n\n1\n2001\nAlbania\nALB\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nALB\n7215.8200\nALB\n3.4587\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n2001\nAlgeria\nDZA\nDZA\nImprisonment as punishment\nNaN\nNaN\nNaN\nNaN\nNaN\nDZA\n11742.5950\nNaN\nNaN\nNaN\nNaN\nDZA\nBanned\nNaN\nNaN\n\n\n3\n2001\nAndorra\nAND\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAND\n59109.0160\nNaN\nNaN\nAND\nRestricted\nNaN\nNaN\nNaN\nNaN\n\n\n4\n2001\nAngola\nAGO\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAGO\n6049.1630\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nprint(\"Long format shape:\", merged_wide_df.shape)\n\nLong format shape: (5270, 20)\n\n\n\nlist(merged_wide_df.columns)\n\n['Year',\n 'Entity',\n 'Code',\n 'Code_censorship',\n 'Censorship of LGBT+ issues (historical)_censorship',\n 'Code_employment',\n 'LGBT+ employment discrimination (historical)_employment',\n 'Code_gini',\n 'Gini coefficient_gini',\n '990179-annotations_gini',\n 'Code_gdp',\n 'GDP per capita, PPP (constant 2021 international $)_gdp',\n 'Code_education',\n 'Public spending on education as a share of GDP_education',\n 'Code_gendercare',\n 'Gender-affirming care (historical)_gendercare',\n 'Code_marriage',\n 'Same-sex marriage (historical)_marriage',\n 'Code_legalgender',\n 'Right to change legal gender (historical)_legalgender']\n\n\n\n# Drop all columns that start with 'Code_'\nmerged_wide_df = merged_wide_df.loc[:, ~merged_wide_df.columns.str.contains(\"Code_\")]\nlist(merged_wide_df.columns)\n\n['Year',\n 'Entity',\n 'Code',\n 'Censorship of LGBT+ issues (historical)_censorship',\n 'LGBT+ employment discrimination (historical)_employment',\n 'Gini coefficient_gini',\n '990179-annotations_gini',\n 'GDP per capita, PPP (constant 2021 international $)_gdp',\n 'Public spending on education as a share of GDP_education',\n 'Gender-affirming care (historical)_gendercare',\n 'Same-sex marriage (historical)_marriage',\n 'Right to change legal gender (historical)_legalgender']\n\n\n\nexclude_cols = [\"Entity\", \"Year\"]\nvalue_cols = merged_wide_df.columns.difference(exclude_cols)\ncleaned_long_df = merged_wide_df.dropna(subset=value_cols, how='all').reset_index(drop=True)\nprint(\"Shape after cleaning:\", cleaned_long_df.shape)\ncleaned_long_df\n\nShape after cleaning: (5270, 12)\n\n\n\n\n\n\n\n\n\nYear\nEntity\nCode\nCensorship of LGBT+ issues (historical)_censorship\nLGBT+ employment discrimination (historical)_employment\nGini coefficient_gini\n990179-annotations_gini\nGDP per capita, PPP (constant 2021 international $)_gdp\nPublic spending on education as a share of GDP_education\nGender-affirming care (historical)_gendercare\nSame-sex marriage (historical)_marriage\nRight to change legal gender (historical)_legalgender\n\n\n\n\n0\n2001\nAfghanistan\nAFG\nNaN\nNaN\nNaN\nNaN\n1454.1108\nNaN\nNaN\nBanned\nNaN\n\n\n1\n2001\nAlbania\nALB\nNaN\nNaN\nNaN\nNaN\n7215.8200\n3.4587\nNaN\nNaN\nNaN\n\n\n2\n2001\nAlgeria\nDZA\nImprisonment as punishment\nNaN\nNaN\nNaN\n11742.5950\nNaN\nNaN\nBanned\nNaN\n\n\n3\n2001\nAndorra\nAND\nNaN\nNaN\nNaN\nNaN\n59109.0160\nNaN\nRestricted\nNaN\nNaN\n\n\n4\n2001\nAngola\nAGO\nNaN\nNaN\nNaN\nNaN\n6049.1630\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5265\n2023\nVietnam\nVNM\nNaN\nNaN\nNaN\nNaN\n13491.8800\nNaN\nLegal\nBanned\nLegal, surgery required\n\n\n5266\n2023\nWorld\nOWID_WRL\nNaN\nNaN\nNaN\nNaN\n20670.9410\nNaN\nNaN\nNaN\nNaN\n\n\n5267\n2023\nYemen\nYEM\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nBanned\nNaN\n\n\n5268\n2023\nZambia\nZMB\nImprisonment as punishment\nNaN\nNaN\nNaN\n3673.4841\nNaN\nNaN\nBanned\nNaN\n\n\n5269\n2023\nZimbabwe\nZWE\nImprisonment as punishment\nNaN\nNaN\nNaN\n3442.2512\nNaN\nNaN\nBanned\nNaN\n\n\n\n\n5270 rows × 12 columns\n\n\n\n\ncleaned_long_df.tail()\n\n\n\n\n\n\n\n\nYear\nEntity\nCode\nCensorship of LGBT+ issues (historical)_censorship\nLGBT+ employment discrimination (historical)_employment\nGini coefficient_gini\n990179-annotations_gini\nGDP per capita, PPP (constant 2021 international $)_gdp\nPublic spending on education as a share of GDP_education\nGender-affirming care (historical)_gendercare\nSame-sex marriage (historical)_marriage\nRight to change legal gender (historical)_legalgender\n\n\n\n\n5265\n2023\nVietnam\nVNM\nNaN\nNaN\nNaN\nNaN\n13491.8800\nNaN\nLegal\nBanned\nLegal, surgery required\n\n\n5266\n2023\nWorld\nOWID_WRL\nNaN\nNaN\nNaN\nNaN\n20670.9410\nNaN\nNaN\nNaN\nNaN\n\n\n5267\n2023\nYemen\nYEM\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nBanned\nNaN\n\n\n5268\n2023\nZambia\nZMB\nImprisonment as punishment\nNaN\nNaN\nNaN\n3673.4841\nNaN\nNaN\nBanned\nNaN\n\n\n5269\n2023\nZimbabwe\nZWE\nImprisonment as punishment\nNaN\nNaN\nNaN\n3442.2512\nNaN\nNaN\nBanned\nNaN\n\n\n\n\n\n\n\n\nprint(cleaned_long_df.columns.tolist())\n\n['Year', 'Entity', 'Code', 'Censorship of LGBT+ issues (historical)_censorship', 'LGBT+ employment discrimination (historical)_employment', 'Gini coefficient_gini', '990179-annotations_gini', 'GDP per capita, PPP (constant 2021 international $)_gdp', 'Public spending on education as a share of GDP_education', 'Gender-affirming care (historical)_gendercare', 'Same-sex marriage (historical)_marriage', 'Right to change legal gender (historical)_legalgender']\n\n\n\ncleaned_long_df.columns = (\n    cleaned_long_df.columns\n    .str.replace(\"Entity\", \"country\", regex=False)\n    .str.replace(\"Year\", \"year\", regex=False)\n    .str.replace(\"Code\", \"country-code\", regex=False)\n    .str.replace(\"Censorship of LGBT+ issues (historical)_censorship\", \"lgbtq-censorship\", regex=False)\n    .str.replace(\"LGBT+ employment discrimination (historical)_employment\", \"employment-discrimination\", regex=False)\n    .str.replace(\"Gini coefficient_gini\", \"gini-index\", regex=False)\n    .str.replace(\"GDP per capita, PPP (constant 2021 international $)_gdp\", \"gdp-per-capita\", regex=False)\n    .str.replace(\"Public spending on education as a share of GDP_education\", \"education-spending-gdp\", regex=False)\n    .str.replace(\"Gender-affirming care (historical)_gendercare\", \"gender-affirming-care\", regex=False)\n    .str.replace(\"Same-sex marriage (historical)_marriage\", \"same-sex-marriage\", regex=False)\n    .str.replace(\"Right to change legal gender (historical)_legalgender\", \"legal-gender\", regex=False)\n)\n\n\ncleaned_long_df\n\n\n\n\n\n\n\n\nyear\ncountry\ncountry-code\nlgbtq-censorship\nemployment-discrimination\ngini-index\n990179-annotations_gini\ngdp-per-capita\neducation-spending-gdp\ngender-affirming-care\nsame-sex-marriage\nlegal-gender\n\n\n\n\n0\n2001\nAfghanistan\nAFG\nNaN\nNaN\nNaN\nNaN\n1454.1108\nNaN\nNaN\nBanned\nNaN\n\n\n1\n2001\nAlbania\nALB\nNaN\nNaN\nNaN\nNaN\n7215.8200\n3.4587\nNaN\nNaN\nNaN\n\n\n2\n2001\nAlgeria\nDZA\nImprisonment as punishment\nNaN\nNaN\nNaN\n11742.5950\nNaN\nNaN\nBanned\nNaN\n\n\n3\n2001\nAndorra\nAND\nNaN\nNaN\nNaN\nNaN\n59109.0160\nNaN\nRestricted\nNaN\nNaN\n\n\n4\n2001\nAngola\nAGO\nNaN\nNaN\nNaN\nNaN\n6049.1630\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5265\n2023\nVietnam\nVNM\nNaN\nNaN\nNaN\nNaN\n13491.8800\nNaN\nLegal\nBanned\nLegal, surgery required\n\n\n5266\n2023\nWorld\nOWID_WRL\nNaN\nNaN\nNaN\nNaN\n20670.9410\nNaN\nNaN\nNaN\nNaN\n\n\n5267\n2023\nYemen\nYEM\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nBanned\nNaN\n\n\n5268\n2023\nZambia\nZMB\nImprisonment as punishment\nNaN\nNaN\nNaN\n3673.4841\nNaN\nNaN\nBanned\nNaN\n\n\n5269\n2023\nZimbabwe\nZWE\nImprisonment as punishment\nNaN\nNaN\nNaN\n3442.2512\nNaN\nNaN\nBanned\nNaN\n\n\n\n\n5270 rows × 12 columns\n\n\n\n\nprint(cleaned_long_df.dtypes)\n\nyear                           int64\ncountry                       object\ncountry-code                  object\nlgbtq-censorship              object\nemployment-discrimination     object\ngini-index                   float64\n990179-annotations_gini      float64\ngdp-per-capita               float64\neducation-spending-gdp       float64\ngender-affirming-care         object\nsame-sex-marriage             object\nlegal-gender                  object\ndtype: object\n\n\n\nfloat_cols = cleaned_long_df.select_dtypes(include=[\"float64\"]).columns\ncleaned_long_df[float_cols] = cleaned_long_df[float_cols].round(2)\n\n\neda_summary = pd.DataFrame({\n    \"Non-Null Count\": cleaned_long_df.notnull().sum(),\n    \"Total Rows\": len(cleaned_long_df),\n    \"Non-Null %\": cleaned_long_df.notnull().mean() * 100,\n    \"Data Type\": cleaned_long_df.dtypes\n})\n\n\neda_summary = eda_summary.sort_values(by=\"Non-Null Count\", ascending=False)\neda_summary[\"Non-Null %\"] = eda_summary[\"Non-Null %\"].round(1)\neda_summary.reset_index(inplace=True)\neda_summary.rename(columns={\"index\": \"Column\"}, inplace=True)\n\n\neda_summary\n\n\n\n\n\n\n\n\nColumn\nNon-Null Count\nTotal Rows\nNon-Null %\nData Type\n\n\n\n\n0\nyear\n5270\n5270\n100.0\nint64\n\n\n1\ncountry\n5270\n5270\n100.0\nobject\n\n\n2\ngdp-per-capita\n4841\n5270\n91.9\nfloat64\n\n\n3\ncountry-code\n4772\n5270\n90.6\nobject\n\n\n4\neducation-spending-gdp\n3601\n5270\n68.3\nfloat64\n\n\n5\nsame-sex-marriage\n2560\n5270\n48.6\nobject\n\n\n6\nlegal-gender\n1703\n5270\n32.3\nobject\n\n\n7\ngini-index\n1664\n5270\n31.6\nfloat64\n\n\n8\ngender-affirming-care\n1414\n5270\n26.8\nobject\n\n\n9\nemployment-discrimination\n1225\n5270\n23.2\nobject\n\n\n10\nlgbtq-censorship\n720\n5270\n13.7\nobject\n\n\n11\n990179-annotations_gini\n0\n5270\n0.0\nfloat64\n\n\n\n\n\n\n\n\n## Again Dropping some columns based on Non-Null %\ncolumns_to_drop = ['990179-annotations_gini']\ncleaned_long_df = cleaned_long_df.drop(columns=columns_to_drop)\n\n\n## One more time checking the columns \neda_summary = pd.DataFrame({\n    \"Non-Null Count\": cleaned_long_df.notnull().sum(),\n    \"Total Rows\": len(cleaned_long_df),\n    \"Non-Null %\": cleaned_long_df.notnull().mean() * 100,\n    \"Data Type\": cleaned_long_df.dtypes\n})\n\n\neda_summary = eda_summary.sort_values(by=\"Non-Null Count\", ascending=False)\neda_summary[\"Non-Null %\"] = eda_summary[\"Non-Null %\"].round(1)\neda_summary.reset_index(inplace=True)\neda_summary.rename(columns={\"index\": \"Column\"}, inplace=True)\n\n\neda_summary\n\n\n\n\n\n\n\n\nColumn\nNon-Null Count\nTotal Rows\nNon-Null %\nData Type\n\n\n\n\n0\nyear\n5270\n5270\n100.0\nint64\n\n\n1\ncountry\n5270\n5270\n100.0\nobject\n\n\n2\ngdp-per-capita\n4841\n5270\n91.9\nfloat64\n\n\n3\ncountry-code\n4772\n5270\n90.6\nobject\n\n\n4\neducation-spending-gdp\n3601\n5270\n68.3\nfloat64\n\n\n5\nsame-sex-marriage\n2560\n5270\n48.6\nobject\n\n\n6\nlegal-gender\n1703\n5270\n32.3\nobject\n\n\n7\ngini-index\n1664\n5270\n31.6\nfloat64\n\n\n8\ngender-affirming-care\n1414\n5270\n26.8\nobject\n\n\n9\nemployment-discrimination\n1225\n5270\n23.2\nobject\n\n\n10\nlgbtq-censorship\n720\n5270\n13.7\nobject\n\n\n\n\n\n\n\n\nprint(cleaned_long_df.columns.tolist())\n\n['year', 'country', 'country-code', 'lgbtq-censorship', 'employment-discrimination', 'gini-index', 'gdp-per-capita', 'education-spending-gdp', 'gender-affirming-care', 'same-sex-marriage', 'legal-gender']\n\n\n\n#3 Checking for each country, how many missing values we have for each column \nsummary = cleaned_long_df.groupby(\"country\").agg(\n    total_rows=(\"country\", \"size\"),\n    missing_gdp_per_capita=(\"gdp-per-capita\", lambda x: x.isna().sum()),\n    missing_same_sex_marriage=(\"same-sex-marriage\", lambda x: x.isna().sum()),\n    missing_legal_gender=(\"legal-gender\", lambda x: x.isna().sum()),\n    missing_lgbtq_censorship=(\"lgbtq-censorship\", lambda x: x.isna().sum()),\n    missing_employment_discrimination=(\"employment-discrimination\", lambda x: x.isna().sum()),\n    missing_gender_affirming_care=(\"gender-affirming-care\", lambda x: x.isna().sum())\n)\nsummary[\"missing_count\"] = (\n    summary[\"missing_gdp_per_capita\"]\n    + summary[\"missing_same_sex_marriage\"]\n    + summary[\"missing_same_sex_marriage\"] \n    + summary[\"missing_legal_gender\"]\n    + summary[\"missing_lgbtq_censorship\"]\n    + summary[\"missing_employment_discrimination\"]\n    + summary[\"missing_gender_affirming_care\"]\n    + summary[\"missing_legal_gender\"] \n)\n\nsummary_sorted = summary.sort_values(\"missing_count\", ascending=False)\nsummary_sorted[summary_sorted[\"missing_count\"] &gt; 100]   ###\n\n\n\n\n\n\n\n\ntotal_rows\nmissing_gdp_per_capita\nmissing_same_sex_marriage\nmissing_legal_gender\nmissing_lgbtq_censorship\nmissing_employment_discrimination\nmissing_gender_affirming_care\nmissing_count\n\n\ncountry\n\n\n\n\n\n\n\n\n\n\n\n\nWestern and Central Africa (WB)\n22\n22\n22\n22\n22\n22\n22\n176\n\n\nArgentina (urban)\n21\n21\n21\n21\n21\n21\n21\n168\n\n\nEU (27)\n21\n21\n21\n21\n21\n21\n21\n168\n\n\nCentral Europe and the Baltics (WB)\n21\n21\n21\n21\n21\n21\n21\n168\n\n\nBermuda\n23\n0\n23\n23\n23\n23\n23\n161\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nSint Maarten (Dutch part)\n15\n0\n15\n15\n15\n15\n15\n105\n\n\nAlbania\n23\n0\n2\n23\n23\n9\n23\n105\n\n\nGeorgia\n23\n0\n23\n0\n23\n13\n23\n105\n\n\nMalta\n23\n0\n13\n14\n23\n3\n23\n103\n\n\nCameroon\n23\n0\n0\n23\n9\n23\n23\n101\n\n\n\n\n140 rows × 8 columns\n\n\n\n\n## Based on the top table, some countries have missing values for almost all columns, so we are going to delete them instead of deleting the columns\ncountries_to_exclude = summary_sorted[summary_sorted[\"missing_count\"] &gt; 100].index.tolist()\ncleaned_long_df = cleaned_long_df[~cleaned_long_df[\"country\"].isin(countries_to_exclude)]\ncleaned_long_df = cleaned_long_df.reset_index(drop=True)\ncleaned_long_df.head()\n\n\n\n\n\n\n\n\nyear\ncountry\ncountry-code\nlgbtq-censorship\nemployment-discrimination\ngini-index\ngdp-per-capita\neducation-spending-gdp\ngender-affirming-care\nsame-sex-marriage\nlegal-gender\n\n\n\n\n0\n2001\nAlgeria\nDZA\nImprisonment as punishment\nNaN\nNaN\n11742.60\nNaN\nNaN\nBanned\nNaN\n\n\n1\n2001\nAndorra\nAND\nNaN\nNaN\nNaN\n59109.02\nNaN\nRestricted\nNaN\nNaN\n\n\n2\n2001\nArgentina\nARG\nNaN\nNaN\nNaN\n21066.46\n4.83\nNaN\nNaN\nNaN\n\n\n3\n2001\nArmenia\nARM\nNaN\nNaN\n0.35\n5044.12\n2.47\nLegal, but restricted for minors\nNaN\nLegal, surgery required\n\n\n4\n2001\nAustralia\nAUS\nVaries by region\nNaN\n0.33\n44667.93\n5.22\nLegal\nNaN\nVaries by region\n\n\n\n\n\n\n\n\n ## One more time checking the columns \neda_summary = pd.DataFrame({\n    \"Non-Null Count\": cleaned_long_df.notnull().sum(),\n    \"Total Rows\": len(cleaned_long_df),\n    \"Non-Null %\": cleaned_long_df.notnull().mean() * 100,\n    \"Data Type\": cleaned_long_df.dtypes\n})\n\n\neda_summary = eda_summary.sort_values(by=\"Non-Null Count\", ascending=False)\neda_summary[\"Non-Null %\"] = eda_summary[\"Non-Null %\"].round(1)\neda_summary.reset_index(inplace=True)\neda_summary.rename(columns={\"index\": \"Column\"}, inplace=True)\n\n\neda_summary\n\n\n\n\n\n\n\n\nColumn\nNon-Null Count\nTotal Rows\nNon-Null %\nData Type\n\n\n\n\n0\nyear\n2125\n2125\n100.0\nint64\n\n\n1\ncountry\n2125\n2125\n100.0\nobject\n\n\n2\ncountry-code\n2094\n2125\n98.5\nobject\n\n\n3\ngdp-per-capita\n2023\n2125\n95.2\nfloat64\n\n\n4\nsame-sex-marriage\n1700\n2125\n80.0\nobject\n\n\n5\neducation-spending-gdp\n1677\n2125\n78.9\nfloat64\n\n\n6\nlegal-gender\n1419\n2125\n66.8\nobject\n\n\n7\ngini-index\n1173\n2125\n55.2\nfloat64\n\n\n8\ngender-affirming-care\n1152\n2125\n54.2\nobject\n\n\n9\nemployment-discrimination\n988\n2125\n46.5\nobject\n\n\n10\nlgbtq-censorship\n521\n2125\n24.5\nobject\n\n\n\n\n\n\n\n\n# Desired column order\ncolumn_order = [\n    \"year\", \"country\", \"country-code\",\n    \"gdp-per-capita\", \"education-spending-gdp\",\n    \"same-sex-marriage\", \"lgbtq-censorship\",\n    \"employment-discrimination\", \"gender-affirming-care\",\n    \"legal-gender\"\n]\n\ncleaned_long_df = cleaned_long_df[column_order]\n\ncleaned_long_df.to_csv(\"../data/clean/globalrights.csv\", index=False)"
  },
  {
    "objectID": "scripts/wildfire_clean.html",
    "href": "scripts/wildfire_clean.html",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "",
    "text": "import pandas as pd\n\nwildfire = pd.read_csv(\"../data/raw/wildfire/wildfire.csv\")\nwildfire.head()\n\n\n\n\n\n\n\n\nYEAR\nFIRE_NUMBER\nFIRE_NAME\nCURRENT_SIZE\nSIZE_CLASS\nLATITUDE\nLONGITUDE\nFIRE_ORIGIN\nGENERAL_CAUSE\nINDUSTRY_IDENTIFIER\n...\nDISTANCE_FROM_WATER_SOURCE\nFIRST_BUCKET_DROP_DATE\nFIRST_BH_DATE\nFIRST_BH_SIZE\nFIRST_UC_DATE\nFIRST_UC_SIZE\nFIRST_TO_DATE\nFIRST_TO_SIZE\nFIRST_EX_DATE\nFIRST_EX_SIZE_PERIMETER\n\n\n\n\n0\n2006\nPWF001\nNaN\n0.10\nA\n56.249956\n-117.181960\nPrivate Land\nResident\nNaN\n...\nNaN\nNaN\n2006-04-02 22:00:00\n0.01\n2006-04-02 22:00:00\n0.01\nNaN\nNaN\n2006-04-03 10:20:00\n0.10\n\n\n1\n2006\nEWF002\nNaN\n0.20\nB\n53.606367\n-115.915733\nProvincial Land\nIncendiary\nNaN\n...\nNaN\nNaN\n2006-04-03 13:20:00\n0.20\n2006-04-03 13:20:00\n0.20\nNaN\nNaN\n2006-04-03 14:00:00\n0.20\n\n\n2\n2006\nEWF001\nNaN\n0.50\nB\n53.610933\n-115.594267\nProvincial Land\nIncendiary\nNaN\n...\nNaN\nNaN\n2006-04-03 13:23:00\n0.50\n2006-04-03 13:23:00\n0.50\nNaN\nNaN\n2006-04-03 15:00:00\n0.50\n\n\n3\n2006\nEWF003\nNaN\n0.01\nA\n53.608867\n-115.609467\nProvincial Land\nIncendiary\nNaN\n...\nNaN\nNaN\n2006-04-03 14:08:00\n0.01\n2006-04-03 14:08:00\n0.01\nNaN\nNaN\n2006-04-03 15:05:00\n0.01\n\n\n4\n2006\nPWF002\nNaN\n0.10\nA\n56.249956\n-117.050249\nProvincial Land\nOther Industry\nWaste Disposal\n...\nNaN\nNaN\n2006-04-03 19:57:00\n0.10\n2006-04-03 20:19:00\n0.10\n2006-04-03 20:20:00\n0.1\n2006-04-05 10:18:00\n0.10\n\n\n\n\n5 rows × 50 columns"
  },
  {
    "objectID": "scripts/wildfire_clean.html#drop-uninformative-or-very-sparse-columns",
    "href": "scripts/wildfire_clean.html#drop-uninformative-or-very-sparse-columns",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Drop uninformative or very sparse columns",
    "text": "Drop uninformative or very sparse columns\nThese columns have more than 50% missing values and we can remove them.\n\n## These columns are very sparse\n# FIRE_NAME                       25756\n# INDUSTRY_IDENTIFIER             26071\n# DISCOVERED_SIZE                 26402\n# DISTANCE_FROM_WATER_SOURCE      18958\n# FIRST_BUCKET_DROP_DATE          18957\n# FIRST_TO_DATE                   23809\n# FIRST_TO_SIZE                   23809\n\n\n\nwildfire = wildfire.drop(columns=[\n    \"FIRE_NAME\", \"INDUSTRY_IDENTIFIER\", \"DISCOVERED_SIZE\", \n    \"DISTANCE_FROM_WATER_SOURCE\", \"FIRST_BUCKET_DROP_DATE\", \"FIRST_TO_DATE\", \"FIRST_TO_SIZE\"\n], errors=\"ignore\")"
  },
  {
    "objectID": "scripts/wildfire_clean.html#handle-moderate-missing-values",
    "href": "scripts/wildfire_clean.html#handle-moderate-missing-values",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Handle moderate missing values",
    "text": "Handle moderate missing values\nThese are useful variables but have some missing data. We can fill with “unknown”, 0, or mean.\n\n# few missing\nwildfire[\"DISPATCHED_RESOURCE\"] = wildfire[\"DISPATCHED_RESOURCE\"].fillna(\"Unknown\")\nwildfire[\"DISPATCH_DATE\"] = pd.to_datetime(wildfire[\"DISPATCH_DATE\"], errors=\"coerce\") # I converted this column to date, and If a value can't be converted to a date (e.g., it's missing or malformed), it will be replaced with NaT\nwildfire[\"START_FOR_FIRE_DATE\"] = pd.to_datetime(wildfire[\"START_FOR_FIRE_DATE\"], errors=\"coerce\")\nwildfire[\"INITIAL_ACTION_BY\"] = wildfire[\"INITIAL_ACTION_BY\"].fillna(\"Unknown\")\nwildfire[\"FIRE_ORIGIN\"] = wildfire[\"INITIAL_ACTION_BY\"].fillna(\"Unknown\")\nwildfire[\"FIRST_EX_DATE\"] = pd.to_datetime(wildfire[\"FIRST_EX_DATE\"], errors=\"coerce\")\nwildfire[\"FIRST_EX_SIZE_PERIMETER\"] = wildfire[\"FIRST_EX_SIZE_PERIMETER\"].fillna(-1) # missing or unknown numeric data\n\n# Moderate missing\nwildfire[\"FIRE_START_DATE\"] = pd.to_datetime(wildfire[\"FIRE_START_DATE\"], errors=\"coerce\")\nwildfire[\"DISCOVERED_DATE\"] = pd.to_datetime(wildfire[\"DISCOVERED_DATE\"], errors=\"coerce\")\nwildfire[\"FIRE_SPREAD_RATE\"] = wildfire[\"FIRE_SPREAD_RATE\"].fillna(wildfire[\"FIRE_SPREAD_RATE\"].mean())  ## mean value\nwildfire[\"FIRE_POSITION_ON_SLOPE\"] = wildfire[\"FIRE_POSITION_ON_SLOPE\"].fillna(\"Unknown\")\nwildfire[\"WEATHER_CONDITIONS_OVER_FIRE\"] = wildfire[\"WEATHER_CONDITIONS_OVER_FIRE\"].fillna(\"Unknown\")\nwildfire[\"WIND_DIRECTION\"] = wildfire[\"WIND_DIRECTION\"].fillna(\"Unknown\")\nwildfire[\"FUEL_TYPE\"] = wildfire[\"FUEL_TYPE\"].fillna(\"Unknown\")\nwildfire[\"TRUE_CAUSE\"] = wildfire[\"TRUE_CAUSE\"].fillna(\"Unknown\") \nwildfire[\"FIRE_TYPE\"] = wildfire[\"FIRE_TYPE\"].fillna(\"Unknown\") \n\n# Higher missing \nwildfire[\"RESPONSIBLE_GROUP\"] = wildfire[\"RESPONSIBLE_GROUP\"].fillna(\"Unknown\")\nwildfire[\"ACTIVITY_CLASS\"] = wildfire[\"ACTIVITY_CLASS\"].fillna(\"Unknown\")\nwildfire[\"IA_ARRIVAL_AT_FIRE_DATE\"] = pd.to_datetime(wildfire[\"IA_ARRIVAL_AT_FIRE_DATE\"], errors=\"coerce\")\nwildfire[\"IA_ACCESS\"] = wildfire[\"IA_ACCESS\"].fillna(\"Unknown\")\nwildfire[\"FIRE_FIGHTING_START_DATE\"] = pd.to_datetime(wildfire[\"FIRE_FIGHTING_START_DATE\"], errors=\"coerce\")\nwildfire[\"FIRE_FIGHTING_START_SIZE\"] = wildfire[\"FIRE_FIGHTING_START_SIZE\"].fillna(wildfire[\"FIRE_FIGHTING_START_SIZE\"].median()) ## median value\nwildfire[\"BUCKETING_ON_FIRE\"] = wildfire[\"BUCKETING_ON_FIRE\"].fillna(\"Unknown\")\n\n\n\n\n## Double check everything one more time  --&gt; alll of the date columns now have NaT \nwildfire.isna().sum()\n## Please let me know about the other columns, like humidity or temperature and wind_s, what should we do \n\nYEAR                               0\nFIRE_NUMBER                        0\nCURRENT_SIZE                       0\nSIZE_CLASS                         0\nLATITUDE                           0\nLONGITUDE                          0\nFIRE_ORIGIN                        0\nGENERAL_CAUSE                      0\nRESPONSIBLE_GROUP                  0\nACTIVITY_CLASS                     0\nTRUE_CAUSE                         0\nFIRE_START_DATE                  693\nDETECTION_AGENT_TYPE               0\nDETECTION_AGENT                    0\nDISCOVERED_DATE                 5409\nREPORTED_DATE                      0\nDISPATCHED_RESOURCE                0\nDISPATCH_DATE                     12\nSTART_FOR_FIRE_DATE               17\nASSESSMENT_RESOURCE                0\nASSESSMENT_DATETIME                0\nASSESSMENT_HECTARES                0\nFIRE_SPREAD_RATE                   0\nFIRE_TYPE                          0\nFIRE_POSITION_ON_SLOPE             0\nWEATHER_CONDITIONS_OVER_FIRE       0\nTEMPERATURE                     2872\nRELATIVE_HUMIDITY               2878\nWIND_DIRECTION                     0\nWIND_SPEED                      2880\nFUEL_TYPE                          0\nINITIAL_ACTION_BY                  0\nIA_ARRIVAL_AT_FIRE_DATE         7703\nIA_ACCESS                          0\nFIRE_FIGHTING_START_DATE        7572\nFIRE_FIGHTING_START_SIZE           0\nBUCKETING_ON_FIRE                  0\nFIRST_BH_DATE                      0\nFIRST_BH_SIZE                      0\nFIRST_UC_DATE                      0\nFIRST_UC_SIZE                      0\nFIRST_EX_DATE                      6\nFIRST_EX_SIZE_PERIMETER            0\ndtype: int64"
  },
  {
    "objectID": "scripts/wildfire_clean.html#datetime",
    "href": "scripts/wildfire_clean.html#datetime",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Date/Time",
    "text": "Date/Time\n\ndate_cols = [\n    \"FIRE_START_DATE\", \"DISCOVERED_DATE\", \"REPORTED_DATE\", \"DISPATCH_DATE\",\n    \"START_FOR_FIRE_DATE\", \"IA_ARRIVAL_AT_FIRE_DATE\", \"FIRE_FIGHTING_START_DATE\", \"FIRST_BH_DATE\", \"FIRST_UC_DATE\",\n    \"FIRST_EX_DATE\", \"ASSESSMENT_DATETIME\"\n]\n\nfor col in date_cols:\n    wildfire[col] = pd.to_datetime(wildfire[col], errors=\"coerce\")\n\n## Format all float columns to 2 decimal places\n\nfloat_cols = wildfire.select_dtypes(include=[\"float64\"]).columns\nwildfire[float_cols] = wildfire[float_cols].round(2)"
  },
  {
    "objectID": "scripts/wildfire_clean.html#based-on-alberta-historical-wildfire-data-dictionary-20062024",
    "href": "scripts/wildfire_clean.html#based-on-alberta-historical-wildfire-data-dictionary-20062024",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Based on Alberta Historical Wildfire Data Dictionary (2006–2024)",
    "text": "Based on Alberta Historical Wildfire Data Dictionary (2006–2024)\n\n\n\n\n\n\n\nColumn Name\nOfficial Definition (From Data Dictionary)\n\n\n\n\nfire_start_date\nThe estimated or known time and date the wildfire began. May come from storm tracking, witness statements, or lightning map data.\n\n\ndiscovered_date\nThe time the detection agent first discovered the wildfire. May be blank for unplanned detections.\n\n\nreported_date\nThe time and date the wildfire was reported to Alberta Wildfire (usually when the detection agent contacts dispatch).\n\n\ndispatch_date\nThe date and time the first resource was dispatched to respond to the wildfire.\n\n\nstart_for_fire_date\nThe time and date the dispatched resource left for the wildfire, e.g., wheels roll, skids up, or vehicle departure.\n\n\nassessment_datetime\nThe date and time of the initial wildfire assessment, which determines the fire year.\n\n\nia_arrival_at_fire_date\nThe date and time the initial action resource arrived at the wildfire site.\n\n\nfire_fighting_start_date\nThe date and time suppression efforts began (e.g., digging firelines, water drops).\n\n\nfirst_bh_date\nThe date/time the wildfire status changed to Being Held (BH) — unlikely to spread further under current conditions.\n\n\nfirst_uc_date\nThe date/time the fire was declared Under Control (UC) — fire perimeter secured, no further spread expected.\n\n\nfirst_ex_date\nThe date/time the fire was declared Extinguished (EX) — fully out, no hot spots remaining."
  },
  {
    "objectID": "scripts/wildfire_clean.html#i-just-keep-these-date-columns-and-i-think-these-columns-are-most-informative",
    "href": "scripts/wildfire_clean.html#i-just-keep-these-date-columns-and-i-think-these-columns-are-most-informative",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "I just keep these date columns and I think these columns are most informative",
    "text": "I just keep these date columns and I think these columns are most informative\n\n## I keep these columns\n##   'fire_start_date',\n##   'discovered_date',\n##   'ia_arrival_at_fire_date',\n##   'fire_fighting_start_date',\n##   'first_bh_date',\n##   'first_uc_date',\n##   'first_ex_date'\n\n# I deleted these columns\ncols_to_delete = [\n  'reported_date',\n    'dispatch_date',\n    'start_for_fire_date',\n    'first_ex_date',\n    'discovered_date', \n    'assessment_datetime',\n    'dispatched_resource', ## This is not a date column, but it is not useful so I deleted it here\n    'assessment_resource' ## This is not date column but it is not usefull so I deleted here\n]\n\nwildfire = wildfire.drop(columns=cols_to_delete, errors='ignore')\nwildfire.head()\n\n\n\n\n\n\n\n\nyear\nfire_number\ncurrent_size\nsize_class\nlatitude\nlongitude\nfire_origin\ngeneral_cause\nresponsible_group\nactivity_class\n...\nia_arrival_at_fire_date\nia_access\nfire_fighting_start_date\nfire_fighting_start_size\nbucketing_on_fire\nfirst_bh_date\nfirst_bh_size\nfirst_uc_date\nfirst_uc_size\nfirst_ex_size_perimeter\n\n\n\n\n0\n2006\nPWF001\n0.10\nA\n56.25\n-117.18\nLand Owner\nResident\nResident\nGrass\n...\nNaT\nUnknown\nNaT\n0.02\nUnknown\n2006-04-02 22:00:00\n0.01\n2006-04-02 22:00:00\n0.01\n0.10\n\n\n1\n2006\nEWF002\n0.20\nB\n53.61\n-115.92\nFire Department\nIncendiary\nOthers (explain in remarks)\nLighting Fires\n...\nNaT\nUnknown\nNaT\n0.02\nUnknown\n2006-04-03 13:20:00\n0.20\n2006-04-03 13:20:00\n0.20\n0.20\n\n\n2\n2006\nEWF001\n0.50\nB\n53.61\n-115.59\nFire Department\nIncendiary\nOthers (explain in remarks)\nLighting Fires\n...\nNaT\nUnknown\nNaT\n0.02\nUnknown\n2006-04-03 13:23:00\n0.50\n2006-04-03 13:23:00\n0.50\n0.50\n\n\n3\n2006\nEWF003\n0.01\nA\n53.61\n-115.61\nIndustry\nIncendiary\nOthers (explain in remarks)\nLighting Fires\n...\nNaT\nUnknown\nNaT\n0.02\nUnknown\n2006-04-03 14:08:00\n0.01\n2006-04-03 14:08:00\n0.01\n0.01\n\n\n4\n2006\nPWF002\n0.10\nA\n56.25\n-117.05\nFire Department\nOther Industry\nEmployees\nRefuse\n...\nNaT\nUnknown\nNaT\n0.02\nUnknown\n2006-04-03 19:57:00\n0.10\n2006-04-03 20:19:00\n0.10\n0.10\n\n\n\n\n5 rows × 35 columns\n\n\n\n\nwildfire.columns.tolist()\n\n['year',\n 'fire_number',\n 'current_size',\n 'size_class',\n 'latitude',\n 'longitude',\n 'fire_origin',\n 'general_cause',\n 'responsible_group',\n 'activity_class',\n 'true_cause',\n 'fire_start_date',\n 'detection_agent_type',\n 'detection_agent',\n 'assessment_hectares',\n 'fire_spread_rate',\n 'fire_type',\n 'fire_position_on_slope',\n 'weather_conditions_over_fire',\n 'temperature',\n 'relative_humidity',\n 'wind_direction',\n 'wind_speed',\n 'fuel_type',\n 'initial_action_by',\n 'ia_arrival_at_fire_date',\n 'ia_access',\n 'fire_fighting_start_date',\n 'fire_fighting_start_size',\n 'bucketing_on_fire',\n 'first_bh_date',\n 'first_bh_size',\n 'first_uc_date',\n 'first_uc_size',\n 'first_ex_size_perimeter']"
  },
  {
    "objectID": "scripts/wildfire_clean.html#please-let-me-know-which-columns-you-think-are-better-to-keep",
    "href": "scripts/wildfire_clean.html#please-let-me-know-which-columns-you-think-are-better-to-keep",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Please let me know which columns you think are better to keep",
    "text": "Please let me know which columns you think are better to keep\n\n\n\n\n\n\n\nCategory\nColumns\n\n\n\n\nIdentifiers\n'year', 'fire_number'\n\n\nFire Size & Status\n'current_size', 'size_class', 'fire_fighting_start_size', 'first_bh_size', 'first_uc_size', 'first_ex_size_perimeter'\n\n\nLocation\n'latitude', 'longitude', 'fire_origin'\n\n\nCause & Activity\n'general_cause', 'true_cause', 'activity_class', 'responsible_group'\n\n\nKey Dates\n'fire_start_date', 'discovered_date', 'ia_arrival_at_fire_date', 'fire_fighting_start_date', 'first_bh_date', 'first_uc_date'\n\n\nDetection & Resources\n'detection_agent_type', 'detection_agent', 'initial_action_by', 'ia_access'\n\n\nAssessment & Behavior\n'assessment_hectares', 'fire_spread_rate', 'fire_type', 'fire_position_on_slope', 'fuel_type'\n\n\nWeather\n'weather_conditions_over_fire', 'temperature', 'relative_humidity', 'wind_direction', 'wind_speed'\n\n\nSuppression\n'bucketing_on_fire'"
  },
  {
    "objectID": "scripts/wildfire_clean.html#validate-cleaned-file",
    "href": "scripts/wildfire_clean.html#validate-cleaned-file",
    "title": "Wildfire Dataset Cleaning Steps",
    "section": "Validate cleaned file",
    "text": "Validate cleaned file\n\nclean = pd.read_csv(\"../data/clean/wildfire.csv\")\nclean.shape\nclean.head()\n\n\n\n\n\n\n\n\nyear\nfire_number\ncurrent_size\nsize_class\nlatitude\nlongitude\nfire_origin\ngeneral_cause\nresponsible_group\nactivity_class\n...\nia_arrival_at_fire_date\nia_access\nfire_fighting_start_date\nfire_fighting_start_size\nbucketing_on_fire\nfirst_bh_date\nfirst_bh_size\nfirst_uc_date\nfirst_uc_size\nfirst_ex_size_perimeter\n\n\n\n\n0\n2006\nPWF001\n0.10\nA\n56.25\n-117.18\nLand Owner\nResident\nResident\nGrass\n...\nNaN\nUnknown\nNaN\n0.02\nUnknown\n2006-04-02 22:00:00\n0.01\n2006-04-02 22:00:00\n0.01\n0.10\n\n\n1\n2006\nEWF002\n0.20\nB\n53.61\n-115.92\nFire Department\nIncendiary\nOthers\nLighting Fires\n...\nNaN\nUnknown\nNaN\n0.02\nUnknown\n2006-04-03 13:20:00\n0.20\n2006-04-03 13:20:00\n0.20\n0.20\n\n\n2\n2006\nEWF001\n0.50\nB\n53.61\n-115.59\nFire Department\nIncendiary\nOthers\nLighting Fires\n...\nNaN\nUnknown\nNaN\n0.02\nUnknown\n2006-04-03 13:23:00\n0.50\n2006-04-03 13:23:00\n0.50\n0.50\n\n\n3\n2006\nEWF003\n0.01\nA\n53.61\n-115.61\nIndustry\nIncendiary\nOthers\nLighting Fires\n...\nNaN\nUnknown\nNaN\n0.02\nUnknown\n2006-04-03 14:08:00\n0.01\n2006-04-03 14:08:00\n0.01\n0.01\n\n\n4\n2006\nPWF002\n0.10\nA\n56.25\n-117.05\nFire Department\nOther Industry\nEmployees\nRefuse\n...\nNaN\nUnknown\nNaN\n0.02\nUnknown\n2006-04-03 19:57:00\n0.10\n2006-04-03 20:19:00\n0.10\n0.10\n\n\n\n\n5 rows × 35 columns"
  },
  {
    "objectID": "website_files/citation.html",
    "href": "website_files/citation.html",
    "title": "Citation",
    "section": "",
    "text": "Burak K (2025). diversedata: Diverse Dataset Hub. R package version TBD, https://github.com/diverse-data-hub/diversedata"
  },
  {
    "objectID": "website_files/citation.html#tbd-another-reference",
    "href": "website_files/citation.html#tbd-another-reference",
    "title": "Citation",
    "section": "TBD Another Reference",
    "text": "TBD Another Reference\n\nOwners\nKatie Burak PhD\nCopyright Holder\n\nCollaborators\nFrancisco Ramirez\nAzin Piran\nSiddarth Subrahmanian"
  },
  {
    "objectID": "website_files/description_pages/hcmst.html",
    "href": "website_files/description_pages/hcmst.html",
    "title": "How Couples Meet and Stay Together",
    "section": "",
    "text": "This data set contains information from the “How Couples Meet and Stay Together” (HCMST) study, which surveyed 1,722 U.S. adults in 2022 to explore how relationships form and changed with time. It focuses on how relationships were influenced by the COVID-19 pandemic and offers insight at modern relationships, including changes in dating behaviors and how couples adapted during a challenging time. Conducted by Ipsos, and led by researchers from Stanford University, the survey focused on dating habits and the impact of the COVID-19 pandemic on relationships. Adapted from the original data set, this data offers a look at how social changes have changed how couples meet and stay together.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nhcmst.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nFamily and Relationships\n\n\nAssociated Tasks\n\n\nClassification\n\n\nFeature Type\n\n\nFactor, Integer, Numeric\n\n\nInstances\n\n\n1328\n\n\nFeatures\n\n\n21\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nsubject_age\nFeature\nNumeric\nSubject age\nyears\nNo\n\n\nsubject_education\nFeature\nOrdinal Categorical\nHighest degree obtained. Ordered categories: [‘no_education’ &lt; ‘1st_4th_grade’ &lt; ‘5th_6th_grade’ &lt; ‘7th_8th_grade’ &lt; ‘9th’ &lt; ‘10th’ &lt; ‘11th’ &lt; ‘12th_nodiploma’ &lt; ‘high_school_grad’ &lt; ‘some_college’ &lt; ‘associate_degree’ &lt; ‘bach_degree’ &lt; ‘masters_degree’ &lt; ‘prof_doct_degree’]\n-\nNo\n\n\nsubject_sex\nFeature\nNominal Categorical\nLevels: [‘male’, ‘female’, ‘other’]\n-\nNo\n\n\nsubject_ethnicity\nFeature\nNominal Categorical\nLevels: [‘white’, ‘black’, ‘other’, ‘hispanic’, ‘2_plus_eth’]\n-\nNo\n\n\nsubject_income_category\nFeature\nOrdinal Categorical\nOrdered categories: [‘under_5k’ &lt; ‘5k_7k’ &lt; ‘7k_10k’ &lt; ‘10k_12k’ &lt; ‘12k_15k’ &lt; ‘15k_20k’ &lt; ‘20k_25k’ &lt; ‘25k_30k’ &lt; ‘30k_35k’ &lt; ‘35k_40k’ &lt; ‘40k_50k’ &lt; ‘50k_60k’ &lt; ‘60k_75k’ &lt; ‘75k_85k’ &lt; ‘85k_100k’ &lt; ‘100k_125k’ &lt; ‘125k_150k’ &lt; ‘150k_175k’ &lt; ‘175k_200k’ &lt; ‘200k_250k’ &lt; ‘over_250k’]\ndollars\nNo\n\n\nsubject_employment_status\nFeature\nNominal Categorical\nLevels: [‘working_paid_employee’, ‘working_self_employed’, ‘not_working_temp_layoff’, ‘not_working_looking’, ‘not_working_retired’, ‘not_working_disabled’, ‘not_working_other’]\n-\nNo\n\n\nsame_sex_couple\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\nmarried\nFeature\nNominal Categorical\nLevels: [‘not_married’, ‘married’]\n-\nYes\n\n\nsex_frequency\nFeature\nOrdinal Categorical\nOrdered categories: [‘once_or_more_a_day’ &lt; ‘3_to_6_times_a_week’ &lt; ‘once_or_twice_a_week’ &lt; ‘2_to_3_times_a_month’ &lt; ‘once_a_month_or_less’]\n-\nYes\n\n\nflirts_with_partner\nFeature\nOrdinal Categorical\nOrdered categories: [‘every_day’ &lt; ‘a_few_times_a_week’ &lt; ‘once_a_week’ &lt; ‘1_to_3_times_a_month’ &lt; ‘less_than_once_a_month’ &lt; ‘never’]\n-\nYes\n\n\nfights_with_partner\nFeature\nOrdinal Categorical\nOrdered categories: [‘0_times’ &lt; ‘1_time’ &lt; ‘2_times’ &lt; ‘3_times’ &lt; ‘4_times’ &lt; ‘5_times’ &lt; ‘6_times’ &lt; ‘7_or_more_times’]\nAmount in the last 7 days\nYes\n\n\nrelationship_duration\nFeature\nNumeric\nDuration of relationship\nyears\nYes\n\n\nchildren\nFeature\nNumeric\nNumber of children in the household.\n-\nNo\n\n\nrel_change_during_pandemic\nFeature\nNominal Categorical\nLevels: [‘better_than_before’, ‘no_change’, ‘worse_than_before’]\n-\nNo\n\n\ninc_change_during_pandemic\nFeature\nOrdinal Categorical\nOrdered categories: [‘much_worse’ &lt; ‘worse’ &lt; ‘no_change’ &lt; ‘better’ &lt; ‘much_better’]\n-\nYes\n\n\nsubject_had_covid\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\npartner_had_covid\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\nsubject_vaccinated\nFeature\nNominal Categorical\nLevels: [‘fully_vaccinated_and_booster’, ‘fully_vaccinated_no_booster’, ‘partially_vaccinated’, ‘not_vaccinated’]\n-\nYes\n\n\npartner_vaccinated\nFeature\nNominal Categorical\nLevels: [‘fully_vaccinated_and_booster’, ‘fully_vaccinated_no_booster’, ‘partially_vaccinated’, ‘not_vaccinated’]\n-\nYes\n\n\nagree_covid_approach\nFeature\nNominal Categorical\nLevels: [‘completely_agree’, ‘mostly_agree’, ‘mostly_disagree’, ‘completely_disagree’]\n-\nYes\n\n\nrelationship_quality\nTarget\nOrdinal Categorical\nLevels: [‘excellent’ &lt; ‘good’ &lt; ‘fair’ &lt; ‘poor’ &lt; ‘very_poor’]\n-\nNo"
  },
  {
    "objectID": "website_files/description_pages/hcmst.html#data-set-information",
    "href": "website_files/description_pages/hcmst.html#data-set-information",
    "title": "How Couples Meet and Stay Together",
    "section": "",
    "text": "This data set contains information from the “How Couples Meet and Stay Together” (HCMST) study, which surveyed 1,722 U.S. adults in 2022 to explore how relationships form and changed with time. It focuses on how relationships were influenced by the COVID-19 pandemic and offers insight at modern relationships, including changes in dating behaviors and how couples adapted during a challenging time. Conducted by Ipsos, and led by researchers from Stanford University, the survey focused on dating habits and the impact of the COVID-19 pandemic on relationships. Adapted from the original data set, this data offers a look at how social changes have changed how couples meet and stay together.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nhcmst.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nFamily and Relationships\n\n\nAssociated Tasks\n\n\nClassification\n\n\nFeature Type\n\n\nFactor, Integer, Numeric\n\n\nInstances\n\n\n1328\n\n\nFeatures\n\n\n21\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nsubject_age\nFeature\nNumeric\nSubject age\nyears\nNo\n\n\nsubject_education\nFeature\nOrdinal Categorical\nHighest degree obtained. Ordered categories: [‘no_education’ &lt; ‘1st_4th_grade’ &lt; ‘5th_6th_grade’ &lt; ‘7th_8th_grade’ &lt; ‘9th’ &lt; ‘10th’ &lt; ‘11th’ &lt; ‘12th_nodiploma’ &lt; ‘high_school_grad’ &lt; ‘some_college’ &lt; ‘associate_degree’ &lt; ‘bach_degree’ &lt; ‘masters_degree’ &lt; ‘prof_doct_degree’]\n-\nNo\n\n\nsubject_sex\nFeature\nNominal Categorical\nLevels: [‘male’, ‘female’, ‘other’]\n-\nNo\n\n\nsubject_ethnicity\nFeature\nNominal Categorical\nLevels: [‘white’, ‘black’, ‘other’, ‘hispanic’, ‘2_plus_eth’]\n-\nNo\n\n\nsubject_income_category\nFeature\nOrdinal Categorical\nOrdered categories: [‘under_5k’ &lt; ‘5k_7k’ &lt; ‘7k_10k’ &lt; ‘10k_12k’ &lt; ‘12k_15k’ &lt; ‘15k_20k’ &lt; ‘20k_25k’ &lt; ‘25k_30k’ &lt; ‘30k_35k’ &lt; ‘35k_40k’ &lt; ‘40k_50k’ &lt; ‘50k_60k’ &lt; ‘60k_75k’ &lt; ‘75k_85k’ &lt; ‘85k_100k’ &lt; ‘100k_125k’ &lt; ‘125k_150k’ &lt; ‘150k_175k’ &lt; ‘175k_200k’ &lt; ‘200k_250k’ &lt; ‘over_250k’]\ndollars\nNo\n\n\nsubject_employment_status\nFeature\nNominal Categorical\nLevels: [‘working_paid_employee’, ‘working_self_employed’, ‘not_working_temp_layoff’, ‘not_working_looking’, ‘not_working_retired’, ‘not_working_disabled’, ‘not_working_other’]\n-\nNo\n\n\nsame_sex_couple\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\nmarried\nFeature\nNominal Categorical\nLevels: [‘not_married’, ‘married’]\n-\nYes\n\n\nsex_frequency\nFeature\nOrdinal Categorical\nOrdered categories: [‘once_or_more_a_day’ &lt; ‘3_to_6_times_a_week’ &lt; ‘once_or_twice_a_week’ &lt; ‘2_to_3_times_a_month’ &lt; ‘once_a_month_or_less’]\n-\nYes\n\n\nflirts_with_partner\nFeature\nOrdinal Categorical\nOrdered categories: [‘every_day’ &lt; ‘a_few_times_a_week’ &lt; ‘once_a_week’ &lt; ‘1_to_3_times_a_month’ &lt; ‘less_than_once_a_month’ &lt; ‘never’]\n-\nYes\n\n\nfights_with_partner\nFeature\nOrdinal Categorical\nOrdered categories: [‘0_times’ &lt; ‘1_time’ &lt; ‘2_times’ &lt; ‘3_times’ &lt; ‘4_times’ &lt; ‘5_times’ &lt; ‘6_times’ &lt; ‘7_or_more_times’]\nAmount in the last 7 days\nYes\n\n\nrelationship_duration\nFeature\nNumeric\nDuration of relationship\nyears\nYes\n\n\nchildren\nFeature\nNumeric\nNumber of children in the household.\n-\nNo\n\n\nrel_change_during_pandemic\nFeature\nNominal Categorical\nLevels: [‘better_than_before’, ‘no_change’, ‘worse_than_before’]\n-\nNo\n\n\ninc_change_during_pandemic\nFeature\nOrdinal Categorical\nOrdered categories: [‘much_worse’ &lt; ‘worse’ &lt; ‘no_change’ &lt; ‘better’ &lt; ‘much_better’]\n-\nYes\n\n\nsubject_had_covid\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\npartner_had_covid\nFeature\nNominal Categorical\nLevels: [‘no’, ‘yes’]\n-\nYes\n\n\nsubject_vaccinated\nFeature\nNominal Categorical\nLevels: [‘fully_vaccinated_and_booster’, ‘fully_vaccinated_no_booster’, ‘partially_vaccinated’, ‘not_vaccinated’]\n-\nYes\n\n\npartner_vaccinated\nFeature\nNominal Categorical\nLevels: [‘fully_vaccinated_and_booster’, ‘fully_vaccinated_no_booster’, ‘partially_vaccinated’, ‘not_vaccinated’]\n-\nYes\n\n\nagree_covid_approach\nFeature\nNominal Categorical\nLevels: [‘completely_agree’, ‘mostly_agree’, ‘mostly_disagree’, ‘completely_disagree’]\n-\nYes\n\n\nrelationship_quality\nTarget\nOrdinal Categorical\nLevels: [‘excellent’ &lt; ‘good’ &lt; ‘fair’ &lt; ‘poor’ &lt; ‘very_poor’]\n-\nNo"
  },
  {
    "objectID": "website_files/description_pages/hcmst.html#about-the-data",
    "href": "website_files/description_pages/hcmst.html#about-the-data",
    "title": "How Couples Meet and Stay Together",
    "section": "About the Data",
    "text": "About the Data\nThis data set is adapted from the original data set How Couples Meet and Stay Together 2017, 2022 survey, collected by Stanford University researchers. The data set explores the dynamics of relationships among adults in the United States, with data points gathered from subjects in 2017, 2020 and 2022. This adapted data set focuses on variables that may affect the quality of the relationship, considering demographic characteristics of the subjects, as well as the effect of the COVID-19 pandemic.\nThe extensive use of dating apps and the COVID-19 pandemic had a significant impact on how romantic relationships in the United States. This data set enables exploration of how external factors, like the health of the subjects and income changes, as well as personal behaviors, like conflict and intimate dynamics, relate to an individual’s perception of the quality of the relationship.\nThis analysis contributes to discussions around partnership resilience, healthy relationships, and how norms around sexuality and technology shape romantic relationships.\n\nKey Features of the Dataset\nEach row in the data set represents an individual subject and includes the following selected variables:\n\nSubject demographics: age, sex, ethnicity, education level, income level, and employment status\nRelationship context: whether the subject is part of a same-sex relationship, whether they are married, the duration of the relationship and how many children are in the household.\nCouple behavior indicators: sex, flirting and fighting frequency.\nPandemic Variables: interpreted impact of the pandemic in the relationship, income change during the pandemic, if the subject and their partner were sick with COVID-19 and if they were vaccinated.\nQuality of the relationship: variable used to measure the subject’s perceived quality of their relationship.\n\n\n\nPurpose and Use Cases\nThis data set supports investigations into:\n\nDemographic and behavioral predictors of relationship quality.\nHow the pandemic experience affected relationships.\nDifferences in relationship dynamics between different levels of income, gender and sexual orientation."
  },
  {
    "objectID": "website_files/description_pages/hcmst.html#case-study",
    "href": "website_files/description_pages/hcmst.html#case-study",
    "title": "How Couples Meet and Stay Together",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nWhat behavioral factors are strongly associated with relationship quality in the context of the COVID-19 pandemic? Are these factors different for same sex couples?\nThis case study examines the association between relationship_quality and a variety of demographic, behavioral and pandemic-related variables.\nBy examining survey data, we aim to:\n\nExplore the different factors that were collected through the survey.\nIdentify the behavioral factors that most strongly affect the perceived relationship quality. We will focus specifically on finding how sex_frequency, flirts_with_partner and fights_with_partner affect the perception of relationship quality.\nEvaluate if these factors have a different impact on same_sex_couples.\n\n\n\nMethodology\n\n0. Load Libraries\n\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(cowplot)\n\n\nAttaching package: 'cowplot'\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nlibrary(broom)\nlibrary(brant)\n\nWarning: package 'brant' was built under R version 4.4.3\n\n\n\n\n1. Data Cleaning & Processing\nFirst, we can load our data and remove all NA values from the data set as we will be interested in using all the available variables as explanatory variables.\n\n# Reading Data\nhcmst &lt;- read_csv(\"../../data/clean/hcmst.csv\") \n\nRows: 1328 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (18): subject_education, subject_sex, subject_ethnicity, subject_income_...\ndbl  (3): subject_age, relationship_duration, children\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Review total rows\nnrow(hcmst)\n\n[1] 1328\n\n# Select features of interest and removing NA\nhcmst &lt;- hcmst |&gt; \n  dplyr::select(same_sex_couple, sex_frequency, flirts_with_partner, fights_with_partner, relationship_quality) |&gt; \n  drop_na()\n\n# Remaining row count.\nnrow(hcmst)\n\n[1] 1241\n\n# Visualize the data set\nhead(hcmst)\n\n# A tibble: 6 × 5\n  same_sex_couple sex_frequency        flirts_with_partner   fights_with_partner\n  &lt;chr&gt;           &lt;chr&gt;                &lt;chr&gt;                 &lt;chr&gt;              \n1 no              once_or_twice_a_week a_few_times_a_week    0_times            \n2 no              once_a_month_or_less never                 7_or_more_times    \n3 no              once_or_twice_a_week a_few_times_a_week    2_times            \n4 no              once_or_twice_a_week 1_to_3_times_a_month  0_times            \n5 no              once_or_twice_a_week a_few_times_a_week    0_times            \n6 no              once_a_month_or_less less_than_once_a_mon… 1_time             \n# ℹ 1 more variable: relationship_quality &lt;chr&gt;\n\n\n\n\n2. Variable Encoding\nWe can note that our categorical response follows a specific order. For this reason, we require a model that suits ordinal responses. Hence, we will be using an Ordinal Logistic regression model framework.\nIn order to do so, we need to make sure that our response variable is encoded as an ordered factor. We will also take this opportunity to encode all our explanatory variables as factors (and ordered factors) as needed, even if we will not use all of them in our exercise.\n\n# First, we can encode our nomical categorical explanatory variables:\n\nhcmst$same_sex_couple &lt;- as.factor(hcmst$same_sex_couple)\nlevels(hcmst$same_sex_couple)\n\n[1] \"no\"  \"yes\"\n\n\n\n# Then, we can encode all our ordinal categorical explanatory variables:\n\nhcmst$sex_frequency &lt;- as.ordered(hcmst$sex_frequency)\nhcmst$sex_frequency &lt;- fct_relevel(\n  hcmst$sex_frequency,\n  c(\"once_a_month_or_less\", \"2_to_3_times_a_month\", \"once_or_twice_a_week\", \"3_to_6_times_a_week\", \"once_or_more_a_day\")\n)\nlevels(hcmst$sex_frequency)\n\n[1] \"once_a_month_or_less\" \"2_to_3_times_a_month\" \"once_or_twice_a_week\"\n[4] \"3_to_6_times_a_week\"  \"once_or_more_a_day\"  \n\nhcmst$flirts_with_partner &lt;- as.ordered(hcmst$flirts_with_partner)\nhcmst$flirts_with_partner &lt;- fct_relevel(\n  hcmst$flirts_with_partner,\n  c(\"never\", \"less_than_once_a_month\", \"1_to_3_times_a_month\", \"once_a_week\", \"a_few_times_a_week\", \"every_day\")\n)\nlevels(hcmst$flirts_with_partner)\n\n[1] \"never\"                  \"less_than_once_a_month\" \"1_to_3_times_a_month\"  \n[4] \"once_a_week\"            \"a_few_times_a_week\"     \"every_day\"             \n\nhcmst$fights_with_partner &lt;- as.ordered(hcmst$fights_with_partner)\nhcmst$fights_with_partner &lt;- fct_relevel(\n  hcmst$fights_with_partner,\n  c(\"0_times\", \"1_time\", \"2_times\", \"3_times\", \"4_times\", \"5_times\", \"6_times\", \"7_or_more_times\")\n)\nlevels(hcmst$fights_with_partner)\n\n[1] \"0_times\"         \"1_time\"          \"2_times\"         \"3_times\"        \n[5] \"4_times\"         \"5_times\"         \"6_times\"         \"7_or_more_times\"\n\n\n\nhcmst$relationship_quality &lt;- as.ordered(hcmst$relationship_quality)\nhcmst$relationship_quality &lt;- fct_relevel(\n  hcmst$relationship_quality,\n  c(\"very_poor\", \"poor\", \"fair\", \"good\", \"excellent\")\n)\nlevels(hcmst$relationship_quality)\n\n[1] \"very_poor\" \"poor\"      \"fair\"      \"good\"      \"excellent\"\n\nhead(hcmst)\n\n# A tibble: 6 × 5\n  same_sex_couple sex_frequency        flirts_with_partner   fights_with_partner\n  &lt;fct&gt;           &lt;ord&gt;                &lt;ord&gt;                 &lt;ord&gt;              \n1 no              once_or_twice_a_week a_few_times_a_week    0_times            \n2 no              once_a_month_or_less never                 7_or_more_times    \n3 no              once_or_twice_a_week a_few_times_a_week    2_times            \n4 no              once_or_twice_a_week 1_to_3_times_a_month  0_times            \n5 no              once_or_twice_a_week a_few_times_a_week    0_times            \n6 no              once_a_month_or_less less_than_once_a_mon… 1_time             \n# ℹ 1 more variable: relationship_quality &lt;ord&gt;\n\n\n\n\n2. Exploratory Data Analysis\nLet’s visualize histograms and stacked bar charts for our different categorical variables to see how different groups were sampled in the survey and how different these samples are for same sex couples.\nFirst, we will create a couple of functions that will be used for visualization.\n\nstacked_bar_plot &lt;- function(data, x_var, stacked_var, plot_title = \"Stacked Bar Charts\") {\n\n  prop_summary &lt;- as.data.frame(xtabs(\n    formula = as.formula(paste0(\"~\", x_var, \"+\", stacked_var)),\n    data = data\n  ))\n\n  row_totals &lt;- aggregate(Freq ~ get(x_var), data = prop_summary, sum)\n  names(row_totals) &lt;- c(x_var, \"Total\")\n\n  prop_summary &lt;- prop_summary |&gt; \n    left_join(row_totals, by = x_var) |&gt; \n    mutate(prop = Freq / Total)\n\n  ggplot(\n    prop_summary, aes_string(x = x_var, y = \"prop\", fill = stacked_var)) +\n    geom_bar(stat = \"identity\", linewidth = 0.7, colour = \"black\") +\n    geom_text(\n      aes(\n        label = ifelse(\n          prop &gt;= 0.05, \n          paste0(\n            sprintf(\"%.0f\", prop * 100), \n            \"%\"), \n          \"\")\n        ),\n      position = position_stack(vjust = 0.5), \n      colour = \"firebrick3\", \n      fontface = \"bold\", \n      size = 5) +\n    scale_y_continuous(labels = percent_format()) +\n    labs(y = \"Percentage\", x = \"Same Sex Couple\", fill = \"\") +\n    ggtitle(plot_title) +\n    theme(\n      plot.title = element_text(size = 12, face = \"bold\"),\n      axis.text.x = element_text(size = 9, angle = 0),\n      axis.text.y = element_text(size = 9, angle = 0),\n      axis.title = element_text(size = 12),\n      legend.text = element_text(size = 12, margin = margin(r = 1, unit = \"cm\")),\n      legend.title = element_text(size = 12, face = \"bold\")\n    ) +\n    guides(fill = guide_legend(title = \"Characteristic\")) +\n    scale_fill_brewer(palette = \"Blues\")\n}\n\nhistogram_plot &lt;- function(data, y_var, plot_title = \"Counts by Category\") {\n  data_long &lt;- data |&gt;\n    dplyr::select(all_of(y_var)) |&gt;\n    pivot_longer(cols = everything(), names_to = \"variable\", values_to = \"value\") |&gt;\n    count(variable, value)\n\n  ggplot(data_long, aes(y = reorder(value, n))) +\n    geom_bar(aes(x = n), stat = \"identity\", fill = \"skyblue2\") +\n    labs(\n      title = plot_title,\n      x = \"Count\",\n      y = NULL\n    ) +\n    theme_minimal()\n}\n\nWe can note that a small minority of the sample are involved in same-sex couples.\n\nhist_same_sex &lt;- histogram_plot(hcmst, \"same_sex_couple\", plot_title = \"Counts by Category\")\n\nhist_same_sex\n\n\n\n\n\n\n\n\nNow we can look at how often the sample are having sex with their partners.\nWe can note that same-sex couples have very similar proportions in how often they have sex vs different-sex couples. We can also note that the sample is skewed towards having sex less frequently.\n\nprop_sex_freq &lt;- stacked_bar_plot(hcmst, \"same_sex_couple\", \"sex_frequency\", plot_title = \"Stacked Bar Charts\")\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\nhist_sex_freq &lt;- histogram_plot(hcmst, \"sex_frequency\", plot_title = \"Counts by Category\")\n\nplot_grid(prop_sex_freq, hist_sex_freq, ncol = 1)\n\n\n\n\n\n\n\n\nWe can also visualize how often couples flirt and fight with their partners. Again, visually there are minor differences in these frequencies between same-sex and different-sex couples. We can also note that the sample is skewed towards having a low frequency of both flirting and fighting.\n\nprop_flirt_freq &lt;- stacked_bar_plot(hcmst, \"same_sex_couple\", \"flirts_with_partner\", plot_title = \"Stacked Bar Charts\")\n\nhist_flirt_freq &lt;- histogram_plot(hcmst, \"flirts_with_partner\", plot_title = \"Counts by Category\")\n\nplot_grid(prop_flirt_freq, hist_flirt_freq, ncol = 1)\n\n\n\n\n\n\n\n\n\nprop_fight_freq &lt;- stacked_bar_plot(hcmst, \"same_sex_couple\", \"fights_with_partner\", plot_title = \"Stacked Bar Charts\")\n\nhist_fight_freq &lt;- histogram_plot(hcmst, \"fights_with_partner\", plot_title = \"Counts by Category\")\n\nplot_grid(prop_fight_freq, hist_fight_freq, ncol = 1)\n\n\n\n\n\n\n\n\nAs for our target variable, it can be noted that most subjects perceived the quality of their relationship to be good or excellent.\n\nprop_quality_freq &lt;- stacked_bar_plot(hcmst, \"same_sex_couple\", \"relationship_quality\", plot_title = \"Stacked Bar Charts\")\n\nhist_quality_freq &lt;- histogram_plot(hcmst, \"relationship_quality\", plot_title = \"Counts by Category\")\n\nplot_grid(prop_quality_freq, hist_quality_freq, ncol = 1)\n\n\n\n\n\n\n\n\n\nggsave(\"../img/hcmst.png\", plot = prop_quality_freq, width = 6, height = 4, dpi = 300)\n\n\n\n3. Ordinal Logistic Regression\nWe will be assuming and fitting a proportional odds model, which assumes that the log-odds of being in a higher category of the response variable follows a linear relationship with the explanatory variables.\nFor our modeling purposes, we will use the MASS package, polr() function to obtain model estimates.\nGiven that we are using ordinal categorical variables as explanatory variables, we will also set our model to use successive differences contrasts to facilitate the interpretation of the estimates.\n\noptions(contrasts = c(\"contr.treatment\", \"contr.sdif\"))\n\nNow, we can fit our model. Noting that polr() does not calculate p-values, we can compute them and bind them to our model estimates. We will also focus only on statistically significant estimates.\nFor the purposes of this exercise, we will only use a subset of the variables in our modeling. We will be interested in how behavioral variables (sex_frequency, flirts_with_partner and fights_with_partner) affect the perception of relationship quality, additionally, we are interested in seeing if these effects are different for same_sex_couples.\n\nordinal_model &lt;- polr(relationship_quality ~ same_sex_couple + sex_frequency + flirts_with_partner + fights_with_partner,\n  data = hcmst, Hess = TRUE\n)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nsummary_partial_ordinal_model &lt;- cbind(tidy(ordinal_model),\n  p.value = pnorm(abs(tidy(ordinal_model)$statistic), lower.tail = FALSE) * 2) |&gt;\n  mutate_if(is.numeric, round, 2)\n\nsummary_partial_ordinal_model |&gt;\n  mutate(exp_estimate = exp(estimate)) |&gt; \n  filter(p.value &lt; 0.05, \n         coef.type == \"coefficient\")\n\n                                                    term estimate std.error\n1 sex_frequency2_to_3_times_a_month-once_a_month_or_less     0.61      0.15\n2    flirts_with_partneronce_a_week-1_to_3_times_a_month    -0.68      0.32\n3        flirts_with_partnerevery_day-a_few_times_a_week     0.80      0.27\n4                      fights_with_partner1_time-0_times    -0.62      0.14\n  statistic   coef.type p.value exp_estimate\n1      4.07 coefficient    0.00    1.8404314\n2     -2.15 coefficient    0.03    0.5066170\n3      2.98 coefficient    0.00    2.2255409\n4     -4.50 coefficient    0.00    0.5379444\n\n\nPositive estimates are associated with higher relationship quality, while negative estimates are associated with lower relationship quality. Additionally, the exponential of the estimate is the odds ratio, which represents how much the odds of having a higher relationship_quality level changes between levels.\nWe can interpret these estimates:\n\nsame_sex_couple: There is no statistical evidence that being part of a same-sex couple has an association with the perceived relationship quality\n\n\n\nsex_frequency: People who have sex 2-3 times a month have 1.8 higher odds of reporting better relationship quality that those who have sex once a month or less.\nflirts_with_partner: Flirting once per week vs 1-3 times per month is associated with a 49% lower odds of better relationship quality. This is a bit unexpected.\nflirts_with_partner: Flirting every day vs a few times per week is associated with 2.3 higher odds of better relationship quality.\nfights_with_partner: Fighting once vs none is associated with 47% lower odds of better relationship quality.\n\nWith our fitted model, we are now able to make predictions on new examples. Based on demographic, behavioral, COVID-19 related variables, we can predict the probabilities of the different levels of perceived relationship_quality for a specific subject.\nBased on the calculated estimates, we would think that people who have more sex, flirt more and fight less would perceive a better relationship_quality. We can test this premise:\n\npredict(ordinal_model, tibble(\n  same_sex_couple = \"no\",\n  sex_frequency = \"once_a_month_or_less\",\n  flirts_with_partner = \"never\",\n  fights_with_partner = \"7_or_more_times\"), \n  type = \"probs\")\n\n very_poor       poor       fair       good  excellent \n0.05086336 0.24537641 0.41765952 0.25193653 0.03416417 \n\npredict(ordinal_model, tibble(\n  same_sex_couple = \"no\",\n  sex_frequency = \"once_or_more_a_day\",\n  flirts_with_partner = \"every_day\",\n  fights_with_partner = \"0_times\"), \n  type = \"probs\")\n\n   very_poor         poor         fair         good    excellent \n0.0002267081 0.0015513052 0.0086702893 0.0963954372 0.8931562601 \n\n\nWe can note that a subject who has sex once a month or less, that never flirt with their partner, and that fought with their partner 7 or more times in the last week, have a 41% probability of perceiving their relationship quality as fair. On the other hand, a subject who has sex once or more per day, that flirts with their partner on a daily basis and that has not fought with their partner in the last week, has an 81% probability of perceiving their relationship quality as excellent.\n\n\n4. Proportional Odds Assumption\nTo ensure the validity of our analysis, we are going to test the proportional odds assumption. To do so, we can use the Brant-Wald test, which assesses whether our model fulfills this assumption.\n\nbrant(ordinal_model)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n---------------------------------------------------------------------------------------------------- \nTest for                                X2  df  probability \n---------------------------------------------------------------------------------------------------- \nOmnibus                                 39.82   51  0.87\nsame_sex_coupleyes                          2.88    3   0.41\nsex_frequency2_to_3_times_a_month-once_a_month_or_less      2.38    3   0.5\nsex_frequencyonce_or_twice_a_week-2_to_3_times_a_month      1.45    3   0.69\nsex_frequency3_to_6_times_a_week-once_or_twice_a_week       2.85    3   0.42\nsex_frequencyonce_or_more_a_day-3_to_6_times_a_week     0   3   1\nflirts_with_partnerless_than_once_a_month-never         2.35    3   0.5\nflirts_with_partner1_to_3_times_a_month-less_than_once_a_month  0.16    3   0.98\nflirts_with_partneronce_a_week-1_to_3_times_a_month     0   3   1\nflirts_with_partnera_few_times_a_week-once_a_week           0.88    3   0.83\nflirts_with_partnerevery_day-a_few_times_a_week         1.5 3   0.68\nfights_with_partner1_time-0_times                   7.42    3   0.06\nfights_with_partner2_times-1_time                   1.43    3   0.7\nfights_with_partner3_times-2_times                  1.81    3   0.61\nfights_with_partner4_times-3_times                  2.06    3   0.56\nfights_with_partner5_times-4_times                  0.08    3   0.99\nfights_with_partner6_times-5_times                  0.08    3   0.99\nfights_with_partner7_or_more_times-6_times              0.82    3   0.85\n---------------------------------------------------------------------------------------------------- \n\nH0: Parallel Regression Assumption holds\n\n\nWarning in brant(ordinal_model): 2118 combinations in table(dv,ivs) do not\noccur. Because of that, the test results might be invalid.\n\n\nNote that with an \\(\\alpha = 0.05\\), we are completely fulfilling the proportional odds assumption (the column probability delivers the corresponding p-values).\nAlso, note that throughout the analysis we got a few warnings. These are caused by having categories in our model that are quite sparse, where combinations of the response and the levels of the predictor have no observations. These gaps may affect Brant statistics. A solution for this matter would be to bin some of the levels of our categories to avoid having empty combinations of levels between our response and explanatory variables.\n\n\n5. Discussion\nThis analysis explored how sex frequency, flirting and fighting relate to perceived relationship quality for different types of couples. Through the analysis, we could note that relationship behaviors play a key role in how individuals assess their relationships. More specifically, we could conclude the following from this exercise:\n\nBehaviors are important, being part of a same-sex couple not so much: More frequent sex and flirting are associated with higher perceived relationship quality, while more frequent fighting affects that perception negatively. Being part of a same-sex couple did not have a statistically significant impact on the perceived relationship quality\nSome effects might not be linear: Not all statistically significant estimates led to better outcomes. Interestingly, flirting once a week was associated with a lower perceived relationship quality than flirting 1-3 times a month.\nEncoding and model choice are critical: Model selection is tied to the type of response variable. Ordinal categorical response variables are tied to ordinal logistic regression models.\nInterpretation is key: Having ordinal explanatory variables poses a challenge in interpretation of model estimates. Using the right contrasts supports model interpretation.\nSparsity may affect results: Having many levels in our categories may lead to sparsity in the combination of explanatory variables to all levels of the response variable. Caution is advised in these cases."
  },
  {
    "objectID": "website_files/description_pages/hcmst.html#attribution",
    "href": "website_files/description_pages/hcmst.html#attribution",
    "title": "How Couples Meet and Stay Together",
    "section": "Attribution",
    "text": "Attribution\nData adapted from Rosenfeld, Michael J., Reuben J. Thomas, and Sonia Hausen. 2023. How Couples Meet and Stay Together 2017-2020-2022 Combined Dataset. [Computer files]. Stanford, CA: Stanford University Libraries. Data."
  },
  {
    "objectID": "website_files/description_pages/wildfire.html",
    "href": "website_files/description_pages/wildfire.html",
    "title": "Historical Canadian Wildfire Data",
    "section": "",
    "text": "Dataset including information on wildfires in the province of Alberta from 2006 to 2024, inclusive. Information tracked for each fire includes: cause, size, location (latitude and longitude, legal land description, and forest area), time and duration, weather conditions, staffing and physical resources used to suppress the fire, and area burned.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nwildfire.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nClimate Change\n\n\nAssociated Tasks\n\n\nClassification, Time Series, Geospatial Analysis\n\n\nFeature Type\n\n\nCategorical, Integer\n\n\nInstances\n\n\n26551 records\n\n\nFeatures\n\n\n50\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nASSESSMENT_HECTARES\nFeature\nFloat\nFire Size\nHectares\nNo\n\n\nTRUE_CAUSE\nFeature\nCategorical\nInsufficient Resources, Insufficient Buffer, Winter Burning, Incendiary Device, Permit Related, Friction Spark, Hot Exhaust, Unclassified, Burning Substance, Arson Suspected, Unattended Fire, Unpredictable Event, Mechanical Failure, Abandoned Fire, Vehicle Fire, Unsafe Fire, Line Impact, High Hazard, Flammable Fluids, Arson Known, Animals\n-\nNo"
  },
  {
    "objectID": "website_files/description_pages/wildfire.html#data-set-information",
    "href": "website_files/description_pages/wildfire.html#data-set-information",
    "title": "Historical Canadian Wildfire Data",
    "section": "",
    "text": "Dataset including information on wildfires in the province of Alberta from 2006 to 2024, inclusive. Information tracked for each fire includes: cause, size, location (latitude and longitude, legal land description, and forest area), time and duration, weather conditions, staffing and physical resources used to suppress the fire, and area burned.\n\n\n\n Download CSV \n\n\n\n\n\n\nCSV Name\n\n\nwildfire.csv\n\n\nDataset Characteristics\n\n\nMultivariate\n\n\nSubject Area\n\n\nClimate Change\n\n\nAssociated Tasks\n\n\nClassification, Time Series, Geospatial Analysis\n\n\nFeature Type\n\n\nCategorical, Integer\n\n\nInstances\n\n\n26551 records\n\n\nFeatures\n\n\n50\n\n\nHas Missing Values?\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\nMissing Values\n\n\n\n\nASSESSMENT_HECTARES\nFeature\nFloat\nFire Size\nHectares\nNo\n\n\nTRUE_CAUSE\nFeature\nCategorical\nInsufficient Resources, Insufficient Buffer, Winter Burning, Incendiary Device, Permit Related, Friction Spark, Hot Exhaust, Unclassified, Burning Substance, Arson Suspected, Unattended Fire, Unpredictable Event, Mechanical Failure, Abandoned Fire, Vehicle Fire, Unsafe Fire, Line Impact, High Hazard, Flammable Fluids, Arson Known, Animals\n-\nNo"
  },
  {
    "objectID": "website_files/description_pages/wildfire.html#about-the-data",
    "href": "website_files/description_pages/wildfire.html#about-the-data",
    "title": "Historical Canadian Wildfire Data",
    "section": "About the Data",
    "text": "About the Data\nThis dataset contains information on wildfires in Canada, compiled from official government sources.\n\nKey Features of the Dataset\n\nFire size (in hectares)\nCause of fire (e.g., lightning, human activity)\nDetection method\nResponse team size\nLatitude/longitude of the fire\nWeather conditions at the time of fire\n\n\n\nPurpose and Use Cases\nThe data was collected to monitor, assess, and respond to wildfire risks across regions. Wildfires have significant environmental, social, and economic impacts—especially for remote, Indigenous, and underserved communities that may lack the infrastructure to respond effectively.\nFrom an equity and inclusion perspective, studying wildfire data can help identify geographic and resource disparities in fire detection and containment efforts, as well as the disproportionate risks certain populations face due to climate change and infrastructure gaps."
  },
  {
    "objectID": "website_files/description_pages/wildfire.html#case-study",
    "href": "website_files/description_pages/wildfire.html#case-study",
    "title": "Historical Canadian Wildfire Data",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nCan we identify the environmental and human factors most associated with large wildfires (&gt;10 hectares)?\nThe goal is to explore potential predictors of fire size, such as weather, fire cause, and detection method, and provide insights that could inform early interventions and resource planning.\n\n\nMethodology\n\n1. Data Cleaning & Processing\n\nConverted fire size to numeric\nCreated a binary variable large_fire (TRUE if &gt;10 ha)\nFiltered out incomplete records\n\n\n\n2. Exploratory Data Analysis (EDA)\nFire Size Distribution\n\nlibrary(ggplot2)\n\nggplot(wildfire_clean, aes(x = ASSESSMENT_HECTARES)) +\n  geom_histogram(bins = 40) +\n  scale_x_log10() +\n  labs(\n    title = \"Distribution of Fire Size (Assessment Hectares)\",\n    x = \"Fire Size (log scale)\",\n    y = \"Number of Fires\"\n  )\n\n\n\n\n\n\n\n\nProportion of Large Fires by Cause\n\nwildfire_clean %&gt;%\n  group_by(TRUE_CAUSE) %&gt;%\n  summarize(prop_large = mean(large_fire, na.rm = TRUE)) %&gt;%\n  ggplot(aes(x = reorder(TRUE_CAUSE, prop_large), y = prop_large)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Proportion of Large Fires by True Cause\",\n    x = \"True Cause\",\n    y = \"Proportion of Fires &gt; 10 ha\"\n  )\n\n\n\n\n\n\n\n\n\n\n3. Logistic Regression Model\nWe build a logistic regression model to predict the likelihood of a fire becoming large based on temperature, wind speed, and cause.\n\nlibrary(broom)\n\nmodel &lt;- glm(\n  large_fire ~ TEMPERATURE + WIND_SPEED + TRUE_CAUSE + DETECTION_AGENT_TYPE,\n  data = wildfire_clean,\n  family = \"binomial\"\n)\n\n\n# Tidy and clean model output\ntidy_model &lt;- broom::tidy(model) %&gt;%\n  dplyr::mutate(\n    estimate = round(estimate, 3),\n    std.error = round(std.error, 3),\n    statistic = round(statistic, 2),\n    p.value = round(p.value, 4)\n  )\n\n# Create a nice table\ngt_table &lt;- tidy_model %&gt;%\n  gt::gt() %&gt;%\n  gt::tab_header(\n    title = \"Logistic Regression Results\",\n    subtitle = \"Predicting Large Fires (&gt; 10 ha)\"\n  ) %&gt;%\n  gt::cols_label(\n    term = \"Variable\",\n    estimate = \"Estimate (Log-Odds)\",\n    std.error = \"Std. Error\",\n    statistic = \"z value\",\n    p.value = \"p-value\"\n  ) %&gt;%\n  gt::fmt_missing(everything(), missing_text = \"-\") %&gt;%\n  gt::tab_options(\n    table.font.size = \"small\",\n    data_row.padding = gt::px(4),\n    heading.title.font.size = 16,\n    heading.subtitle.font.size = 12\n  )\n\ngt_table\n\n\n\n\n\n\n\nLogistic Regression Results\n\n\nPredicting Large Fires (&gt; 10 ha)\n\n\nVariable\nEstimate (Log-Odds)\nStd. Error\nz value\np-value\n\n\n\n\n(Intercept)\n-4.262\n0.512\n-8.32\n0.0000\n\n\nTEMPERATURE\n-0.040\n0.012\n-3.22\n0.0013\n\n\nWIND_SPEED\n0.051\n0.007\n7.01\n0.0000\n\n\nTRUE_CAUSEAnimals\n-15.465\n2121.042\n-0.01\n0.9942\n\n\nTRUE_CAUSEArson Known\n-16.045\n2200.700\n-0.01\n0.9942\n\n\nTRUE_CAUSEArson Suspected\n-0.219\n0.671\n-0.33\n0.7443\n\n\nTRUE_CAUSEBurning Substance\n-0.016\n0.450\n-0.04\n0.9716\n\n\nTRUE_CAUSEFlammable Fluids\n-16.016\n4207.738\n0.00\n0.9970\n\n\nTRUE_CAUSEFriction Spark\n0.401\n0.678\n0.59\n0.5541\n\n\nTRUE_CAUSEHigh Hazard\n-16.284\n1926.733\n-0.01\n0.9933\n\n\nTRUE_CAUSEHot Exhaust\n0.346\n0.793\n0.44\n0.6628\n\n\nTRUE_CAUSEIncendiary Device\n0.489\n1.075\n0.45\n0.6492\n\n\nTRUE_CAUSEInsufficient Buffer\n0.231\n0.514\n0.45\n0.6531\n\n\nTRUE_CAUSEInsufficient Resources\n3.811\n1.241\n3.07\n0.0021\n\n\nTRUE_CAUSELine Impact\n-2.123\n1.069\n-1.99\n0.0470\n\n\nTRUE_CAUSEMechanical Failure\n-0.532\n0.790\n-0.67\n0.5011\n\n\nTRUE_CAUSEPermit Related\n0.326\n0.425\n0.77\n0.4439\n\n\nTRUE_CAUSEUnattended Fire\n0.041\n1.064\n0.04\n0.9696\n\n\nTRUE_CAUSEUnclassified\n0.375\n0.791\n0.47\n0.6355\n\n\nTRUE_CAUSEUnpredictable Event\n-0.738\n0.800\n-0.92\n0.3562\n\n\nTRUE_CAUSEUnsafe Fire\n-0.146\n0.401\n-0.36\n0.7161\n\n\nTRUE_CAUSEVehicle Fire\n-0.631\n1.060\n-0.60\n0.5516\n\n\nTRUE_CAUSEWinter Burning\n0.433\n0.454\n0.95\n0.3409\n\n\nDETECTION_AGENT_TYPEGRP\n-16.143\n438.705\n-0.04\n0.9706\n\n\nDETECTION_AGENT_TYPELKT\n0.023\n0.371\n0.06\n0.9502\n\n\nDETECTION_AGENT_TYPEUNP\n-0.613\n0.363\n-1.69\n0.0907\n\n\n\n\n\n\n\n\n\n4. Discussion\nThe logistic regression model revealed that higher wind speeds are strongly associated with an increased likelihood of a fire becoming large (over 10 hectares), consistent with our expectations about fire spread dynamics.\nSurprisingly, temperature showed a small negative association with fire size, though this may be influenced by interactions with other environmental factors like humidity or fuel type.\nAmong causes, “Insufficient Resources” and “Line Impact” were associated with significantly higher odds of large fires. This suggests that both human-related limitations and infrastructure vulnerability (like power lines) play a role in fire escalation.\nThe detection agent type showed weak evidence that fires detected by UNP agents may be less likely to become large, compared to FPD Staff, but the effect was not statistically strong (p = 0.09). Further exploration is needed here, especially considering the early intervention ability of different detection teams.\nThese findings provide insights into key environmental and operational factors influencing wildfire severity. Importantly, they point to the need for targeted mitigation strategies in areas with poor detection access or high infrastructure risks.\nIn the broader context of equity, this analysis reinforces that resource constraints and delayed detection—often more common in remote or underfunded regions—can amplify wildfire impacts. Data-informed strategies can help ensure more equitable protection against climate-driven disasters.\n\n\n5. Interpretation Boost using marginaleffects\nWind Speed\nAs wind speed increases, the model estimates a higher probability of a fire becoming large (&gt;10 hectares). However, the variability in the predicted probabilities also increases at higher wind speeds, as indicated by the wider confidence intervals. This suggests that while there is a general upward trend, the model’s certainty about the exact magnitude of the effect decreases in this range—likely due to fewer observations or greater variability in fire outcomes at high wind speeds.\n\nlibrary(marginaleffects)\n\nWarning: package 'marginaleffects' was built under R version 4.4.3\n\n## continuous variable\nplot_predictions(\n  model,\n  by = \"WIND_SPEED\"\n)\n\n\n\n\n\n\n\n\nTemperature\nAs temperature increases, the model predicts a relatively stable probability of a fire becoming large. The trend line flattens and the confidence intervals narrow, indicating that the model is more confident and consistent in its estimates across higher temperature ranges. This suggests that the relationship between temperature and fire size is more stable and predictable at higher temperatures, possibly due to a larger number of observations or less variability in outcomes.\n\n## continuous variable \"TEMPERATURE\"\n\nplot_predictions(\n  model,\n  by = \"TEMPERATURE\"\n)\n\n\n\n\n\n\n\n\nTrue Cause\nThe predicted probability of a large fire is near zero for most TRUE_CAUSE categories, indicating that these causes (e.g., natural ignition, campfires, equipment use) are generally not associated with large-scale fires. However, the category “Insufficient Resources” stands out with a significantly higher predicted probability and a wide confidence interval. This suggests that fires classified under this cause are much more likely to become large, though the wide interval reflects substantial uncertainty — likely due to a small number of observations in that category.\n\n## categorical variable \"TRUE_CAUSE\"\nplot_predictions(model, by = \"TRUE_CAUSE\") +\n  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1)) +\n  ggplot2::labs(\n    title = \"Predicted Probability of Large Fire by True Cause\",\n    x = \"True Cause\",\n    y = \"Predicted Probability\"\n  )\n\n\n\n\n\n\n\n\nDetection Agent Type\nAlthough fires detected by AIR agents appear more likely to become large, the model is relatively uncertain about this pattern. The wide confidence interval indicates that this result should be interpreted cautiously, and may reflect data sparsity or high variability in fire outcomes for AIR-detected cases.\n\n## categorical variable \"DETECTION_AGENT_TYPE\"\nplot_predictions(\n  model,\n  by = \"DETECTION_AGENT_TYPE\"\n)"
  },
  {
    "objectID": "website_files/description_pages/wildfire.html#attribution",
    "href": "website_files/description_pages/wildfire.html#attribution",
    "title": "Historical Canadian Wildfire Data",
    "section": "Attribution",
    "text": "Attribution\nData sourced from the Government of Alberta via the Government of Canada’s Open Government Portal, available under an Open Government Licence - Alberta. Original dataset: Historical wildfire data: 2006-2024."
  },
  {
    "objectID": "website_files/grid_items/globalrights.html",
    "href": "website_files/grid_items/globalrights.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Global Rights\n\n\nDescription: XXX\n\nMore Details"
  },
  {
    "objectID": "website_files/grid_items/indigenousbusiness.html",
    "href": "website_files/grid_items/indigenousbusiness.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Indigenous Businesses\n\n\nDescription: XXX\n\nMore Details"
  },
  {
    "objectID": "website_files/grid_items/wildfire.html",
    "href": "website_files/grid_items/wildfire.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "Wildfire\n\n\nDescription: This data set on Canadian wildfires includes data on fire size, cause, location, detection method, response, and weather. Collected from official sources, it supports wildfire risk assessment and response. It also highlights social and geographic disparities, emphasizing impacts on remote and underserved communities facing climate-related and infrastructure challenges.\n\nMore Details"
  },
  {
    "objectID": "website_files/notebooks/hcmst.html",
    "href": "website_files/notebooks/hcmst.html",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "This data set is adapted from the original data set How Couples Meet and Stay Together 2017, 2022 survey, collected by Stanford University researchers. The data set explores the dynamics of relationships among adults in the United States, with data points gathered from subjects in 2017, 2020 and 2022. This adapted data set focuses on variables that may affect the quality of the relationship, considering demographic characteristics of the subjects, as well as the effect of the COVID-19 pandemic.\nThe extensive use of dating apps and the COVID-19 pandemic had a significant impact on how romantic relationships in the United States. This data set enables exploration of how external factors, like the health of the subjects and income changes, as well as personal behaviors, like conflict and intimate dynamics, relate to an individual’s perception of the quality of the relationship.\nThis analysis contributes to discussions around partnership resilience, healthy relationships, and how norms around sexuality and technology shape romantic relationships.\n\n\nEach row in the data set represents an individual subject and includes the following selected variables:\n\nSubject demographics: age, sex, ethnicity, education level, income level, and employment status\nRelationship context: whether the subject is part of a same-sex relationship, whether they are married, the duration of the relationship and how many children are in the household.\nCouple behavior indicators: sex, flirting and fighting frequency.\nPandemic Variables: interpreted impact of the pandemic in the relationship, income change during the pandemic, if the subject and their partner were sick with COVID-19 and if they were vaccinated.\nQuality of the relationship: variable used to measure the subject’s perceived quality of their relationship.\n\n\n\n\nThis data set supports investigations into:\n\nDemographic and behavioral predictors of relationship quality.\nHow the pandemic experience affected relationships.\nDifferences in relationship dynamics between different levels of income, gender and sexual orientation."
  },
  {
    "objectID": "website_files/notebooks/hcmst.html#about-the-data",
    "href": "website_files/notebooks/hcmst.html#about-the-data",
    "title": "Diverse Data Hub",
    "section": "",
    "text": "This data set is adapted from the original data set How Couples Meet and Stay Together 2017, 2022 survey, collected by Stanford University researchers. The data set explores the dynamics of relationships among adults in the United States, with data points gathered from subjects in 2017, 2020 and 2022. This adapted data set focuses on variables that may affect the quality of the relationship, considering demographic characteristics of the subjects, as well as the effect of the COVID-19 pandemic.\nThe extensive use of dating apps and the COVID-19 pandemic had a significant impact on how romantic relationships in the United States. This data set enables exploration of how external factors, like the health of the subjects and income changes, as well as personal behaviors, like conflict and intimate dynamics, relate to an individual’s perception of the quality of the relationship.\nThis analysis contributes to discussions around partnership resilience, healthy relationships, and how norms around sexuality and technology shape romantic relationships.\n\n\nEach row in the data set represents an individual subject and includes the following selected variables:\n\nSubject demographics: age, sex, ethnicity, education level, income level, and employment status\nRelationship context: whether the subject is part of a same-sex relationship, whether they are married, the duration of the relationship and how many children are in the household.\nCouple behavior indicators: sex, flirting and fighting frequency.\nPandemic Variables: interpreted impact of the pandemic in the relationship, income change during the pandemic, if the subject and their partner were sick with COVID-19 and if they were vaccinated.\nQuality of the relationship: variable used to measure the subject’s perceived quality of their relationship.\n\n\n\n\nThis data set supports investigations into:\n\nDemographic and behavioral predictors of relationship quality.\nHow the pandemic experience affected relationships.\nDifferences in relationship dynamics between different levels of income, gender and sexual orientation."
  },
  {
    "objectID": "website_files/notebooks/hcmst.html#case-study",
    "href": "website_files/notebooks/hcmst.html#case-study",
    "title": "Diverse Data Hub",
    "section": "Case Study",
    "text": "Case Study\n\nObjective\nWhat behavioral factors are strongly associated with relationship quality in the context of the COVID-19 pandemic? Are these factors different for same sex couples?\nThis case study examines the association between relationship_quality and a variety of demographic, behavioral and pandemic-related variables.\nBy examining survey data, we aim to:\n\nExplore the different factors that were collected through the survey.\nIdentify the behavioral factors that most strongly affect the perceived relationship quality. We will focus specifically on finding how sex_frequency, flirts_with_partner and fights_with_partner affect the perception of relationship quality.\nEvaluate if these factors have a different impact on same_sex_couples.\n\n\n\nMethodology\n\n0. Load Libraries\n\nlibrary(tidyverse) \n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(cowplot)\n\n\nAttaching package: 'cowplot'\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nlibrary(broom)\nlibrary(brant)\n\nWarning: package 'brant' was built under R version 4.4.3\n\n\n\n\n1. Data Cleaning & Processing\nFirst, we can load our data and remove all NA values from the data set as we will be interested in using all the available variables as explanatory variables.\n\n# Reading Data\nhcmst &lt;- read_csv(\"../../data/clean/hcmst.csv\") \n\nRows: 1328 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (18): subject_education, subject_sex, subject_ethnicity, subject_income_...\ndbl  (3): subject_age, relationship_duration, children\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Review total rows\nnrow(hcmst)\n\n[1] 1328\n\n# Select features of interest and removing NA\nhcmst &lt;- hcmst |&gt; \n  dplyr::select(same_sex_couple, sex_frequency, flirts_with_partner, fights_with_partner, relationship_quality) |&gt; \n  drop_na()\n\n# Remaining row count.\nnrow(hcmst)\n\n[1] 1241\n\n# Visualize the data set\nhead(hcmst)\n\n# A tibble: 6 × 5\n  same_sex_couple sex_frequency        flirts_with_partner   fights_with_partner\n  &lt;chr&gt;           &lt;chr&gt;                &lt;chr&gt;                 &lt;chr&gt;              \n1 no              once_or_twice_a_week a_few_times_a_week    0_times            \n2 no              once_a_month_or_less never                 7_or_more_times    \n3 no              once_or_twice_a_week a_few_times_a_week    2_times            \n4 no              once_or_twice_a_week 1_to_3_times_a_month  0_times            \n5 no              once_or_twice_a_week a_few_times_a_week    0_times            \n6 no              once_a_month_or_less less_than_once_a_mon… 1_time             \n# ℹ 1 more variable: relationship_quality &lt;chr&gt;\n\n\n\n\n2. Variable Encoding\nWe can note that our categorical response follows a specific order. For this reason, we require a model that suits ordinal responses. Hence, we will be using an Ordinal Logistic regression model framework.\nIn order to do so, we need to make sure that our response variable is encoded as an ordered factor. We will also take this opportunity to encode all our explanatory variables as factors (and ordered factors) as needed, even if we will not use all of them in our exercise.\n\n# First, we can encode our nomical categorical explanatory variables:\n\nhcmst$same_sex_couple &lt;- as.factor(hcmst$same_sex_couple)\nlevels(hcmst$same_sex_couple)\n\n[1] \"no\"  \"yes\"\n\n\n\n# Then, we can encode all our ordinal categorical explanatory variables:\n\nhcmst$sex_frequency &lt;- as.ordered(hcmst$sex_frequency)\nhcmst$sex_frequency &lt;- fct_relevel(\n  hcmst$sex_frequency,\n  c(\"once_a_month_or_less\", \"2_to_3_times_a_month\", \"once_or_twice_a_week\", \"3_to_6_times_a_week\", \"once_or_more_a_day\")\n)\nlevels(hcmst$sex_frequency)\n\n[1] \"once_a_month_or_less\" \"2_to_3_times_a_month\" \"once_or_twice_a_week\"\n[4] \"3_to_6_times_a_week\"  \"once_or_more_a_day\"  \n\nhcmst$flirts_with_partner &lt;- as.ordered(hcmst$flirts_with_partner)\nhcmst$flirts_with_partner &lt;- fct_relevel(\n  hcmst$flirts_with_partner,\n  c(\"never\", \"less_than_once_a_month\", \"1_to_3_times_a_month\", \"once_a_week\", \"a_few_times_a_week\", \"every_day\")\n)\nlevels(hcmst$flirts_with_partner)\n\n[1] \"never\"                  \"less_than_once_a_month\" \"1_to_3_times_a_month\"  \n[4] \"once_a_week\"            \"a_few_times_a_week\"     \"every_day\"             \n\nhcmst$fights_with_partner &lt;- as.ordered(hcmst$fights_with_partner)\nhcmst$fights_with_partner &lt;- fct_relevel(\n  hcmst$fights_with_partner,\n  c(\"0_times\", \"1_time\", \"2_times\", \"3_times\", \"4_times\", \"5_times\", \"6_times\", \"7_or_more_times\")\n)\nlevels(hcmst$fights_with_partner)\n\n[1] \"0_times\"         \"1_time\"          \"2_times\"         \"3_times\"        \n[5] \"4_times\"         \"5_times\"         \"6_times\"         \"7_or_more_times\"\n\n\n\nhcmst$relationship_quality &lt;- as.ordered(hcmst$relationship_quality)\nhcmst$relationship_quality &lt;- fct_relevel(\n  hcmst$relationship_quality,\n  c(\"very_poor\", \"poor\", \"fair\", \"good\", \"excellent\")\n)\nlevels(hcmst$relationship_quality)\n\n[1] \"very_poor\" \"poor\"      \"fair\"      \"good\"      \"excellent\"\n\nhead(hcmst)\n\n# A tibble: 6 × 5\n  same_sex_couple sex_frequency        flirts_with_partner   fights_with_partner\n  &lt;fct&gt;           &lt;ord&gt;                &lt;ord&gt;                 &lt;ord&gt;              \n1 no              once_or_twice_a_week a_few_times_a_week    0_times            \n2 no              once_a_month_or_less never                 7_or_more_times    \n3 no              once_or_twice_a_week a_few_times_a_week    2_times            \n4 no              once_or_twice_a_week 1_to_3_times_a_month  0_times            \n5 no              once_or_twice_a_week a_few_times_a_week    0_times            \n6 no              once_a_month_or_less less_than_once_a_mon… 1_time             \n# ℹ 1 more variable: relationship_quality &lt;ord&gt;\n\n\n\n\n2. Exploratory Data Analysis\nLet’s visualize histograms and stacked bar charts for our different categorical variables to see how different groups were sampled in the survey and how different these samples are for same sex couples.\nFirst, we will create a couple of functions that will be used for visualization.\n\nstacked_bar_plot &lt;- function(data, x_var, stacked_var, plot_title = \"Stacked Bar Charts\") {\n\n  prop_summary &lt;- as.data.frame(xtabs(\n    formula = as.formula(paste0(\"~\", x_var, \"+\", stacked_var)),\n    data = data\n  ))\n\n  row_totals &lt;- aggregate(Freq ~ get(x_var), data = prop_summary, sum)\n  names(row_totals) &lt;- c(x_var, \"Total\")\n\n  prop_summary &lt;- prop_summary |&gt; \n    left_join(row_totals, by = x_var) |&gt; \n    mutate(prop = Freq / Total)\n\n  ggplot(\n    prop_summary, aes_string(x = x_var, y = \"prop\", fill = stacked_var)) +\n    geom_bar(stat = \"identity\", linewidth = 0.7, colour = \"black\") +\n    geom_text(\n      aes(\n        label = ifelse(\n          prop &gt;= 0.05, \n          paste0(\n            sprintf(\"%.0f\", prop * 100), \n            \"%\"), \n          \"\")\n        ),\n      position = position_stack(vjust = 0.5), \n      colour = \"firebrick3\", \n      fontface = \"bold\", \n      size = 5) +\n    scale_y_continuous(labels = percent_format()) +\n    labs(y = \"Percentage\", x = \"Same Sex Couple\", fill = \"\") +\n    ggtitle(plot_title) +\n    theme(\n      plot.title = element_text(size = 12, face = \"bold\"),\n      axis.text.x = element_text(size = 9, angle = 0),\n      axis.text.y = element_text(size = 9, angle = 0),\n      axis.title = element_text(size = 12),\n      legend.text = element_text(size = 12, margin = margin(r = 1, unit = \"cm\")),\n      legend.title = element_text(size = 12, face = \"bold\")\n    ) +\n    guides(fill = guide_legend(title = \"Characteristic\")) +\n    scale_fill_brewer(palette = \"Blues\")\n}\n\nhistogram_plot &lt;- function(data, y_var, plot_title = \"Counts by Category\") {\n  data_long &lt;- data |&gt;\n    dplyr::select(all_of(y_var)) |&gt;\n    pivot_longer(cols = everything(), names_to = \"variable\", values_to = \"value\") |&gt;\n    count(variable, value)\n\n  ggplot(data_long, aes(y = reorder(value, n))) +\n    geom_bar(aes(x = n), stat = \"identity\", fill = \"skyblue2\") +\n    labs(\n      title = plot_title,\n      x = \"Count\",\n      y = NULL\n    ) +\n    theme_minimal()\n}\n\nWe can note that a small minority of the sample are involved in same-sex couples.\n\nhist_same_sex &lt;- histogram_plot(hcmst, \"same_sex_couple\", plot_title = \"Counts by Category\")\n\nhist_same_sex\n\n\n\n\n\n\n\n\nNow we can look at how often the sample are having sex with their partners.\nWe can note that same-sex couples have very similar proportions in how often they have sex vs different-sex couples. We can also note that the sample is skewed towards having sex less frequently.\n\nprop_sex_freq &lt;- stacked_bar_plot(hcmst, \"same_sex_couple\", \"sex_frequency\", plot_title = \"Stacked Bar Charts\")\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\nhist_sex_freq &lt;- histogram_plot(hcmst, \"sex_frequency\", plot_title = \"Counts by Category\")\n\nplot_grid(prop_sex_freq, hist_sex_freq, ncol = 1)\n\n\n\n\n\n\n\n\nWe can also visualize how often couples flirt and fight with their partners. Again, visually there are minor differences in these frequencies between same-sex and different-sex couples. We can also note that the sample is skewed towards having a low frequency of both flirting and fighting.\n\nprop_flirt_freq &lt;- stacked_bar_plot(hcmst, \"same_sex_couple\", \"flirts_with_partner\", plot_title = \"Stacked Bar Charts\")\n\nhist_flirt_freq &lt;- histogram_plot(hcmst, \"flirts_with_partner\", plot_title = \"Counts by Category\")\n\nplot_grid(prop_flirt_freq, hist_flirt_freq, ncol = 1)\n\n\n\n\n\n\n\n\n\nprop_fight_freq &lt;- stacked_bar_plot(hcmst, \"same_sex_couple\", \"fights_with_partner\", plot_title = \"Stacked Bar Charts\")\n\nhist_fight_freq &lt;- histogram_plot(hcmst, \"fights_with_partner\", plot_title = \"Counts by Category\")\n\nplot_grid(prop_fight_freq, hist_fight_freq, ncol = 1)\n\n\n\n\n\n\n\n\nAs for our target variable, it can be noted that most subjects perceived the quality of their relationship to be good or excellent.\n\nprop_quality_freq &lt;- stacked_bar_plot(hcmst, \"same_sex_couple\", \"relationship_quality\", plot_title = \"Stacked Bar Charts\")\n\nhist_quality_freq &lt;- histogram_plot(hcmst, \"relationship_quality\", plot_title = \"Counts by Category\")\n\nplot_grid(prop_quality_freq, hist_quality_freq, ncol = 1)\n\n\n\n\n\n\n\n\n\nggsave(\"../img/hcmst.png\", plot = prop_quality_freq, width = 6, height = 4, dpi = 300)\n\n\n\n3. Ordinal Logistic Regression\nWe will be assuming and fitting a proportional odds model, which assumes that the log-odds of being in a higher category of the response variable follows a linear relationship with the explanatory variables.\nFor our modeling purposes, we will use the MASS package, polr() function to obtain model estimates.\nGiven that we are using ordinal categorical variables as explanatory variables, we will also set our model to use successive differences contrasts to facilitate the interpretation of the estimates.\n\noptions(contrasts = c(\"contr.treatment\", \"contr.sdif\"))\n\nNow, we can fit our model. Noting that polr() does not calculate p-values, we can compute them and bind them to our model estimates. We will also focus only on statistically significant estimates.\nFor the purposes of this exercise, we will only use a subset of the variables in our modeling. We will be interested in how behavioral variables (sex_frequency, flirts_with_partner and fights_with_partner) affect the perception of relationship quality, additionally, we are interested in seeing if these effects are different for same_sex_couples.\n\nordinal_model &lt;- polr(relationship_quality ~ same_sex_couple + sex_frequency + flirts_with_partner + fights_with_partner,\n  data = hcmst, Hess = TRUE\n)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nsummary_partial_ordinal_model &lt;- cbind(tidy(ordinal_model),\n  p.value = pnorm(abs(tidy(ordinal_model)$statistic), lower.tail = FALSE) * 2) |&gt;\n  mutate_if(is.numeric, round, 2)\n\nsummary_partial_ordinal_model |&gt;\n  mutate(exp_estimate = exp(estimate)) |&gt; \n  filter(p.value &lt; 0.05, \n         coef.type == \"coefficient\")\n\n                                                    term estimate std.error\n1 sex_frequency2_to_3_times_a_month-once_a_month_or_less     0.61      0.15\n2    flirts_with_partneronce_a_week-1_to_3_times_a_month    -0.68      0.32\n3        flirts_with_partnerevery_day-a_few_times_a_week     0.80      0.27\n4                      fights_with_partner1_time-0_times    -0.62      0.14\n  statistic   coef.type p.value exp_estimate\n1      4.07 coefficient    0.00    1.8404314\n2     -2.15 coefficient    0.03    0.5066170\n3      2.98 coefficient    0.00    2.2255409\n4     -4.50 coefficient    0.00    0.5379444\n\n\nPositive estimates are associated with higher relationship quality, while negative estimates are associated with lower relationship quality. Additionally, the exponential of the estimate is the odds ratio, which represents how much the odds of having a higher relationship_quality level changes between levels.\nWe can interpret these estimates:\n\nsame_sex_couple: There is no statistical evidence that being part of a same-sex couple has an association with the perceived relationship quality\n\n\n\nsex_frequency: People who have sex 2-3 times a month have 1.8 higher odds of reporting better relationship quality that those who have sex once a month or less.\nflirts_with_partner: Flirting once per week vs 1-3 times per month is associated with a 49% lower odds of better relationship quality. This is a bit unexpected.\nflirts_with_partner: Flirting every day vs a few times per week is associated with 2.3 higher odds of better relationship quality.\nfights_with_partner: Fighting once vs none is associated with 47% lower odds of better relationship quality.\n\nWith our fitted model, we are now able to make predictions on new examples. Based on demographic, behavioral, COVID-19 related variables, we can predict the probabilities of the different levels of perceived relationship_quality for a specific subject.\nBased on the calculated estimates, we would think that people who have more sex, flirt more and fight less would perceive a better relationship_quality. We can test this premise:\n\npredict(ordinal_model, tibble(\n  same_sex_couple = \"no\",\n  sex_frequency = \"once_a_month_or_less\",\n  flirts_with_partner = \"never\",\n  fights_with_partner = \"7_or_more_times\"), \n  type = \"probs\")\n\n very_poor       poor       fair       good  excellent \n0.05086336 0.24537641 0.41765952 0.25193653 0.03416417 \n\npredict(ordinal_model, tibble(\n  same_sex_couple = \"no\",\n  sex_frequency = \"once_or_more_a_day\",\n  flirts_with_partner = \"every_day\",\n  fights_with_partner = \"0_times\"), \n  type = \"probs\")\n\n   very_poor         poor         fair         good    excellent \n0.0002267081 0.0015513052 0.0086702893 0.0963954372 0.8931562601 \n\n\nWe can note that a subject who has sex once a month or less, that never flirt with their partner, and that fought with their partner 7 or more times in the last week, have a 41% probability of perceiving their relationship quality as fair. On the other hand, a subject who has sex once or more per day, that flirts with their partner on a daily basis and that has not fought with their partner in the last week, has an 81% probability of perceiving their relationship quality as excellent.\n\n\n4. Proportional Odds Assumption\nTo ensure the validity of our analysis, we are going to test the proportional odds assumption. To do so, we can use the Brant-Wald test, which assesses whether our model fulfills this assumption.\n\nbrant(ordinal_model)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n---------------------------------------------------------------------------------------------------- \nTest for                                X2  df  probability \n---------------------------------------------------------------------------------------------------- \nOmnibus                                 39.82   51  0.87\nsame_sex_coupleyes                          2.88    3   0.41\nsex_frequency2_to_3_times_a_month-once_a_month_or_less      2.38    3   0.5\nsex_frequencyonce_or_twice_a_week-2_to_3_times_a_month      1.45    3   0.69\nsex_frequency3_to_6_times_a_week-once_or_twice_a_week       2.85    3   0.42\nsex_frequencyonce_or_more_a_day-3_to_6_times_a_week     0   3   1\nflirts_with_partnerless_than_once_a_month-never         2.35    3   0.5\nflirts_with_partner1_to_3_times_a_month-less_than_once_a_month  0.16    3   0.98\nflirts_with_partneronce_a_week-1_to_3_times_a_month     0   3   1\nflirts_with_partnera_few_times_a_week-once_a_week           0.88    3   0.83\nflirts_with_partnerevery_day-a_few_times_a_week         1.5 3   0.68\nfights_with_partner1_time-0_times                   7.42    3   0.06\nfights_with_partner2_times-1_time                   1.43    3   0.7\nfights_with_partner3_times-2_times                  1.81    3   0.61\nfights_with_partner4_times-3_times                  2.06    3   0.56\nfights_with_partner5_times-4_times                  0.08    3   0.99\nfights_with_partner6_times-5_times                  0.08    3   0.99\nfights_with_partner7_or_more_times-6_times              0.82    3   0.85\n---------------------------------------------------------------------------------------------------- \n\nH0: Parallel Regression Assumption holds\n\n\nWarning in brant(ordinal_model): 2118 combinations in table(dv,ivs) do not\noccur. Because of that, the test results might be invalid.\n\n\nNote that with an \\(\\alpha = 0.05\\), we are completely fulfilling the proportional odds assumption (the column probability delivers the corresponding p-values).\nAlso, note that throughout the analysis we got a few warnings. These are caused by having categories in our model that are quite sparse, where combinations of the response and the levels of the predictor have no observations. These gaps may affect Brant statistics. A solution for this matter would be to bin some of the levels of our categories to avoid having empty combinations of levels between our response and explanatory variables.\n\n\n5. Discussion\nThis analysis explored how sex frequency, flirting and fighting relate to perceived relationship quality for different types of couples. Through the analysis, we could note that relationship behaviors play a key role in how individuals assess their relationships. More specifically, we could conclude the following from this exercise:\n\nBehaviors are important, being part of a same-sex couple not so much: More frequent sex and flirting are associated with higher perceived relationship quality, while more frequent fighting affects that perception negatively. Being part of a same-sex couple did not have a statistically significant impact on the perceived relationship quality\nSome effects might not be linear: Not all statistically significant estimates led to better outcomes. Interestingly, flirting once a week was associated with a lower perceived relationship quality than flirting 1-3 times a month.\nEncoding and model choice are critical: Model selection is tied to the type of response variable. Ordinal categorical response variables are tied to ordinal logistic regression models.\nInterpretation is key: Having ordinal explanatory variables poses a challenge in interpretation of model estimates. Using the right contrasts supports model interpretation.\nSparsity may affect results: Having many levels in our categories may lead to sparsity in the combination of explanatory variables to all levels of the response variable. Caution is advised in these cases."
  },
  {
    "objectID": "website_files/notebooks/notebook_py.html",
    "href": "website_files/notebooks/notebook_py.html",
    "title": "Python Page With Code",
    "section": "",
    "text": "import matplotlib.pyplot as plt\n\nplt.plot([1, 2, 3], [4, 9, 5])\nplt.title(\"Simple Python Plot\")\nplt.show()"
  },
  {
    "objectID": "website_files/notebooks/template.html",
    "href": "website_files/notebooks/template.html",
    "title": "Notebook Template",
    "section": "",
    "text": "Provide background information and context about the dataset. Think about answering the following questions:\n\nWhere does the data come from?\nWhy was it collected?\nWhy is the topic of the data socially relevant in the context of equity, diversity and inclusion?\n\n\n\n\n\n\nClearly define the problem or question being addressed by this analysis. What is the goal? What data science problem are you trying to solve or understand with this dataset?\n\n\n\nDescribe the approach taken to address the objective. This could include:\n\nData processing and cleaning steps\nExploratory Data Analysis (EDA)\nModels used\nStatistical tests\n\nInclude relevant code snippets and visualizations where necessary.\n\n\n\nSummarize the key findings, insights, and interpretations from the analysis. What did the data reveal? Were there any unexpected results or trends? How do these results relate to the original objective? In what ways do the findings from this analysis connect to real-world challenges?\n\n\n\n\n\nOriginal Data Source: [Link to the dataset or description of its origin]\n\nLicense: [Dataset license, e.g., “CC BY 4.0”]\n\nCitation: [If applicable, how to cite the data source or paper]\n\nReferences: [Links to or descriptions of key methods, algorithms, or resources used]\n\nAcknowledgements: [Contributors, collaborators, or any support received]"
  },
  {
    "objectID": "website_files/notebooks/template.html#about-the-data",
    "href": "website_files/notebooks/template.html#about-the-data",
    "title": "Notebook Template",
    "section": "",
    "text": "Provide background information and context about the dataset. Think about answering the following questions:\n\nWhere does the data come from?\nWhy was it collected?\nWhy is the topic of the data socially relevant in the context of equity, diversity and inclusion?"
  },
  {
    "objectID": "website_files/notebooks/template.html#case-study",
    "href": "website_files/notebooks/template.html#case-study",
    "title": "Notebook Template",
    "section": "",
    "text": "Clearly define the problem or question being addressed by this analysis. What is the goal? What data science problem are you trying to solve or understand with this dataset?\n\n\n\nDescribe the approach taken to address the objective. This could include:\n\nData processing and cleaning steps\nExploratory Data Analysis (EDA)\nModels used\nStatistical tests\n\nInclude relevant code snippets and visualizations where necessary.\n\n\n\nSummarize the key findings, insights, and interpretations from the analysis. What did the data reveal? Were there any unexpected results or trends? How do these results relate to the original objective? In what ways do the findings from this analysis connect to real-world challenges?"
  },
  {
    "objectID": "website_files/notebooks/template.html#attribution",
    "href": "website_files/notebooks/template.html#attribution",
    "title": "Notebook Template",
    "section": "",
    "text": "Original Data Source: [Link to the dataset or description of its origin]\n\nLicense: [Dataset license, e.g., “CC BY 4.0”]\n\nCitation: [If applicable, how to cite the data source or paper]\n\nReferences: [Links to or descriptions of key methods, algorithms, or resources used]\n\nAcknowledgements: [Contributors, collaborators, or any support received]"
  }
]